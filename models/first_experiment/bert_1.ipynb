{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"bert_1.ipynb","provenance":[{"file_id":"1CzRinqR8Ua2sw0ghLFsovCSlp8VlYnak","timestamp":1617058182082},{"file_id":"https://github.com/mc51/blog_posts/blob/master/doctors_nlp3.ipynb","timestamp":1617030468564}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r-JKjIUr5Frz","executionInfo":{"status":"ok","timestamp":1617726277585,"user_tz":-120,"elapsed":3492,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}},"outputId":"25c05244-6df4-44f6-827a-8e307551ea34"},"source":["# Needed on Google Colab\n","import os\n","if os.environ.get('COLAB_GPU', False):\n","    !pip install -U transformers\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\")"],"execution_count":40,"outputs":[{"output_type":"stream","text":["Requirement already up-to-date: transformers in /usr/local/lib/python3.7/dist-packages (4.4.2)\n","Requirement already satisfied, skipping upgrade: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.2)\n","Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Requirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied, skipping upgrade: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.8.1)\n","Requirement already satisfied, skipping upgrade: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.44)\n","Requirement already satisfied, skipping upgrade: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fYFC1iYJuQEZ","executionInfo":{"status":"ok","timestamp":1617726277586,"user_tz":-120,"elapsed":3479,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}},"outputId":"1e79f788-c55d-4ba0-9a0f-206535740538"},"source":["import nltk\n","import re\n","import pickle\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import tensorflow as tf\n","from datetime import datetime\n","from sklearn import metrics\n","from sklearn.model_selection import train_test_split\n","from nltk.stem.snowball import SnowballStemmer\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","import warnings\n","\n","pd.options.display.max_colwidth = 6000\n","pd.options.display.max_rows = 400\n","np.set_printoptions(suppress=True)\n","warnings.filterwarnings(\"ignore\")\n","print(tf.__version__)"],"execution_count":41,"outputs":[{"output_type":"stream","text":["2.4.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"14VeTB-gu72U"},"source":["Executing this on Colab will make sure that our model runs on a TPU if available and falls back to GPU / CPU otherwise:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nDBKQm8j_Meg","executionInfo":{"status":"ok","timestamp":1617726286934,"user_tz":-120,"elapsed":12818,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}},"outputId":"14857b97-88e3-4774-f465-aa2bc11cb2ce"},"source":["# Try to run on TPU if available\n","# Detect hardware, return appropriate distribution strategy\n","try:\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n","    print(\"Running on TPU \", tpu.cluster_spec().as_dict()[\"worker\"])\n","except ValueError:\n","    tpu = None\n","\n","if tpu:\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","else:\n","    strategy = tf.distribute.get_strategy()\n","print(\"REPLICAS: \", strategy.num_replicas_in_sync)"],"execution_count":42,"outputs":[{"output_type":"stream","text":["Running on TPU  ['10.49.166.194:8470']\n","WARNING:tensorflow:TPU system grpc://10.49.166.194:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:TPU system grpc://10.49.166.194:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.49.166.194:8470\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.49.166.194:8470\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n","WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["REPLICAS:  8\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Zi6GR-GBvBId"},"source":["In our case, we are running on a TPU with eight cores. This will give us an immense speed up!  \n","As before, we first download and extract our data:"]},{"cell_type":"code","metadata":{"id":"OqiD4dLhv1UK","executionInfo":{"status":"ok","timestamp":1617726286938,"user_tz":-120,"elapsed":12815,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}}},"source":["# store current path and download and extract data there\n","CURR_PATH = !pwd"],"execution_count":43,"outputs":[]},{"cell_type":"code","metadata":{"id":"zxTJmxYsSGRM","executionInfo":{"status":"ok","timestamp":1617726286940,"user_tz":-120,"elapsed":12813,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}}},"source":["# PARAMETERS\n","PATH_DATA = CURR_PATH[0]\n","PATH_GDRIVE_TMP = \"/content/drive/MyDrive/tmp/\"  # Google Drive"],"execution_count":44,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XjeL0DV3vQgb"},"source":["Let's load the data set and create our target variable. Positive ratings (one or two) will be considered as good and negative ones (five or six) as negative. As before, we ignore neutral ratings:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":342},"id":"_ds8eLyeQ-qf","executionInfo":{"status":"ok","timestamp":1617726286943,"user_tz":-120,"elapsed":12810,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}},"outputId":"3482c861-d418-40d2-a2da-18f62d509920"},"source":["# read data from csv\n","data = pd.read_csv(PATH_GDRIVE_TMP + \"only_lockdown.csv\", sep='\\t', header=None, skiprows=[0])\n","\n","# Create binary grade, class 1-2 or 5-6  = good or bad\n","data[\"opinion_integer\"] = 0\n","data.loc[data[6] == '-', \"opinion_integer\"] = 0\n","data.loc[data[6] == 'o', \"opinion_integer\"] = 1\n","data.loc[data[6] == '+', \"opinion_integer\"] = 2\n","\n","data.head(6)"],"execution_count":45,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>opinion_integer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-</td>\n","      <td>x</td>\n","      <td>x</td>\n","      <td>x</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>29137</td>\n","      <td>2020_03_15</td>\n","      <td>16</td>\n","      <td>NEOS</td>\n","      <td>Abgeordneter Josef Schellhorn (NEOS)</td>\n","      <td>False</td>\n","      <td>Das heißt, diese Planbarkeit ist jetzt gar nicht machbar – für Sie nicht –, nur die Unternehmer kommen mit dieser Unplanbarkeit gar nicht zurecht, weil dieser Lockdown ja jetzt nur für eine Woche bestimmt ist.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-</td>\n","      <td>x</td>\n","      <td>-</td>\n","      <td>x</td>\n","      <td>x</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>31054</td>\n","      <td>2020_03_20</td>\n","      <td>19</td>\n","      <td>NEOS</td>\n","      <td>Abgeordnete Mag. Beate Meinl-Reisinger, MES (NEOS)</td>\n","      <td>False</td>\n","      <td>Wie und wann schaffen wir es, aus diesem Lockdown wieder herauszukommen, ohne die Gesundheit der Menschen in Österreich oder auch europaweit aufs Spiel zu setzen?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-</td>\n","      <td>#</td>\n","      <td>#+</td>\n","      <td>-</td>\n","      <td>x</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>32973</td>\n","      <td>2020_04_03</td>\n","      <td>22</td>\n","      <td>ÖVP</td>\n","      <td>Abgeordneter August Wöginger (ÖVP)</td>\n","      <td>True</td>\n","      <td>Kickl hat am 13. März von einem Lockdown gesprochen – also alles zudrehen, nichts geht mehr in diesem Land.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>+</td>\n","      <td>x</td>\n","      <td>+</td>\n","      <td>x</td>\n","      <td>x</td>\n","      <td>+</td>\n","      <td>+</td>\n","      <td>34265</td>\n","      <td>2020_04_03</td>\n","      <td>22</td>\n","      <td>NEOS</td>\n","      <td>Abgeordnete Dipl.-Ing. Karin Doppelbauer (NEOS)</td>\n","      <td>False</td>\n","      <td>Ich möchte gleich zu Beginn eines klarstellen, damit es keine Missverständnisse gibt: Ja, der Lockdown war richtig.</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>+</td>\n","      <td>x</td>\n","      <td>x</td>\n","      <td>x</td>\n","      <td>o</td>\n","      <td>o</td>\n","      <td>-</td>\n","      <td>34269</td>\n","      <td>2020_04_03</td>\n","      <td>22</td>\n","      <td>NEOS</td>\n","      <td>Abgeordnete Dipl.-Ing. Karin Doppelbauer (NEOS)</td>\n","      <td>False</td>\n","      <td>Lassen Sie mich aber mit dem Gemeinsamen beginnen: Was das Ziel betrifft, sind wir uns ja alle einig: Es geht um nichts Geringeres als das Einpendeln unserer Volks­wirtschaft auf ein Level, wie es vor der Krise war, oder, wenn Sie so wollen, wenn man jetzt den Lockdown schrittweise lockert, dass dann das Wirtschaftssystem eigentlich genauso aussieht, wie es vor der Krise war.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>+</td>\n","      <td>x</td>\n","      <td>x</td>\n","      <td>x</td>\n","      <td>+s</td>\n","      <td>o</td>\n","      <td>o</td>\n","      <td>34709</td>\n","      <td>2020_04_03</td>\n","      <td>22</td>\n","      <td>NEOS</td>\n","      <td>Abgeordnete Mag. Martina Künsberg Sarre (NEOS)</td>\n","      <td>False</td>\n","      <td>Regelmäßige begleitende Datenerhe­bun­gen in dieser Phase des Lockdowns, in der Lehrer_innen, Schüler_innen und Eltern auf digitales Unterrichten und Lernen absolut angewiesen sind, können einen wesent­lichen Beitrag für eine effiziente Digitalisierung des Bildungssystems in der Zukunft leisten.</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   0  ... opinion_integer\n","0  -  ...               0\n","1  -  ...               0\n","2  -  ...               0\n","3  +  ...               2\n","4  +  ...               0\n","5  +  ...               1\n","\n","[6 rows x 15 columns]"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ikzWTxAASFZM","executionInfo":{"status":"ok","timestamp":1617726287493,"user_tz":-120,"elapsed":13352,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}},"outputId":"284df306-14a0-4e1e-e868-b7998c11057b"},"source":["nltk.download(\"stopwords\")\n","nltk.download(\"punkt\")\n","stemmer = SnowballStemmer(\"german\")\n","stop_words = set(stopwords.words(\"german\"))\n","\n","\n","def clean_text(text, for_embedding=False):\n","    \"\"\"\n","        - remove any html tags (< /br> often found)\n","        - Keep only ASCII + European Chars and whitespace, no digits\n","        - remove single letter chars\n","        - convert all whitespaces (tabs etc.) to single wspace\n","        if not for embedding (but e.g. tdf-idf):\n","        - all lowercase\n","        - remove stopwords, punctuation and stemm\n","    \"\"\"\n","    RE_WSPACE = re.compile(r\"\\s+\", re.IGNORECASE)\n","    RE_TAGS = re.compile(r\"<[^>]+>\")\n","    RE_ASCII = re.compile(r\"[^A-Za-zÀ-ž ]\", re.IGNORECASE)\n","    RE_SINGLECHAR = re.compile(r\"\\b[A-Za-zÀ-ž]\\b\", re.IGNORECASE)\n","    if for_embedding:\n","        # Keep punctuation\n","        RE_ASCII = re.compile(r\"[^A-Za-zÀ-ž,.!? ]\", re.IGNORECASE)\n","        RE_SINGLECHAR = re.compile(r\"\\b[A-Za-zÀ-ž,.!?]\\b\", re.IGNORECASE)\n","\n","    text = re.sub(RE_TAGS, \" \", text)\n","    text = re.sub(RE_ASCII, \" \", text)\n","    text = re.sub(RE_SINGLECHAR, \" \", text)\n","    text = re.sub(RE_WSPACE, \" \", text)\n","\n","    word_tokens = word_tokenize(text)\n","    words_tokens_lower = [word.lower() for word in word_tokens]\n","\n","    if for_embedding:\n","        # no stemming, lowering and punctuation / stop words removal\n","        words_filtered = word_tokens\n","    else:\n","        words_filtered = [\n","            stemmer.stem(word) for word in words_tokens_lower if word not in stop_words\n","        ]\n","\n","    text_clean = \" \".join(words_filtered)\n","    return text_clean"],"execution_count":46,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Vmb_LGpLvdxm"},"source":["Now, we can we apply this pre-processing and cleaning to our original data:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8YJgw-JPSnWD","executionInfo":{"status":"ok","timestamp":1617726287495,"user_tz":-120,"elapsed":13348,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}},"outputId":"8781381e-3d92-4d5d-b061-da1c162ed406"},"source":["%%time\n","# Clean Comments\n","data[\"comment_clean\"] = data.loc[data[13].str.len() > 20, 13]\n","data[\"comment_clean\"] = data[\"comment_clean\"].map(\n","    lambda x: clean_text(x, for_embedding=True) if isinstance(x, str) else x\n",")"],"execution_count":47,"outputs":[{"output_type":"stream","text":["CPU times: user 144 ms, sys: 0 ns, total: 144 ms\n","Wall time: 143 ms\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NqAX1AmfvjcM"},"source":["This is how the final comments will look like:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":858},"id":"4yafAt6HhKCU","executionInfo":{"status":"ok","timestamp":1617726287496,"user_tz":-120,"elapsed":13339,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}},"outputId":"3c23b0c7-0468-4025-e5d2-d686c808657c"},"source":["data"],"execution_count":48,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>opinion_integer</th>\n","      <th>comment_clean</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-</td>\n","      <td>x</td>\n","      <td>x</td>\n","      <td>x</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>29137</td>\n","      <td>2020_03_15</td>\n","      <td>16</td>\n","      <td>NEOS</td>\n","      <td>Abgeordneter Josef Schellhorn (NEOS)</td>\n","      <td>False</td>\n","      <td>Das heißt, diese Planbarkeit ist jetzt gar nicht machbar – für Sie nicht –, nur die Unternehmer kommen mit dieser Unplanbarkeit gar nicht zurecht, weil dieser Lockdown ja jetzt nur für eine Woche bestimmt ist.</td>\n","      <td>0</td>\n","      <td>Das heißt , diese Planbarkeit ist jetzt gar nicht machbar für Sie nicht , nur die Unternehmer kommen mit dieser Unplanbarkeit gar nicht zurecht , weil dieser Lockdown ja jetzt nur für eine Woche bestimmt ist .</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-</td>\n","      <td>x</td>\n","      <td>-</td>\n","      <td>x</td>\n","      <td>x</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>31054</td>\n","      <td>2020_03_20</td>\n","      <td>19</td>\n","      <td>NEOS</td>\n","      <td>Abgeordnete Mag. Beate Meinl-Reisinger, MES (NEOS)</td>\n","      <td>False</td>\n","      <td>Wie und wann schaffen wir es, aus diesem Lockdown wieder herauszukommen, ohne die Gesundheit der Menschen in Österreich oder auch europaweit aufs Spiel zu setzen?</td>\n","      <td>0</td>\n","      <td>Wie und wann schaffen wir es , aus diesem Lockdown wieder herauszukommen , ohne die Gesundheit der Menschen in Österreich oder auch europaweit aufs Spiel zu setzen ?</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-</td>\n","      <td>#</td>\n","      <td>#+</td>\n","      <td>-</td>\n","      <td>x</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>32973</td>\n","      <td>2020_04_03</td>\n","      <td>22</td>\n","      <td>ÖVP</td>\n","      <td>Abgeordneter August Wöginger (ÖVP)</td>\n","      <td>True</td>\n","      <td>Kickl hat am 13. März von einem Lockdown gesprochen – also alles zudrehen, nichts geht mehr in diesem Land.</td>\n","      <td>0</td>\n","      <td>Kickl hat am . März von einem Lockdown gesprochen also alles zudrehen , nichts geht mehr in diesem Land .</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>+</td>\n","      <td>x</td>\n","      <td>+</td>\n","      <td>x</td>\n","      <td>x</td>\n","      <td>+</td>\n","      <td>+</td>\n","      <td>34265</td>\n","      <td>2020_04_03</td>\n","      <td>22</td>\n","      <td>NEOS</td>\n","      <td>Abgeordnete Dipl.-Ing. Karin Doppelbauer (NEOS)</td>\n","      <td>False</td>\n","      <td>Ich möchte gleich zu Beginn eines klarstellen, damit es keine Missverständnisse gibt: Ja, der Lockdown war richtig.</td>\n","      <td>2</td>\n","      <td>Ich möchte gleich zu Beginn eines klarstellen , damit es keine Missverständnisse gibt Ja , der Lockdown war richtig .</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>+</td>\n","      <td>x</td>\n","      <td>x</td>\n","      <td>x</td>\n","      <td>o</td>\n","      <td>o</td>\n","      <td>-</td>\n","      <td>34269</td>\n","      <td>2020_04_03</td>\n","      <td>22</td>\n","      <td>NEOS</td>\n","      <td>Abgeordnete Dipl.-Ing. Karin Doppelbauer (NEOS)</td>\n","      <td>False</td>\n","      <td>Lassen Sie mich aber mit dem Gemeinsamen beginnen: Was das Ziel betrifft, sind wir uns ja alle einig: Es geht um nichts Geringeres als das Einpendeln unserer Volks­wirtschaft auf ein Level, wie es vor der Krise war, oder, wenn Sie so wollen, wenn man jetzt den Lockdown schrittweise lockert, dass dann das Wirtschaftssystem eigentlich genauso aussieht, wie es vor der Krise war.</td>\n","      <td>0</td>\n","      <td>Lassen Sie mich aber mit dem Gemeinsamen beginnen Was das Ziel betrifft , sind wir uns ja alle einig Es geht um nichts Geringeres als das Einpendeln unserer Volks wirtschaft auf ein Level , wie es vor der Krise war , oder , wenn Sie so wollen , wenn man jetzt den Lockdown schrittweise lockert , dass dann das Wirtschaftssystem eigentlich genauso aussieht , wie es vor der Krise war .</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>487</th>\n","      <td>+</td>\n","      <td>x</td>\n","      <td>x</td>\n","      <td>x</td>\n","      <td>+</td>\n","      <td>o</td>\n","      <td>+</td>\n","      <td>140987</td>\n","      <td>2020_11_26</td>\n","      <td>67</td>\n","      <td>Grüne</td>\n","      <td>Abgeordnete Dr. Elisabeth Götze (Grüne)</td>\n","      <td>True</td>\n","      <td>Wegen des aktuellen Lockdowns hat das Wifo die Prognose revidiert, daher wird im Vergleich zum Bundesfinanzrahmengesetz vergangene Woche jetzt noch mehr Geld für die Menschen – für Soziales und für Arbeit – vorgesehen, für die Unterstützung von Be­troffenen dieser Coronakrise.</td>\n","      <td>2</td>\n","      <td>Wegen des aktuellen Lockdowns hat das Wifo die Prognose revidiert , daher wird im Vergleich zum Bundesfinanzrahmengesetz vergangene Woche jetzt noch mehr Geld für die Menschen für Soziales und für Arbeit vorgesehen , für die Unterstützung von Be troffenen dieser Coronakrise .</td>\n","    </tr>\n","    <tr>\n","      <th>488</th>\n","      <td>-</td>\n","      <td>x</td>\n","      <td>x</td>\n","      <td>x</td>\n","      <td>-</td>\n","      <td>o</td>\n","      <td>-</td>\n","      <td>141109</td>\n","      <td>2020_11_26</td>\n","      <td>67</td>\n","      <td>NEOS</td>\n","      <td>Abgeordnete Dipl.-Ing. Karin Doppelbauer (NEOS)</td>\n","      <td>False</td>\n","      <td>Noch einmal: Ich bin auch der Meinung meiner Kolleginnen und Kollegen von der Oppo­sition, dass der harte Lockdown, der in dieses Budget 2021 nicht eingepreist ist, natürlich hätte eingepreist werden sollen.</td>\n","      <td>0</td>\n","      <td>Noch einmal Ich bin auch der Meinung meiner Kolleginnen und Kollegen von der Oppo sition , dass der harte Lockdown , der in dieses Budget nicht eingepreist ist , natürlich hätte eingepreist werden sollen .</td>\n","    </tr>\n","    <tr>\n","      <th>489</th>\n","      <td>-</td>\n","      <td>x</td>\n","      <td>x</td>\n","      <td>-</td>\n","      <td>x</td>\n","      <td>o</td>\n","      <td>-</td>\n","      <td>141310</td>\n","      <td>2020_11_26</td>\n","      <td>67</td>\n","      <td>FPÖ</td>\n","      <td>Abgeordneter Michael Schnedlitz (FPÖ)</td>\n","      <td>False</td>\n","      <td>Sie haben ja zum Beispiel durch den Lockdown und die überbordenden Maßnah­men durch die Hintertür das größte Amazon-Förderpaket der Geschichte geschaffen.</td>\n","      <td>0</td>\n","      <td>Sie haben ja zum Beispiel durch den Lockdown und die überbordenden Maßnah men durch die Hintertür das größte Amazon Förderpaket der Geschichte geschaffen .</td>\n","    </tr>\n","    <tr>\n","      <th>490</th>\n","      <td>-</td>\n","      <td>x</td>\n","      <td>x</td>\n","      <td>-</td>\n","      <td>x</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>141594</td>\n","      <td>2020_11_26</td>\n","      <td>67</td>\n","      <td>SPÖ</td>\n","      <td>Abgeordnete Mag. Karin Greiner (SPÖ)</td>\n","      <td>False</td>\n","      <td>Bedingt durch die Maßnahmen der ÖVP/Grüne-Bundesregierung, insbesondere der neuerliche Lockdown im Novem­ber 2020 lassen die Einnahmen ganzer Branchen wegbrechen.</td>\n","      <td>0</td>\n","      <td>Bedingt durch die Maßnahmen der ÖVP Grüne Bundesregierung , insbesondere der neuerliche Lockdown im Novem ber lassen die Einnahmen ganzer Branchen wegbrechen .</td>\n","    </tr>\n","    <tr>\n","      <th>491</th>\n","      <td>-</td>\n","      <td>x</td>\n","      <td>x</td>\n","      <td>-</td>\n","      <td>x</td>\n","      <td>o</td>\n","      <td>-</td>\n","      <td>141604</td>\n","      <td>2020_11_26</td>\n","      <td>67</td>\n","      <td>SPÖ</td>\n","      <td>Abgeordnete Mag. Karin Greiner (SPÖ)</td>\n","      <td>False</td>\n","      <td>Angesichts der sich weiter verschlechternden Situation durch den zweiten Lockdown, dessen Dauer immer noch nicht abzusehen ist, sowie der Mehrwertsteuersenkungen für manche Bereiche, was sich ebenfalls auf eine zusätzliche Reduktion der Ertragsanteile auswirkt, benötigen die Gemeinden dringend Finanzmittel um die Leistungen für die Be­völkerung aufrecht erhalten zu können.</td>\n","      <td>0</td>\n","      <td>Angesichts der sich weiter verschlechternden Situation durch den zweiten Lockdown , dessen Dauer immer noch nicht abzusehen ist , sowie der Mehrwertsteuersenkungen für manche Bereiche , was sich ebenfalls auf eine zusätzliche Reduktion der Ertragsanteile auswirkt , benötigen die Gemeinden dringend Finanzmittel um die Leistungen für die Be völkerung aufrecht erhalten zu können .</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>492 rows × 16 columns</p>\n","</div>"],"text/plain":["     0  ...                                                                                                                                                                                                                                                                                                                                                                                     comment_clean\n","0    -  ...                                                                                                                                                                                 Das heißt , diese Planbarkeit ist jetzt gar nicht machbar für Sie nicht , nur die Unternehmer kommen mit dieser Unplanbarkeit gar nicht zurecht , weil dieser Lockdown ja jetzt nur für eine Woche bestimmt ist .\n","1    -  ...                                                                                                                                                                                                                             Wie und wann schaffen wir es , aus diesem Lockdown wieder herauszukommen , ohne die Gesundheit der Menschen in Österreich oder auch europaweit aufs Spiel zu setzen ?\n","2    -  ...                                                                                                                                                                                                                                                                                         Kickl hat am . März von einem Lockdown gesprochen also alles zudrehen , nichts geht mehr in diesem Land .\n","3    +  ...                                                                                                                                                                                                                                                                             Ich möchte gleich zu Beginn eines klarstellen , damit es keine Missverständnisse gibt Ja , der Lockdown war richtig .\n","4    +  ...  Lassen Sie mich aber mit dem Gemeinsamen beginnen Was das Ziel betrifft , sind wir uns ja alle einig Es geht um nichts Geringeres als das Einpendeln unserer Volks wirtschaft auf ein Level , wie es vor der Krise war , oder , wenn Sie so wollen , wenn man jetzt den Lockdown schrittweise lockert , dass dann das Wirtschaftssystem eigentlich genauso aussieht , wie es vor der Krise war .\n","..  ..  ...                                                                                                                                                                                                                                                                                                                                                                                               ...\n","487  +  ...                                                                                                              Wegen des aktuellen Lockdowns hat das Wifo die Prognose revidiert , daher wird im Vergleich zum Bundesfinanzrahmengesetz vergangene Woche jetzt noch mehr Geld für die Menschen für Soziales und für Arbeit vorgesehen , für die Unterstützung von Be troffenen dieser Coronakrise .\n","488  -  ...                                                                                                                                                                                     Noch einmal Ich bin auch der Meinung meiner Kolleginnen und Kollegen von der Oppo sition , dass der harte Lockdown , der in dieses Budget nicht eingepreist ist , natürlich hätte eingepreist werden sollen .\n","489  -  ...                                                                                                                                                                                                                                       Sie haben ja zum Beispiel durch den Lockdown und die überbordenden Maßnah men durch die Hintertür das größte Amazon Förderpaket der Geschichte geschaffen .\n","490  -  ...                                                                                                                                                                                                                                   Bedingt durch die Maßnahmen der ÖVP Grüne Bundesregierung , insbesondere der neuerliche Lockdown im Novem ber lassen die Einnahmen ganzer Branchen wegbrechen .\n","491  -  ...      Angesichts der sich weiter verschlechternden Situation durch den zweiten Lockdown , dessen Dauer immer noch nicht abzusehen ist , sowie der Mehrwertsteuersenkungen für manche Bereiche , was sich ebenfalls auf eine zusätzliche Reduktion der Ertragsanteile auswirkt , benötigen die Gemeinden dringend Finanzmittel um die Leistungen für die Be völkerung aufrecht erhalten zu können .\n","\n","[492 rows x 16 columns]"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"id":"4OatMBdjfD02","executionInfo":{"status":"ok","timestamp":1617726287498,"user_tz":-120,"elapsed":13334,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}}},"source":["data['totalwords'] = data['comment_clean'].str.count(' ') + 1"],"execution_count":49,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Uv5v4_TfOaO","executionInfo":{"status":"ok","timestamp":1617726287499,"user_tz":-120,"elapsed":13329,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}},"outputId":"a754fa51-b6f9-48bf-ae55-2f0d65d233fc"},"source":["data['totalwords'].max()"],"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"text/plain":["121"]},"metadata":{"tags":[]},"execution_count":50}]},{"cell_type":"code","metadata":{"id":"bqglg5EmV9No","executionInfo":{"status":"ok","timestamp":1617726287501,"user_tz":-120,"elapsed":13325,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}}},"source":["# Drop Missing\n","data = data.dropna(axis=\"index\", subset=[\"opinion_integer\", \"comment_clean\"]).reset_index(\n","    drop=True\n",")\n","data = data[[\"comment_clean\", \"opinion_integer\"]]\n","data.columns = [\"text\", \"label\"]\n","data.head(2)\n","data.to_csv(PATH_GDRIVE_TMP + \"only_lockdown_pp.csv\", index=False)"],"execution_count":51,"outputs":[]},{"cell_type":"code","metadata":{"id":"z3PI8aNr76jc","executionInfo":{"status":"ok","timestamp":1617726287503,"user_tz":-120,"elapsed":13324,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}}},"source":["# skip pre processing if done before\n","#data = pd.read_csv(PATH_GDRIVE_TMP + \"only_lockdown_pp.csv\")"],"execution_count":52,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CoDBvCOPDT1K"},"source":["### A brief background on transformers and BERT\n","\n","You've made it to the interesting part. But before we further dive into the code, let's get a brief background on transformers and BERT. Transformer models, similar to RNNs (e.g. the LSTM we used in [part 2]({filename}/doctors_nlp2.ipynb)), are designed to handle sequences of data well. They shine at picking up relations between various inputs in an input sequence. Hence, they lend themselves perfectly for NLP tasks where such associations correspond to semantic relationships. This is also a convenient property of LSTM models, e.g. the one we implemented previously. It was able to learn relationships between sequences of the input, e.g. word vectors. For LSTMs, however, this ability is limited. Because inputs are processed in sequence, in practice, at the end of a long sentence information from the beginning will often be lost. Also, computational limits come into play really quick for the same reason. Transformer models address this issue by using the so called `attention` mechanism. This allows them to process inputs in a non sequential way which allows for better parallelization. Following, computational efficiency is greatly improved. In addition, they learn associations between words even if those are far apart in a sentence. This is an outstanding improvement when trying to model language. It explains why transformers are at the foundation of most state of the art models and why they have surpassed former architectures like LSTMs.  \n","BERT is currently one of the most successful transformer architectures (although, this will change quickly as the speed of innovation at the moment is mind blowing). For a well illustrated and thorough introduction, check out [this article](http://jalammar.github.io/illustrated-bert/) by Jay Allamar. BERT has been developed by Google and has set new records on several language related tasks. Its main novelty is the introduction of bi-directionality. Previous models looked at inputs uni directionally, i.e. from left to right. In contrast, BERT also looks at them from right to left. The authors have proved that this leads to a deeper understanding of context in texts and increases performance significantly.  \n","As most other state of the art models, a lot of BERT's performance comes from sheer size. BERT large (24 layers, 16 attention heads, 340 million parameters) is trained on a huge text dataset in order to gain a thorough understanding of language in general. For this, it follows several ingenious unsupervised training strategies. Training such models is extremely computationally demanding and expensive. For all but big institutions and companies it is prohibitory.  \n","Fortunately, we can apply the principle of transfer learning to such models. That is, we can fine tune a pre trained model on a more specific task and dataset (which doesn't need to be that huge). In our case, we will simply add a classification layer to the pre trained BERT model. Then, we will do a supervised training on our labeled dataset. Consequently, we will mainly train our classifier layer while most other layers will only be minimally impacted. In a sense, we use the general language understanding of the pre trained model and improve its understanding of our unique domain. Moreover, we teach it to solve a specific task. In our case, this will be sentiment analysis in the form of a binary text classification."]},{"cell_type":"markdown","metadata":{"id":"bRP_b3_6vnk3"},"source":["### Feture Creation and Modeling\n","\n","As mentioned before, we use the [`transformers`](https://github.com/huggingface/transformers) library. To stay consistent with our previous neural network model, we use the Tensorflow 2.0 implementation. In addition, this allows us to use the TPU on Google Colab without much trouble. Another invaluable advantage of the transformers library, is that several pre trained models are readily available for usage.  \n","BERT comes with its own Tokenizer. As with the model itself, we will use a pre trained version of the tokenizer. Here, we use a variant that has been specifically trained on German texts and made public. Hence, it already comes with a huge German vocabulary:\n","\n"]},{"cell_type":"code","metadata":{"id":"J7tt6I3g5r1k","executionInfo":{"status":"ok","timestamp":1617726287863,"user_tz":-120,"elapsed":13679,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}}},"source":["# this will download and initialize the pre trained tokenizer\n","from transformers import BertTokenizer, TFBertModel\n","\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-german-cased\")"],"execution_count":53,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iTe4YJL27VYx"},"source":["The inputs expected by BERT are very similar to the ones we've used before: they are just vectors containing integers which can be mapped to tokens by using a dictionary. The only difference is that BERT expects several \"special\" tokens. `[CLS]` stands for classification and marks the beginning of a new input to be classified. `[SEP]` marks the separation between sentences. Finally, `[PAD]` is used as a placeholder in order to pad all vectors to the same fixed length. The helper method `encode_plus` of the `Tokenizer` object deals with creating the numeric vectors while taking care of the extra tokens: \n","\n"]},{"cell_type":"code","metadata":{"id":"V1V50oOB5rUV","executionInfo":{"status":"ok","timestamp":1617726287865,"user_tz":-120,"elapsed":13674,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}}},"source":["MAXLEN = 128\n","#MAXLEN = 256\n","\n","def preprocess_text(data):\n","    \"\"\" take texts and prepare as input features for BERT \n","    \"\"\"\n","    input_ids = []\n","    # For every sentence...\n","    for comment in data:\n","        encoded_sent = tokenizer.encode_plus(\n","            text=comment,\n","            add_special_tokens=True,  # Add `[CLS]` and `[SEP]`\n","            max_length=MAXLEN,  # Max length to truncate/pad\n","            pad_to_max_length=True,  # Pad sentence to max length\n","            return_attention_mask=False,  # attention mask not needed for our task\n","        )\n","        # Add the outputs to the lists\n","        input_ids.append(encoded_sent.get(\"input_ids\"))\n","    return input_ids"],"execution_count":54,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"P4s_1of29uJz"},"source":["Before creating our features, let's check out the workings of the tokenizer with an example:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AxfQAU3sH5yV","executionInfo":{"status":"ok","timestamp":1617726287867,"user_tz":-120,"elapsed":13672,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}},"outputId":"e79601a1-45dc-486a-aa18-b81735b62151"},"source":["# Original Comment and encoding outputs\n","comment = [\"Bedingt durch die Maßnahmen der ÖVP Grüne Bundesregierung, insbesondere der neuerliche Lockdown im November lassen die Einnahmen ganzer Branchen wegbrechen.\"]\n","input_ids = preprocess_text(comment)\n","print(\"Comment: \", comment)\n","print(\"Tokenized Comment: \", tokenizer.convert_ids_to_tokens(input_ids[0])[0:20])\n","print(\"Token IDs: \", input_ids[0][0:20])"],"execution_count":55,"outputs":[{"output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"],"name":"stderr"},{"output_type":"stream","text":["Comment:  ['Bedingt durch die Maßnahmen der ÖVP Grüne Bundesregierung, insbesondere der neuerliche Lockdown im November lassen die Einnahmen ganzer Branchen wegbrechen.']\n","Tokenized Comment:  ['[CLS]', 'Beding', '##t', 'durch', 'die', 'Maßnahmen', 'der', 'ÖVP', 'Grüne', 'Bundesregierung', ',', 'insbesondere', 'der', 'neuer', '##liche', 'Lock', '##down', 'im', 'November', 'lassen']\n","Token IDs:  [3, 14560, 26901, 261, 30, 3406, 21, 26318, 14134, 4260, 26918, 1831, 21, 4201, 322, 22158, 21646, 106, 1324, 1641]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"nd457Xb197pS"},"source":["First, you can see the special tokens being automatically added in the right places. Second, we see that some tokens simply correspond to regular words, i.e. \"Ich\" and \"liebe\". This will be the case for all words that are in the vocabulary. Here, that will amount to most regular German words. In contrast, unknown words get a special treatment. Instead of just being left out, as was the case with the FastText embeddings, they are split to shorter character sequences. For example \"data\", which is not a German word, becomes \"dat\" and \"##a\". This allows the model to still use these novel words.  \n","There is one more major difference between BERT's word embeddings and e.g. FastText's. Recall how vector representations of words with similar semantic meaning in FastText were similar, i.e. had a short distance between them. This allowed our model to group similar words together. BERT takes this one step further. A word's vector representation is not static anymore but depends on context. Consequently, the vector for \"broke\" is different when it's in a context of \"money\" vs. \" a record\". This immensely improves contextual awareness and might benefit predictions in many cases.  \n","Now, we apply the tokenization process to our data:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HLK7nNldJgaj","executionInfo":{"status":"ok","timestamp":1617726288499,"user_tz":-120,"elapsed":14297,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}},"outputId":"dd7621a1-3156-47d6-fcf6-bbd9c2e841cc"},"source":["%%time\n","import pickle\n","\n","input_ids = preprocess_text(data[\"text\"])\n","# tokenization takes quite long\n","# we can save the result and load it quickly via pickle\n","pickle.dump(input_ids, open(PATH_GDRIVE_TMP + \"input_ids_lockdown.pkl\", \"wb\"))\n","# input_ids = pickle.load(open(PATH_GDRIVE_TMP+\"/input_ids.pkl\", \"rb\"))"],"execution_count":56,"outputs":[{"output_type":"stream","text":["CPU times: user 437 ms, sys: 0 ns, total: 437 ms\n","Wall time: 439 ms\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hmlMfRp5_5tm"},"source":["Next, we split out data into train and test for cross validation:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"w9TyLpZhOW2u","executionInfo":{"status":"ok","timestamp":1617726288501,"user_tz":-120,"elapsed":14294,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}},"outputId":"8c94933f-e396-43ba-fdc5-769cd6ee66c3"},"source":["# Sample data for cross validation\n","train_ids, test_ids, train_labels, test_labels = train_test_split(\n","    input_ids, data[\"label\"], test_size=0.15, shuffle=True\n",")\n","print(f\"Train set: {len(train_ids)}\\nTest set: {len(test_ids)}\")"],"execution_count":57,"outputs":[{"output_type":"stream","text":["Train set: 418\n","Test set: 74\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"dare43crAM1B"},"source":["Here, we set the model parameters. `MAXLEN` is the max. number of tokens in our input. Longer inputs will be truncated to this. While greater lengths will yield better predictions, they also mean a greater computational toll. We differentiate between `BATCH_SIZE_PER_REPLICA` and `BATCH_SIZE` when we run on multiple GPUs or TPUs, as is the case on Google Colab. Each TPU core will deal with `BATCH_SIZE_PER_REPLICA` batches at a time. `EPOCHS` is simply the number of training iterations over the whole training set:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"atfTlPd2V4Bq","executionInfo":{"status":"ok","timestamp":1617726288503,"user_tz":-120,"elapsed":14290,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}},"outputId":"71f75a52-d0b7-435f-8cbb-03c0bddb08eb"},"source":["strategy.num_replicas_in_sync"],"execution_count":58,"outputs":[{"output_type":"execute_result","data":{"text/plain":["8"]},"metadata":{"tags":[]},"execution_count":58}]},{"cell_type":"code","metadata":{"id":"VQcG-40V6REl","executionInfo":{"status":"ok","timestamp":1617726288504,"user_tz":-120,"elapsed":14285,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}}},"source":["# Set Model Parameters\n","MAXLEN = MAXLEN\n","BATCH_SIZE_PER_REPLICA = 8\n","BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n","EPOCHS = 8\n","LEARNING_RATE = 1e-5\n","DATA_LENGTH = len(data)"],"execution_count":59,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"OmkFfQVXBkBO"},"source":["As a last step before building our model, we need to prepare our dataset. Before, we used NumPy arrays as inputs. Here, we use the `tf.data.Dataset` class which offers several convenient methods:"]},{"cell_type":"code","metadata":{"id":"h2Su9FAcNWiK","executionInfo":{"status":"ok","timestamp":1617726288505,"user_tz":-120,"elapsed":14281,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}}},"source":["def create_dataset(\n","    data_tuple,\n","    epochs=EPOCHS,\n","    batch_size=BATCH_SIZE,\n","    buffer_size=DATA_LENGTH,\n","    train=False,\n","):\n","    dataset = tf.data.Dataset.from_tensor_slices(data_tuple)\n","    if train:\n","        dataset = dataset.shuffle(\n","            buffer_size=buffer_size, reshuffle_each_iteration=True\n","        ).repeat(epochs)\n","    dataset = dataset.batch(batch_size)\n","    return dataset\n","\n","\n","train = create_dataset(\n","    (train_ids, train_labels), buffer_size=len(train_ids), train=True\n",")\n","test = create_dataset((test_ids, test_labels), buffer_size=len(test_ids))"],"execution_count":60,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CVuhbfcACT6-"},"source":["Finally, we define a function that returns our model architecture:"]},{"cell_type":"code","metadata":{"id":"aP7WVslnIabU","executionInfo":{"status":"ok","timestamp":1617726288506,"user_tz":-120,"elapsed":14277,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}}},"source":["def build_model(transformer, max_len=MAXLEN):\n","    \"\"\" add binary classification to pretrained model\n","    \"\"\"\n","    input_word_ids = tf.keras.layers.Input(\n","        shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\"\n","    )\n","    sequence_output = transformer(input_word_ids)[0]\n","    cls_token = sequence_output[:, 0, :]\n","    out = tf.keras.layers.Dense(3, activation=\"sigmoid\")(cls_token)\n","    model = tf.keras.models.Model(inputs=input_word_ids, outputs=out)\n","    model.compile(\n","        tf.keras.optimizers.Adam(lr=LEARNING_RATE),\n","        loss=\"sparse_categorical_crossentropy\",\n","        metrics=[\"accuracy\"],\n","    )\n","    return model"],"execution_count":61,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cWt-_DYeCbzL"},"source":["In the first step, we define an `Input` layer which expects our numeric vectors as input. Then, we add the pre trained transformer which receives the inputs from the previous layer. The output of the transformer is then fed into a `Dense` layer which finally outputs a probability for our input belonging to class 0 or 1.  \n","Now, we build our model by first downloading the pre trained BERT and passing it to our `build_model` function:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b7FUGjp9IIoq","executionInfo":{"status":"ok","timestamp":1617726325843,"user_tz":-120,"elapsed":51610,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}},"outputId":"7e2fbbb0-9aaf-4d32-9a6d-2a561fb0d4f9"},"source":["with strategy.scope():\n","    transformer_layers = TFBertModel.from_pretrained(\"bert-base-german-cased\")\n","    model = build_model(transformer_layers, max_len=MAXLEN)\n","model.summary()"],"execution_count":62,"outputs":[{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Model: \"model_2\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","input_word_ids (InputLayer)  [(None, 128)]             0         \n","_________________________________________________________________\n","tf_bert_model_2 (TFBertModel TFBaseModelOutputWithPool 109081344 \n","_________________________________________________________________\n","tf.__operators__.getitem_2 ( (None, 768)               0         \n","_________________________________________________________________\n","dense_2 (Dense)              (None, 3)                 2307      \n","=================================================================\n","Total params: 109,083,651\n","Trainable params: 109,083,651\n","Non-trainable params: 0\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NGLGT6q_FX_f"},"source":["In total we have almost 110 Mio. trainable parameters. It's convenient that almost all of them have already been trained. Because we use the pre trained weights for them, they will only need to change ever so slightly. Still, it is a big model and even training on GPUs takes considerable time. So again, good thing that we can use TPUs.  \n","Next, we define callbacks that will be used during training. The `EartlyStopping` callback will stop the training if validation loss stops decreasing between epochs. This avoids overfitting. `ModelCheckpoint` saves checkpoints of the model after each epoch, so that training can be resumed. On Google Colab, you can currently only save TPU models in a Cloud Bucket but not on a mounted Google Drive. Hence, I commented out that part:"]},{"cell_type":"code","metadata":{"id":"huw96xaoPwHG","executionInfo":{"status":"ok","timestamp":1617726325846,"user_tz":-120,"elapsed":51608,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}}},"source":["# Stop training when validation acc starts dropping\n","# Save checkpoint of model each period\n","now = datetime.now().strftime(\"%Y-%m-%d_%H%M\")\n","# Create callbacks\n","callbacks = [\n","    tf.keras.callbacks.EarlyStopping(\n","        monitor=\"val_loss\", verbose=1, patience=1, restore_best_weights=True\n","    ),\n","    # tf.keras.callbacks.ModelCheckpoint(\n","    #    PATH_GDRIVE_TMP + now + \"_Model_{epoch:02d}_{val_loss:.4f}.h5\",\n","    #    monitor=\"val_loss\",\n","    #    save_best_only=True,\n","    #    verbose=1,\n","    # ),\n","]"],"execution_count":63,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"GWSJkmkXIGVq"},"source":["Finally, time to get excited! We can now start the model training:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H0EWQeqgZA2N","executionInfo":{"status":"ok","timestamp":1617726425200,"user_tz":-120,"elapsed":150957,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}},"outputId":"11d0950b-c322-47de-bf55-844dea6e629d"},"source":["%%time\n","# Train using appropriate steps per epochs (go through all train data in an epoch)\n","steps_per_epoch = int(np.floor((len(train_ids) / BATCH_SIZE)))\n","print(\n","    f\"Model Params:\\nbatch_size: {BATCH_SIZE}\\nEpochs: {EPOCHS}\\n\"\n","    f\"Step p. Epoch: {steps_per_epoch}\\n\"\n","    f\"Learning rate: {LEARNING_RATE}\"\n",")\n","hist = model.fit(\n","    train,\n","    batch_size=BATCH_SIZE,\n","    epochs=EPOCHS,\n","    steps_per_epoch=steps_per_epoch,\n","    validation_data=test,\n","    verbose=1,\n","    #callbacks=callbacks,\n",")"],"execution_count":64,"outputs":[{"output_type":"stream","text":["Model Params:\n","batch_size: 64\n","Epochs: 8\n","Step p. Epoch: 6\n","Learning rate: 1e-05\n","Epoch 1/8\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 1.4880 - accuracy: 0.3536WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 90s 3s/step - loss: 1.4654 - accuracy: 0.3596 - val_loss: 0.8915 - val_accuracy: 0.6216\n","Epoch 2/8\n","6/6 [==============================] - 1s 243ms/step - loss: 1.0212 - accuracy: 0.5477 - val_loss: 0.9060 - val_accuracy: 0.6216\n","Epoch 3/8\n","6/6 [==============================] - 1s 253ms/step - loss: 0.9794 - accuracy: 0.5602 - val_loss: 0.8857 - val_accuracy: 0.6216\n","Epoch 4/8\n","6/6 [==============================] - 1s 248ms/step - loss: 0.9980 - accuracy: 0.5196 - val_loss: 1.0080 - val_accuracy: 0.5676\n","Epoch 5/8\n","6/6 [==============================] - 1s 248ms/step - loss: 0.9193 - accuracy: 0.6161 - val_loss: 0.8803 - val_accuracy: 0.6351\n","Epoch 6/8\n","6/6 [==============================] - 1s 249ms/step - loss: 0.9064 - accuracy: 0.6358 - val_loss: 0.9152 - val_accuracy: 0.6216\n","Epoch 7/8\n","6/6 [==============================] - 1s 247ms/step - loss: 0.8949 - accuracy: 0.5714 - val_loss: 0.8528 - val_accuracy: 0.6757\n","Epoch 8/8\n","6/6 [==============================] - 1s 249ms/step - loss: 0.8353 - accuracy: 0.5823 - val_loss: 0.8309 - val_accuracy: 0.6622\n","CPU times: user 38.8 s, sys: 1.96 s, total: 40.7 s\n","Wall time: 1min 39s\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_nzBqsg8I1eY"},"source":["The model converges really fast and stops early after only three epochs. This is because it already achieves the lowest validation loss in the second period:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":608},"id":"r1HG7IBOfzmf","executionInfo":{"status":"ok","timestamp":1617726426327,"user_tz":-120,"elapsed":152078,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}},"outputId":"e8220983-805b-4045-e80b-b684967db79c"},"source":["loss = pd.DataFrame(\n","    {\"train loss\": hist.history[\"loss\"], \"test loss\": hist.history[\"val_loss\"]}\n",").melt()\n","loss[\"epoch\"] = loss.groupby(\"variable\").cumcount() + 1\n","sns.lineplot(x=\"epoch\", y=\"value\", hue=\"variable\", data=loss).set(\n","    title=\"Model loss\",\n","    ylabel=\"\",\n","    xticks=range(1, loss[\"epoch\"].max() + 1),\n","    xticklabels=loss[\"epoch\"].unique(),\n",")"],"execution_count":65,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Text(0, 0.5, ''),\n"," [<matplotlib.axis.XTick at 0x7f37a311f350>,\n","  <matplotlib.axis.XTick at 0x7f367029e610>,\n","  <matplotlib.axis.XTick at 0x7f36701b4250>,\n","  <matplotlib.axis.XTick at 0x7f3673633f90>,\n","  <matplotlib.axis.XTick at 0x7f3670218d10>,\n","  <matplotlib.axis.XTick at 0x7f37bcac5850>,\n","  <matplotlib.axis.XTick at 0x7f3670008390>,\n","  <matplotlib.axis.XTick at 0x7f3673a807d0>],\n"," [Text(0, 0, '1'),\n","  Text(0, 0, '2'),\n","  Text(0, 0, '3'),\n","  Text(0, 0, '4'),\n","  Text(0, 0, '5'),\n","  Text(0, 0, '6'),\n","  Text(0, 0, '7'),\n","  Text(0, 0, '8')],\n"," Text(0.5, 1.0, 'Model loss')]"]},"metadata":{"tags":[]},"execution_count":65},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"ttN0O4gq8fpU"},"source":["Since the low loss value indicates that our model is already really good, we don't do any hyperparameter tuning. Also, our parameters were already chosen with good care. However, when looking for peak performance, it would be reasonable to compare different configurations. Natural starting points would be to:\n","1. Increasing the input length\n","2. Change the learning rate or use a dynamic rate adaption\n","3. Try different batch sizes\n","\n","I'd expect to see some further but very marginal improvement from these steps."]},{"cell_type":"markdown","metadata":{"id":"vtpQKGwN78Cm"},"source":["### Evaluation \n","\n","Was this all worth it? Let's find out:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cr7Q2oMRWc1p","executionInfo":{"status":"ok","timestamp":1617726439903,"user_tz":-120,"elapsed":165647,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}},"outputId":"ac18e636-e6c4-4765-ee5c-5c439c813a76"},"source":["# predict on test set\n","pred = model.predict(test, batch_size=BATCH_SIZE, verbose=2, use_multiprocessing=True)"],"execution_count":66,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["2/2 - 14s\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4sglQo24Zeki","executionInfo":{"status":"ok","timestamp":1617726439906,"user_tz":-120,"elapsed":165644,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}},"outputId":"46625a9d-35c5-431d-cca9-8765e5bbb15c"},"source":["np.argmax(pred, axis=-1)"],"execution_count":67,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n","       0, 0, 0, 0, 0, 0, 0, 0])"]},"metadata":{"tags":[]},"execution_count":67}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QR5Tr86Yf3zr","executionInfo":{"status":"ok","timestamp":1617726439908,"user_tz":-120,"elapsed":165640,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}},"outputId":"cba0b24c-a476-4ba3-ee2f-668c0c6ed3c6"},"source":["# Load best model from Checkpoint\n","# model = load_model(PATH_GDRIVE_TMP+\"BERT.h5\", compile=False)\n","pred_class = np.argmax(pred, axis=-1)\n","report = metrics.classification_report(test_labels, pred_class)\n","print(report)"],"execution_count":68,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       0.69      0.98      0.81        45\n","           1       0.50      0.16      0.24        19\n","           2       0.50      0.20      0.29        10\n","\n","    accuracy                           0.66        74\n","   macro avg       0.56      0.45      0.44        74\n","weighted avg       0.61      0.66      0.59        74\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"mgEzkcGZG_dY"},"source":["Let's recap our previous results: In [the first part]({filename}/doctors_nlp1.ipynb) we used a traditional classification method and achieved a decent macro f1-score of `0.9`. In [part two]({filename}/doctors_nlp1.ipynb), we improved the score to `0.93` using a LSTM neural network and FastText word embeddings. For our harder to predict class 1 (bad ratings), we had a precision of `0.86` and recall of `0.89`.  \n","Compared to that, our BERT approach is a significant improvement. We increase the macro f1 to `0.94` while getting a decent improvement in both, the precision and recall for class 1 . You might be fooled by the small increase of the absolute numbers and wonder why I'm talking about \"big improvement\". Well, we really need to put this into relation. The better a model already performs, the harder it gets to squeeze out further improvements. An increase from a f1 of `0.6` to `0.7` is usually easier to achieve and less impressive than an improvement from `0.95` to `0.97`. Think \"pareto principle\" and \"decreasing marginal returns\"! \n"]}]}