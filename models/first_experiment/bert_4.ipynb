{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"TPU","colab":{"name":"bert_4.ipynb","provenance":[{"file_id":"1qVhqdk4oMU4ccCZv-3sOsRml29QQQYWn","timestamp":1618827479918},{"file_id":"1_FiC6xBCQ4mbGPUHtQxMvpDpIkocY2zh","timestamp":1617733360575},{"file_id":"1WU_w9Sai4W2GnmHFJgseysOmusUDZdCl","timestamp":1617726626656},{"file_id":"1CzRinqR8Ua2sw0ghLFsovCSlp8VlYnak","timestamp":1617058182082},{"file_id":"https://github.com/mc51/blog_posts/blob/master/doctors_nlp3.ipynb","timestamp":1617030468564}],"collapsed_sections":[],"toc_visible":true,"machine_shape":"hm"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"widgets":{"application/vnd.jupyter.widget-state+json":{"7322cb917a8244b49a49e77ef4642344":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_a0782a7d753c4936810f0c6d0c6998eb","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_b137c1e61af947d39917eed41af3d0cc","IPY_MODEL_5067212ef93d4db9ba8025ceb60548a3"]}},"a0782a7d753c4936810f0c6d0c6998eb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"b137c1e61af947d39917eed41af3d0cc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_f005f22eb6a644fba046fb46ad855804","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":254728,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":254728,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ee33280a7cc647fabb09c68bd7cfb4b0"}},"5067212ef93d4db9ba8025ceb60548a3":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ec681b4cd03746ddbf8505afb6b35ad7","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 255k/255k [00:00&lt;00:00, 1.79MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_649a92ceaf9d462aa7f8a25ccf372d8b"}},"f005f22eb6a644fba046fb46ad855804":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"ee33280a7cc647fabb09c68bd7cfb4b0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ec681b4cd03746ddbf8505afb6b35ad7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"649a92ceaf9d462aa7f8a25ccf372d8b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f93869880b43482a9df9bc58debbd5eb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_1b8e63d233954b2f86030ae6afc61e41","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_aaf28adc4de54ae990b4cc7673916546","IPY_MODEL_29e6db18078648149d294f30bec9c2d2"]}},"1b8e63d233954b2f86030ae6afc61e41":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"aaf28adc4de54ae990b4cc7673916546":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_2b7a0838974e46ff9c1c17ea6734982b","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":29,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":29,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8bc41e4c597241ab90012d26e0588af4"}},"29e6db18078648149d294f30bec9c2d2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9396bb938ec04745bcc8c8b2062d4dd0","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 29.0/29.0 [00:00&lt;00:00, 71.0B/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_84e6edc442dc42c2a9c68cdef9c35326"}},"2b7a0838974e46ff9c1c17ea6734982b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"8bc41e4c597241ab90012d26e0588af4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9396bb938ec04745bcc8c8b2062d4dd0":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"84e6edc442dc42c2a9c68cdef9c35326":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"22f4e5c3d126415fbe6c96d44306454a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_30edb99eeee84061b4e96dadae269f71","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_aa55f0c869774007af37c6f7b9dde7be","IPY_MODEL_5c7daff03e6a4577ade74a827c828864"]}},"30edb99eeee84061b4e96dadae269f71":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"aa55f0c869774007af37c6f7b9dde7be":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_90ec4248f1da437485cb2566491bea3a","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":485115,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":485115,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f461eccf81874a1da46188c9b1d5fc47"}},"5c7daff03e6a4577ade74a827c828864":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2706a6999e71419e882de8f2e9c38c07","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 485k/485k [00:00&lt;00:00, 2.80MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_269a4186f6514138ac167ce0a56801a2"}},"90ec4248f1da437485cb2566491bea3a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"f461eccf81874a1da46188c9b1d5fc47":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2706a6999e71419e882de8f2e9c38c07":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"269a4186f6514138ac167ce0a56801a2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c3d503cf6680437ab678be805fb86512":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_410e44d9adfd461bbef3be1b29afa63e","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_88dcaedc3f294fdbaa85ac749dabafb1","IPY_MODEL_4881421cd7fb41b4998c53ca27cba5f9"]}},"410e44d9adfd461bbef3be1b29afa63e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"88dcaedc3f294fdbaa85ac749dabafb1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_13798ad541ab4c9fb15cacb6bf654d5c","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":433,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":433,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a87a0dcdd3cd49dab1b353eca4945779"}},"4881421cd7fb41b4998c53ca27cba5f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_47db99a9bd474ca8b1d9acad45c9505c","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 433/433 [00:00&lt;00:00, 2.95kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_8c82a03e074a4ec8965eea011d7afad0"}},"13798ad541ab4c9fb15cacb6bf654d5c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a87a0dcdd3cd49dab1b353eca4945779":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"47db99a9bd474ca8b1d9acad45c9505c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"8c82a03e074a4ec8965eea011d7afad0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"544fc2b7e6994bf489eaaf6677fa1d61":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_0d4fb462f7e743a7ae1779ef14793abc","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_758549778e9544589acd846174e69eeb","IPY_MODEL_2bc5eecaee6e48b281e0b4164de066f9"]}},"0d4fb462f7e743a7ae1779ef14793abc":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"758549778e9544589acd846174e69eeb":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3df1a9d1474842ebb66ba54930d628fe","_dom_classes":[],"description":"Downloading: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":532854392,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":532854392,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_a1b2742fd0d8474fa3e6d6557d85ef48"}},"2bc5eecaee6e48b281e0b4164de066f9":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_5a6d66ceea254423a1b892b7a79ff926","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 533M/533M [00:13&lt;00:00, 40.7MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_699a4cdb360c480bac1f63c549e88a13"}},"3df1a9d1474842ebb66ba54930d628fe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"a1b2742fd0d8474fa3e6d6557d85ef48":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"5a6d66ceea254423a1b892b7a79ff926":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"699a4cdb360c480bac1f63c549e88a13":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r-JKjIUr5Frz","executionInfo":{"status":"ok","timestamp":1618995068040,"user_tz":-120,"elapsed":27403,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}},"outputId":"83d3a93a-1f57-482a-c68d-42faf5e68885"},"source":["# Needed on Google Colab\n","import os\n","if os.environ.get('COLAB_GPU', False):\n","    !pip install -U transformers\n","    from google.colab import drive\n","    drive.mount(\"/content/drive\")"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d8/b2/57495b5309f09fa501866e225c84532d1fd89536ea62406b2181933fb418/transformers-4.5.1-py3-none-any.whl (2.1MB)\n","\u001b[K     |████████████████████████████████| 2.1MB 6.8MB/s \n","\u001b[?25hCollecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n","\u001b[K     |████████████████████████████████| 901kB 37.9MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n","Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n","Collecting tokenizers<0.11,>=0.10.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/04/5b870f26a858552025a62f1649c20d29d2672c02ff3c3fb4c688ca46467a/tokenizers-0.10.2-cp37-cp37m-manylinux2010_x86_64.whl (3.3MB)\n","\u001b[K     |████████████████████████████████| 3.3MB 56.7MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n","Requirement already satisfied, skipping upgrade: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n","Requirement already satisfied, skipping upgrade: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (3.10.1)\n","Requirement already satisfied, skipping upgrade: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n","Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n","Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n","Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied, skipping upgrade: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n","Requirement already satisfied, skipping upgrade: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n","Installing collected packages: sacremoses, tokenizers, transformers\n","Successfully installed sacremoses-0.0.45 tokenizers-0.10.2 transformers-4.5.1\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fYFC1iYJuQEZ","executionInfo":{"status":"ok","timestamp":1618995074904,"user_tz":-120,"elapsed":4279,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}},"outputId":"7521f4a8-eba4-4b12-9802-dc2f5a333106"},"source":["import nltk\n","import re\n","import pickle\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import tensorflow as tf\n","from datetime import datetime\n","from sklearn import metrics\n","from sklearn.model_selection import train_test_split\n","from nltk.stem.snowball import SnowballStemmer\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","import warnings\n","\n","pd.options.display.max_colwidth = 6000\n","pd.options.display.max_rows = 400\n","np.set_printoptions(suppress=True)\n","warnings.filterwarnings(\"ignore\")\n","print(tf.__version__)"],"execution_count":2,"outputs":[{"output_type":"stream","text":["2.4.1\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"14VeTB-gu72U"},"source":["Executing this on Colab will make sure that our model runs on a TPU if available and falls back to GPU / CPU otherwise:"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nDBKQm8j_Meg","executionInfo":{"status":"ok","timestamp":1618995085202,"user_tz":-120,"elapsed":9168,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}},"outputId":"db208842-8c1e-4e70-aa33-5b82d9854c64"},"source":["# Try to run on TPU if available\n","# Detect hardware, return appropriate distribution strategy\n","try:\n","    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n","    print(\"Running on TPU \", tpu.cluster_spec().as_dict()[\"worker\"])\n","except ValueError:\n","    tpu = None\n","\n","if tpu:\n","    tf.config.experimental_connect_to_cluster(tpu)\n","    tf.tpu.experimental.initialize_tpu_system(tpu)\n","    strategy = tf.distribute.experimental.TPUStrategy(tpu)\n","else:\n","    strategy = tf.distribute.get_strategy()\n","print(\"REPLICAS: \", strategy.num_replicas_in_sync)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Running on TPU  ['10.88.20.58:8470']\n","INFO:tensorflow:Initializing the TPU system: grpc://10.88.20.58:8470\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Initializing the TPU system: grpc://10.88.20.58:8470\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Clearing out eager caches\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Finished initializing TPU system.\n","WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:Found TPU system:\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores: 8\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Workers: 1\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stdout"},{"output_type":"stream","text":["INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"],"name":"stderr"},{"output_type":"stream","text":["REPLICAS:  8\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"OqiD4dLhv1UK","executionInfo":{"status":"ok","timestamp":1618995085204,"user_tz":-120,"elapsed":5155,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}}},"source":["# store current path and download and extract data there\n","CURR_PATH = !pwd"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"zxTJmxYsSGRM","executionInfo":{"status":"ok","timestamp":1618995085204,"user_tz":-120,"elapsed":5059,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}}},"source":["# PARAMETERS\n","PATH_DATA = CURR_PATH[0]\n","PATH_GDRIVE_TMP = \"/content/drive/MyDrive/tmp/\"  # Google Drive"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"_ds8eLyeQ-qf","executionInfo":{"status":"ok","timestamp":1618995085472,"user_tz":-120,"elapsed":4789,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}},"outputId":"38a6eaf5-5a37-4cec-bc57-e0830e651109"},"source":["# read data from csv\n","data = pd.read_csv(PATH_GDRIVE_TMP + \"only_lockdown.csv\", sep='\\t', header=None, skiprows=[0])\n","\n","# Create binary grade, class 1-2 or 5-6  = good or bad\n","data[\"opinion_integer\"] = 0\n","data.loc[data[6] == '-', \"opinion_integer\"] = 0\n","data.loc[data[6] == 'o', \"opinion_integer\"] = 1\n","data.loc[data[6] == '+', \"opinion_integer\"] = 2\n","\n","data.head(6)"],"execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>0</th>\n","      <th>1</th>\n","      <th>2</th>\n","      <th>3</th>\n","      <th>4</th>\n","      <th>5</th>\n","      <th>6</th>\n","      <th>7</th>\n","      <th>8</th>\n","      <th>9</th>\n","      <th>10</th>\n","      <th>11</th>\n","      <th>12</th>\n","      <th>13</th>\n","      <th>opinion_integer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>-</td>\n","      <td>x</td>\n","      <td>x</td>\n","      <td>x</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>29137</td>\n","      <td>2020_03_15</td>\n","      <td>16</td>\n","      <td>NEOS</td>\n","      <td>Abgeordneter Josef Schellhorn (NEOS)</td>\n","      <td>False</td>\n","      <td>Das heißt, diese Planbarkeit ist jetzt gar nicht machbar – für Sie nicht –, nur die Unternehmer kommen mit dieser Unplanbarkeit gar nicht zurecht, weil dieser Lockdown ja jetzt nur für eine Woche bestimmt ist.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>-</td>\n","      <td>x</td>\n","      <td>-</td>\n","      <td>x</td>\n","      <td>x</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>31054</td>\n","      <td>2020_03_20</td>\n","      <td>19</td>\n","      <td>NEOS</td>\n","      <td>Abgeordnete Mag. Beate Meinl-Reisinger, MES (NEOS)</td>\n","      <td>False</td>\n","      <td>Wie und wann schaffen wir es, aus diesem Lockdown wieder herauszukommen, ohne die Gesundheit der Menschen in Österreich oder auch europaweit aufs Spiel zu setzen?</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>-</td>\n","      <td>#</td>\n","      <td>#+</td>\n","      <td>-</td>\n","      <td>x</td>\n","      <td>-</td>\n","      <td>-</td>\n","      <td>32973</td>\n","      <td>2020_04_03</td>\n","      <td>22</td>\n","      <td>ÖVP</td>\n","      <td>Abgeordneter August Wöginger (ÖVP)</td>\n","      <td>True</td>\n","      <td>Kickl hat am 13. März von einem Lockdown gesprochen – also alles zudrehen, nichts geht mehr in diesem Land.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>+</td>\n","      <td>x</td>\n","      <td>+</td>\n","      <td>x</td>\n","      <td>x</td>\n","      <td>+</td>\n","      <td>+</td>\n","      <td>34265</td>\n","      <td>2020_04_03</td>\n","      <td>22</td>\n","      <td>NEOS</td>\n","      <td>Abgeordnete Dipl.-Ing. Karin Doppelbauer (NEOS)</td>\n","      <td>False</td>\n","      <td>Ich möchte gleich zu Beginn eines klarstellen, damit es keine Missverständnisse gibt: Ja, der Lockdown war richtig.</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>+</td>\n","      <td>x</td>\n","      <td>x</td>\n","      <td>x</td>\n","      <td>o</td>\n","      <td>o</td>\n","      <td>-</td>\n","      <td>34269</td>\n","      <td>2020_04_03</td>\n","      <td>22</td>\n","      <td>NEOS</td>\n","      <td>Abgeordnete Dipl.-Ing. Karin Doppelbauer (NEOS)</td>\n","      <td>False</td>\n","      <td>Lassen Sie mich aber mit dem Gemeinsamen beginnen: Was das Ziel betrifft, sind wir uns ja alle einig: Es geht um nichts Geringeres als das Einpendeln unserer Volks­wirtschaft auf ein Level, wie es vor der Krise war, oder, wenn Sie so wollen, wenn man jetzt den Lockdown schrittweise lockert, dass dann das Wirtschaftssystem eigentlich genauso aussieht, wie es vor der Krise war.</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>+</td>\n","      <td>x</td>\n","      <td>x</td>\n","      <td>x</td>\n","      <td>+s</td>\n","      <td>o</td>\n","      <td>o</td>\n","      <td>34709</td>\n","      <td>2020_04_03</td>\n","      <td>22</td>\n","      <td>NEOS</td>\n","      <td>Abgeordnete Mag. Martina Künsberg Sarre (NEOS)</td>\n","      <td>False</td>\n","      <td>Regelmäßige begleitende Datenerhe­bun­gen in dieser Phase des Lockdowns, in der Lehrer_innen, Schüler_innen und Eltern auf digitales Unterrichten und Lernen absolut angewiesen sind, können einen wesent­lichen Beitrag für eine effiziente Digitalisierung des Bildungssystems in der Zukunft leisten.</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   0  ... opinion_integer\n","0  -  ...               0\n","1  -  ...               0\n","2  -  ...               0\n","3  +  ...               2\n","4  +  ...               0\n","5  +  ...               1\n","\n","[6 rows x 15 columns]"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ikzWTxAASFZM","executionInfo":{"status":"ok","timestamp":1618995086423,"user_tz":-120,"elapsed":4572,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}},"outputId":"bca7572d-873a-4eff-a5e8-895052358d29"},"source":["nltk.download(\"stopwords\")\n","nltk.download(\"punkt\")\n","stemmer = SnowballStemmer(\"german\")\n","stop_words = set(stopwords.words(\"german\"))\n","\n","\n","def clean_text(text, for_embedding=False):\n","    \"\"\"\n","        - remove any html tags (< /br> often found)\n","        - Keep only ASCII + European Chars and whitespace, no digits\n","        - remove single letter chars\n","        - convert all whitespaces (tabs etc.) to single wspace\n","        if not for embedding (but e.g. tdf-idf):\n","        - all lowercase\n","        - remove stopwords, punctuation and stemm\n","    \"\"\"\n","    RE_WSPACE = re.compile(r\"\\s+\", re.IGNORECASE)\n","    RE_TAGS = re.compile(r\"<[^>]+>\")\n","    RE_ASCII = re.compile(r\"[^A-Za-zÀ-ž ]\", re.IGNORECASE)\n","    RE_SINGLECHAR = re.compile(r\"\\b[A-Za-zÀ-ž]\\b\", re.IGNORECASE)\n","    if for_embedding:\n","        # Keep punctuation\n","        RE_ASCII = re.compile(r\"[^A-Za-zÀ-ž,.!? ]\", re.IGNORECASE)\n","        RE_SINGLECHAR = re.compile(r\"\\b[A-Za-zÀ-ž,.!?]\\b\", re.IGNORECASE)\n","\n","    text = re.sub(RE_TAGS, \" \", text)\n","    text = re.sub(RE_ASCII, \" \", text)\n","    text = re.sub(RE_SINGLECHAR, \" \", text)\n","    text = re.sub(RE_WSPACE, \" \", text)\n","\n","    word_tokens = word_tokenize(text)\n","    words_tokens_lower = [word.lower() for word in word_tokens]\n","\n","    if for_embedding:\n","        # no stemming, lowering and punctuation / stop words removal\n","        words_filtered = word_tokens\n","    else:\n","        words_filtered = [\n","            stemmer.stem(word) for word in words_tokens_lower if word not in stop_words\n","        ]\n","\n","    text_clean = \" \".join(words_filtered)\n","    return text_clean"],"execution_count":7,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8YJgw-JPSnWD","executionInfo":{"status":"ok","timestamp":1618995087488,"user_tz":-120,"elapsed":2347,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}},"outputId":"edd5deef-2627-428d-fd46-83236a3e22e9"},"source":["%%time\n","# Clean Comments\n","data[\"comment_clean\"] = data.loc[data[13].str.len() > 20, 13]\n","data[\"comment_clean\"] = data[\"comment_clean\"].map(\n","    lambda x: clean_text(x, for_embedding=True) if isinstance(x, str) else x\n",")"],"execution_count":8,"outputs":[{"output_type":"stream","text":["CPU times: user 152 ms, sys: 2.53 ms, total: 154 ms\n","Wall time: 170 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bqglg5EmV9No","executionInfo":{"status":"ok","timestamp":1618995087490,"user_tz":-120,"elapsed":2239,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}}},"source":["# Drop Missing\n","data = data.dropna(axis=\"index\", subset=[\"opinion_integer\", \"comment_clean\"]).reset_index(\n","    drop=True\n",")\n","data = data[[\"comment_clean\", \"opinion_integer\"]]\n","data.columns = [\"text\", \"label\"]\n","data.head(2)\n","data.to_csv(PATH_GDRIVE_TMP + \"only_lockdown_pp.csv\", index=False)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"id":"5rjlq1zLrOEO","executionInfo":{"status":"ok","timestamp":1618995089543,"user_tz":-120,"elapsed":771,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}}},"source":["def split_df(df, split_number):\n","    return df[:split_number], df[split_number:]\n","\n","def corpus_split(holdback_per_class):\n","    train = pd.DataFrame()\n","    test = pd.DataFrame()\n","\n","    for i in range(3):\n","        rows_with_class = data[data['label'] == i]\n","        rows_with_class = rows_with_class.sample(frac=1).reset_index(drop=True)\n","        l, r = split_df(rows_with_class, holdback_per_class)\n","        train = train.append(r, ignore_index=True)\n","        test = test.append(l, ignore_index=True)\n","\n","    train = train.sample(frac=1).reset_index(drop=True)\n","    test = test.sample(frac=1).reset_index(drop=True)\n","\n","    train_x = train['pp_text'].tolist()\n","    test_x = test['pp_text'].tolist()\n","    train_y = train['label'].tolist()\n","    test_y = test['label'].tolist()\n","\n","    return train_x, test_x, train_y, test_y"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"z3PI8aNr76jc","executionInfo":{"status":"ok","timestamp":1618995092828,"user_tz":-120,"elapsed":488,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}}},"source":["# skip pre processing if done before\n","#data = pd.read_csv(PATH_GDRIVE_TMP + \"only_lockdown_pp.csv\")"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"J7tt6I3g5r1k","colab":{"base_uri":"https://localhost:8080/","height":165,"referenced_widgets":["7322cb917a8244b49a49e77ef4642344","a0782a7d753c4936810f0c6d0c6998eb","b137c1e61af947d39917eed41af3d0cc","5067212ef93d4db9ba8025ceb60548a3","f005f22eb6a644fba046fb46ad855804","ee33280a7cc647fabb09c68bd7cfb4b0","ec681b4cd03746ddbf8505afb6b35ad7","649a92ceaf9d462aa7f8a25ccf372d8b","f93869880b43482a9df9bc58debbd5eb","1b8e63d233954b2f86030ae6afc61e41","aaf28adc4de54ae990b4cc7673916546","29e6db18078648149d294f30bec9c2d2","2b7a0838974e46ff9c1c17ea6734982b","8bc41e4c597241ab90012d26e0588af4","9396bb938ec04745bcc8c8b2062d4dd0","84e6edc442dc42c2a9c68cdef9c35326","22f4e5c3d126415fbe6c96d44306454a","30edb99eeee84061b4e96dadae269f71","aa55f0c869774007af37c6f7b9dde7be","5c7daff03e6a4577ade74a827c828864","90ec4248f1da437485cb2566491bea3a","f461eccf81874a1da46188c9b1d5fc47","2706a6999e71419e882de8f2e9c38c07","269a4186f6514138ac167ce0a56801a2"]},"executionInfo":{"status":"ok","timestamp":1618995094755,"user_tz":-120,"elapsed":2298,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}},"outputId":"da2495b8-7cf9-44df-b607-bf1d0931c596"},"source":["# this will download and initialize the pre trained tokenizer\n","from transformers import BertTokenizer, TFBertModel\n","\n","tokenizer = BertTokenizer.from_pretrained(\"bert-base-german-cased\")"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7322cb917a8244b49a49e77ef4642344","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=254728.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"f93869880b43482a9df9bc58debbd5eb","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=29.0, style=ProgressStyle(description_w…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"22f4e5c3d126415fbe6c96d44306454a","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=485115.0, style=ProgressStyle(descripti…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"V1V50oOB5rUV","executionInfo":{"status":"ok","timestamp":1618995100295,"user_tz":-120,"elapsed":1001,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}}},"source":["MAXLEN = 128\n","#MAXLEN = 256\n","\n","def preprocess_text(data):\n","    \"\"\" take texts and prepare as input features for BERT \n","    \"\"\"\n","    input_ids = []\n","    # For every sentence...\n","    for comment in data:\n","        encoded_sent = tokenizer.encode_plus(\n","            text=comment,\n","            add_special_tokens=True,  # Add `[CLS]` and `[SEP]`\n","            max_length=MAXLEN,  # Max length to truncate/pad\n","            pad_to_max_length=True,  # Pad sentence to max length\n","            return_attention_mask=False,  # attention mask not needed for our task\n","        )\n","        # Add the outputs to the lists\n","        input_ids.append(encoded_sent.get(\"input_ids\"))\n","    return input_ids"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HLK7nNldJgaj","executionInfo":{"status":"ok","timestamp":1618995104661,"user_tz":-120,"elapsed":1029,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}},"outputId":"6c623a58-ec08-4661-b7a2-9760b2568ea8"},"source":["%%time\n","import pickle\n","\n","input_ids = preprocess_text(data[\"text\"])\n","# tokenization takes quite long\n","# we can save the result and load it quickly via pickle\n","pickle.dump(input_ids, open(PATH_GDRIVE_TMP + \"input_ids_lockdown.pkl\", \"wb\"))\n","# input_ids = pickle.load(open(PATH_GDRIVE_TMP+\"/input_ids.pkl\", \"rb\"))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"],"name":"stderr"},{"output_type":"stream","text":["CPU times: user 436 ms, sys: 0 ns, total: 436 ms\n","Wall time: 610 ms\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"TQ-qI-I5bZYr"},"source":["# Here Begins the Repeatable Code"]},{"cell_type":"code","metadata":{"id":"VQcG-40V6REl","executionInfo":{"status":"ok","timestamp":1618995108893,"user_tz":-120,"elapsed":522,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}}},"source":["# Set Model Parameters\n","MAXLEN = MAXLEN\n","BATCH_SIZE_PER_REPLICA = 8\n","BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n","EPOCHS = 20\n","LEARNING_RATE = 1e-5\n","DATA_LENGTH = len(data)"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"huw96xaoPwHG","executionInfo":{"status":"ok","timestamp":1618995109204,"user_tz":-120,"elapsed":718,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}}},"source":["# Stop training when validation acc starts dropping\n","# Save checkpoint of model each period\n","now = datetime.now().strftime(\"%Y-%m-%d_%H%M\")\n","# Create callbacks\n","callbacks = [\n","    tf.keras.callbacks.EarlyStopping(\n","        monitor=\"val_loss\", verbose=1, patience=EPOCHS, restore_best_weights=True\n","    ),\n","    # tf.keras.callbacks.ModelCheckpoint(\n","    #    PATH_GDRIVE_TMP + now + \"_Model_{epoch:02d}_{val_loss:.4f}.h5\",\n","    #    monitor=\"val_loss\",\n","    #    save_best_only=True,\n","    #    verbose=1,\n","    # ),\n","]"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"aP7WVslnIabU","executionInfo":{"status":"ok","timestamp":1618995111707,"user_tz":-120,"elapsed":398,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}}},"source":["def build_model(transformer, max_len=MAXLEN):\n","    \"\"\" add binary classification to pretrained model\n","    \"\"\"\n","    input_word_ids = tf.keras.layers.Input(\n","        shape=(max_len,), dtype=tf.int32, name=\"input_word_ids\"\n","    )\n","    sequence_output = transformer(input_word_ids)[0]\n","    cls_token = sequence_output[:, 0, :]\n","    out = tf.keras.layers.Dense(3, activation=\"sigmoid\")(cls_token)\n","    model = tf.keras.models.Model(inputs=input_word_ids, outputs=out)\n","    model.compile(\n","        tf.keras.optimizers.Adam(lr=LEARNING_RATE),\n","        loss=\"sparse_categorical_crossentropy\",\n","        metrics=[\"accuracy\"],\n","    )\n","    return model"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"id":"h2Su9FAcNWiK","executionInfo":{"status":"ok","timestamp":1618995111966,"user_tz":-120,"elapsed":538,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}}},"source":["def create_dataset(\n","    data_tuple,\n","    epochs=EPOCHS,\n","    batch_size=BATCH_SIZE,\n","    buffer_size=DATA_LENGTH,\n","    train=False,\n","):\n","    dataset = tf.data.Dataset.from_tensor_slices(data_tuple)\n","    if train:\n","        dataset = dataset.shuffle(\n","            buffer_size=buffer_size, reshuffle_each_iteration=True\n","        ).repeat(epochs)\n","    dataset = dataset.batch(batch_size)\n","    return dataset"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"wTfcj3Ihcse7","executionInfo":{"status":"ok","timestamp":1618995119404,"user_tz":-120,"elapsed":1212,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}}},"source":["from collections import Counter"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"-cXRZs4cs_pm","executionInfo":{"status":"ok","timestamp":1618995119698,"user_tz":-120,"elapsed":1154,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}}},"source":["data['pp_text'] = preprocess_text(data['text'])"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"W0WbgTBKuE1Q","executionInfo":{"status":"ok","timestamp":1618995122217,"user_tz":-120,"elapsed":665,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}}},"source":["train_ids, test_ids, train_labels, test_labels = corpus_split(20)"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["c3d503cf6680437ab678be805fb86512","410e44d9adfd461bbef3be1b29afa63e","88dcaedc3f294fdbaa85ac749dabafb1","4881421cd7fb41b4998c53ca27cba5f9","13798ad541ab4c9fb15cacb6bf654d5c","a87a0dcdd3cd49dab1b353eca4945779","47db99a9bd474ca8b1d9acad45c9505c","8c82a03e074a4ec8965eea011d7afad0","544fc2b7e6994bf489eaaf6677fa1d61","0d4fb462f7e743a7ae1779ef14793abc","758549778e9544589acd846174e69eeb","2bc5eecaee6e48b281e0b4164de066f9","3df1a9d1474842ebb66ba54930d628fe","a1b2742fd0d8474fa3e6d6557d85ef48","5a6d66ceea254423a1b892b7a79ff926","699a4cdb360c480bac1f63c549e88a13"]},"id":"qULIMZU0bi9I","executionInfo":{"status":"error","timestamp":1619008184964,"user_tz":-120,"elapsed":591214,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}},"outputId":"71a9ff63-ec9b-4de0-b73f-9546dcb5e670"},"source":["runs = 500\n","accuracies = []\n","for i in range(runs):\n","  train_ids, test_ids, train_labels, test_labels = corpus_split(20)\n","  train = create_dataset((train_ids, train_labels), buffer_size=len(train_ids), train=True)\n","  test = create_dataset((test_ids, test_labels), buffer_size=len(test_ids))\n","  with strategy.scope():\n","    transformer_layers = TFBertModel.from_pretrained(\"bert-base-german-cased\")\n","    model = build_model(transformer_layers, max_len=MAXLEN)\n","  train_counts = Counter(train_labels)\n","  num_in_largest_class = max(train_counts.values())\n","  class_weights = {k: num_in_largest_class / train_counts[k] for k in train_counts.keys()}\n","\n","  # Train using appropriate steps per epochs (go through all train data in an epoch)\n","  steps_per_epoch = int(np.floor((len(train_ids) / BATCH_SIZE)))\n","  hist = model.fit(\n","    train,\n","    batch_size=BATCH_SIZE,\n","    epochs=EPOCHS,\n","    steps_per_epoch=steps_per_epoch,\n","    validation_data=test,\n","    verbose=1,\n","    class_weight = class_weights,\n","    callbacks=callbacks,\n","  )\n","\n","  # Evaluate\n","  pred = model.predict(test, batch_size=BATCH_SIZE, verbose=2, use_multiprocessing=True)\n","  pred_class = np.argmax(pred, axis=-1)\n","  report = metrics.classification_report(test_labels, pred_class, output_dict=True)\n","  acc = report['accuracy']\n","  accuracies.append(acc)\n","  with open(PATH_GDRIVE_TMP + 'bert_4_accuracies.txt', 'a+') as f:\n","    f.write(\"%s\\n\" % acc)"],"execution_count":22,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"c3d503cf6680437ab678be805fb86512","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"544fc2b7e6994bf489eaaf6677fa1d61","version_major":2,"version_minor":0},"text/plain":["HBox(children=(FloatProgress(value=0.0, description='Downloading', max=532854392.0, style=ProgressStyle(descri…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n","WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fb04eaa5d70>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fb04eaa5d70>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fb04eaa5d70>> and will run it as-is.\n","Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n","Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7fb065687c20> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7fb065687c20> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n","WARNING: AutoGraph could not transform <function wrap at 0x7fb065687c20> and will run it as-is.\n","Cause: while/else statement not yet supported\n","To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.5268 - accuracy: 0.2729WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 82s 2s/step - loss: 2.5166 - accuracy: 0.2711 - val_loss: 1.2928 - val_accuracy: 0.3333\n","Epoch 2/20\n","6/6 [==============================] - 1s 247ms/step - loss: 2.1311 - accuracy: 0.2787 - val_loss: 1.0694 - val_accuracy: 0.4333\n","Epoch 3/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.9350 - accuracy: 0.4352 - val_loss: 1.1083 - val_accuracy: 0.4500\n","Epoch 4/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.9298 - accuracy: 0.2882 - val_loss: 1.0700 - val_accuracy: 0.4000\n","Epoch 5/20\n","6/6 [==============================] - 1s 242ms/step - loss: 1.8233 - accuracy: 0.4964 - val_loss: 1.0666 - val_accuracy: 0.4333\n","Epoch 6/20\n","6/6 [==============================] - 2s 347ms/step - loss: 1.8553 - accuracy: 0.3833 - val_loss: 1.0751 - val_accuracy: 0.3667\n","Epoch 7/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.8293 - accuracy: 0.5135 - val_loss: 1.1193 - val_accuracy: 0.4167\n","Epoch 8/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.8209 - accuracy: 0.4125 - val_loss: 1.0951 - val_accuracy: 0.4333\n","Epoch 9/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.7823 - accuracy: 0.5029 - val_loss: 1.1037 - val_accuracy: 0.3667\n","Epoch 10/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.7445 - accuracy: 0.5670 - val_loss: 1.0767 - val_accuracy: 0.4667\n","Epoch 11/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.4228 - accuracy: 0.6317 - val_loss: 1.1220 - val_accuracy: 0.3833\n","Epoch 12/20\n","6/6 [==============================] - 1s 253ms/step - loss: 1.3949 - accuracy: 0.6907 - val_loss: 1.1302 - val_accuracy: 0.4333\n","Epoch 13/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.2788 - accuracy: 0.7126 - val_loss: 1.1727 - val_accuracy: 0.4000\n","Epoch 14/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.2947 - accuracy: 0.6818 - val_loss: 1.1707 - val_accuracy: 0.4000\n","Epoch 15/20\n","6/6 [==============================] - 1s 252ms/step - loss: 0.8709 - accuracy: 0.8886 - val_loss: 1.2137 - val_accuracy: 0.4500\n","Epoch 16/20\n","6/6 [==============================] - 1s 243ms/step - loss: 0.7251 - accuracy: 0.8627 - val_loss: 1.2691 - val_accuracy: 0.4333\n","Epoch 17/20\n","6/6 [==============================] - 1s 242ms/step - loss: 0.5563 - accuracy: 0.9156 - val_loss: 1.2977 - val_accuracy: 0.5000\n","Epoch 18/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.5200 - accuracy: 0.9292 - val_loss: 1.3005 - val_accuracy: 0.4833\n","Epoch 19/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.3897 - accuracy: 0.9461 - val_loss: 1.4129 - val_accuracy: 0.4500\n","Epoch 20/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.3075 - accuracy: 0.9640 - val_loss: 1.4111 - val_accuracy: 0.4333\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_1/bert/pooler/dense/kernel:0', 'tf_bert_model_1/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.7534 - accuracy: 0.3635WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 82s 2s/step - loss: 2.7226 - accuracy: 0.3658 - val_loss: 1.2771 - val_accuracy: 0.4667\n","Epoch 2/20\n","6/6 [==============================] - 1s 240ms/step - loss: 2.1881 - accuracy: 0.2887 - val_loss: 1.1011 - val_accuracy: 0.3667\n","Epoch 3/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.8949 - accuracy: 0.3459 - val_loss: 1.0891 - val_accuracy: 0.3667\n","Epoch 4/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.8590 - accuracy: 0.4463 - val_loss: 1.0886 - val_accuracy: 0.3833\n","Epoch 5/20\n","6/6 [==============================] - 1s 242ms/step - loss: 1.8367 - accuracy: 0.3254 - val_loss: 1.0964 - val_accuracy: 0.4167\n","Epoch 6/20\n","6/6 [==============================] - 1s 242ms/step - loss: 1.7754 - accuracy: 0.5046 - val_loss: 1.0903 - val_accuracy: 0.4333\n","Epoch 7/20\n","6/6 [==============================] - 1s 241ms/step - loss: 1.7295 - accuracy: 0.4809 - val_loss: 1.1255 - val_accuracy: 0.3667\n","Epoch 8/20\n","6/6 [==============================] - 1s 239ms/step - loss: 1.6702 - accuracy: 0.5869 - val_loss: 1.1096 - val_accuracy: 0.4333\n","Epoch 9/20\n","6/6 [==============================] - 1s 239ms/step - loss: 1.4607 - accuracy: 0.5479 - val_loss: 1.1715 - val_accuracy: 0.4333\n","Epoch 10/20\n","6/6 [==============================] - 1s 240ms/step - loss: 1.4001 - accuracy: 0.6541 - val_loss: 1.1007 - val_accuracy: 0.5000\n","Epoch 11/20\n","6/6 [==============================] - 1s 241ms/step - loss: 1.3466 - accuracy: 0.6819 - val_loss: 1.0696 - val_accuracy: 0.4833\n","Epoch 12/20\n","6/6 [==============================] - 1s 254ms/step - loss: 0.9932 - accuracy: 0.7994 - val_loss: 1.0998 - val_accuracy: 0.5000\n","Epoch 13/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.9004 - accuracy: 0.8097 - val_loss: 1.0543 - val_accuracy: 0.4667\n","Epoch 14/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.7664 - accuracy: 0.8724 - val_loss: 1.1124 - val_accuracy: 0.5000\n","Epoch 15/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.5580 - accuracy: 0.8722 - val_loss: 1.1210 - val_accuracy: 0.5333\n","Epoch 16/20\n","6/6 [==============================] - 1s 242ms/step - loss: 0.4505 - accuracy: 0.9052 - val_loss: 1.2363 - val_accuracy: 0.5000\n","Epoch 17/20\n","6/6 [==============================] - 1s 240ms/step - loss: 0.3283 - accuracy: 0.9218 - val_loss: 1.2587 - val_accuracy: 0.4833\n","Epoch 18/20\n","6/6 [==============================] - 1s 241ms/step - loss: 0.2354 - accuracy: 0.9650 - val_loss: 1.3008 - val_accuracy: 0.4833\n","Epoch 19/20\n","6/6 [==============================] - 1s 239ms/step - loss: 0.1873 - accuracy: 0.9822 - val_loss: 1.2528 - val_accuracy: 0.5333\n","Epoch 20/20\n","6/6 [==============================] - 1s 238ms/step - loss: 0.1905 - accuracy: 0.9728 - val_loss: 1.3807 - val_accuracy: 0.4833\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_2/bert/pooler/dense/kernel:0', 'tf_bert_model_2/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 3.2938 - accuracy: 0.2994WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 84s 2s/step - loss: 3.2124 - accuracy: 0.3125 - val_loss: 1.2469 - val_accuracy: 0.3167\n","Epoch 2/20\n","6/6 [==============================] - 1s 240ms/step - loss: 2.1276 - accuracy: 0.2566 - val_loss: 1.2606 - val_accuracy: 0.3500\n","Epoch 3/20\n","6/6 [==============================] - 1s 242ms/step - loss: 1.8555 - accuracy: 0.4954 - val_loss: 1.2115 - val_accuracy: 0.3333\n","Epoch 4/20\n","6/6 [==============================] - 1s 248ms/step - loss: 2.0112 - accuracy: 0.2463 - val_loss: 1.2053 - val_accuracy: 0.3333\n","Epoch 5/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.8941 - accuracy: 0.5066 - val_loss: 1.1467 - val_accuracy: 0.3833\n","Epoch 6/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.9013 - accuracy: 0.2467 - val_loss: 1.1630 - val_accuracy: 0.3833\n","Epoch 7/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.9042 - accuracy: 0.4837 - val_loss: 1.1182 - val_accuracy: 0.4167\n","Epoch 8/20\n","6/6 [==============================] - 1s 240ms/step - loss: 1.8321 - accuracy: 0.3038 - val_loss: 1.1620 - val_accuracy: 0.3500\n","Epoch 9/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.9655 - accuracy: 0.4002 - val_loss: 1.1113 - val_accuracy: 0.3833\n","Epoch 10/20\n","6/6 [==============================] - 1s 242ms/step - loss: 1.8059 - accuracy: 0.5416 - val_loss: 1.0932 - val_accuracy: 0.4000\n","Epoch 11/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.7765 - accuracy: 0.4094 - val_loss: 1.0923 - val_accuracy: 0.4333\n","Epoch 12/20\n","6/6 [==============================] - 1s 240ms/step - loss: 1.6033 - accuracy: 0.5875 - val_loss: 1.0703 - val_accuracy: 0.4167\n","Epoch 13/20\n","6/6 [==============================] - 1s 242ms/step - loss: 1.6715 - accuracy: 0.4676 - val_loss: 1.0393 - val_accuracy: 0.5500\n","Epoch 14/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.3780 - accuracy: 0.6176 - val_loss: 1.1045 - val_accuracy: 0.4333\n","Epoch 15/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.3499 - accuracy: 0.6411 - val_loss: 1.0471 - val_accuracy: 0.5500\n","Epoch 16/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.1947 - accuracy: 0.7403 - val_loss: 1.0765 - val_accuracy: 0.5833\n","Epoch 17/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.9449 - accuracy: 0.7881 - val_loss: 1.1816 - val_accuracy: 0.4333\n","Epoch 18/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.8730 - accuracy: 0.8321 - val_loss: 1.1573 - val_accuracy: 0.5000\n","Epoch 19/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.7377 - accuracy: 0.8205 - val_loss: 1.3272 - val_accuracy: 0.5333\n","Epoch 20/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.6586 - accuracy: 0.8611 - val_loss: 1.4105 - val_accuracy: 0.5000\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_3/bert/pooler/dense/kernel:0', 'tf_bert_model_3/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_3/bert/pooler/dense/kernel:0', 'tf_bert_model_3/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_3/bert/pooler/dense/kernel:0', 'tf_bert_model_3/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_3/bert/pooler/dense/kernel:0', 'tf_bert_model_3/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.8117 - accuracy: 0.3752WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 85s 2s/step - loss: 2.7801 - accuracy: 0.3696 - val_loss: 1.3403 - val_accuracy: 0.3167\n","Epoch 2/20\n","6/6 [==============================] - 2s 386ms/step - loss: 2.1688 - accuracy: 0.4870 - val_loss: 1.3068 - val_accuracy: 0.3833\n","Epoch 3/20\n","6/6 [==============================] - 1s 245ms/step - loss: 2.0013 - accuracy: 0.3280 - val_loss: 1.1317 - val_accuracy: 0.3667\n","Epoch 4/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.9735 - accuracy: 0.4838 - val_loss: 1.1112 - val_accuracy: 0.4500\n","Epoch 5/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.8565 - accuracy: 0.3621 - val_loss: 1.0829 - val_accuracy: 0.4333\n","Epoch 6/20\n","6/6 [==============================] - 1s 241ms/step - loss: 1.7106 - accuracy: 0.6159 - val_loss: 1.0924 - val_accuracy: 0.4667\n","Epoch 7/20\n","6/6 [==============================] - 1s 242ms/step - loss: 1.6195 - accuracy: 0.5115 - val_loss: 1.0630 - val_accuracy: 0.4167\n","Epoch 8/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.5579 - accuracy: 0.6458 - val_loss: 1.0744 - val_accuracy: 0.4833\n","Epoch 9/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.3754 - accuracy: 0.6625 - val_loss: 1.0306 - val_accuracy: 0.4833\n","Epoch 10/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.1696 - accuracy: 0.7233 - val_loss: 1.0721 - val_accuracy: 0.4833\n","Epoch 11/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.0536 - accuracy: 0.7585 - val_loss: 1.0277 - val_accuracy: 0.5333\n","Epoch 12/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.9353 - accuracy: 0.7810 - val_loss: 1.0932 - val_accuracy: 0.5000\n","Epoch 13/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.7764 - accuracy: 0.8724 - val_loss: 1.0022 - val_accuracy: 0.5500\n","Epoch 14/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.6640 - accuracy: 0.8233 - val_loss: 1.1466 - val_accuracy: 0.5000\n","Epoch 15/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.6242 - accuracy: 0.8910 - val_loss: 1.0040 - val_accuracy: 0.6000\n","Epoch 16/20\n","6/6 [==============================] - 1s 241ms/step - loss: 0.4223 - accuracy: 0.9433 - val_loss: 1.1371 - val_accuracy: 0.5333\n","Epoch 17/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.3504 - accuracy: 0.9563 - val_loss: 1.0320 - val_accuracy: 0.5667\n","Epoch 18/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.2386 - accuracy: 0.9651 - val_loss: 1.1420 - val_accuracy: 0.5000\n","Epoch 19/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.2444 - accuracy: 0.9861 - val_loss: 1.1077 - val_accuracy: 0.5500\n","Epoch 20/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.1591 - accuracy: 0.9836 - val_loss: 1.1870 - val_accuracy: 0.5500\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_4/bert/pooler/dense/kernel:0', 'tf_bert_model_4/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_4/bert/pooler/dense/kernel:0', 'tf_bert_model_4/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_4/bert/pooler/dense/kernel:0', 'tf_bert_model_4/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_4/bert/pooler/dense/kernel:0', 'tf_bert_model_4/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.5741 - accuracy: 0.3994WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 87s 2s/step - loss: 2.5686 - accuracy: 0.4012 - val_loss: 1.1108 - val_accuracy: 0.4167\n","Epoch 2/20\n","6/6 [==============================] - 1s 243ms/step - loss: 2.1569 - accuracy: 0.2583 - val_loss: 1.0983 - val_accuracy: 0.4333\n","Epoch 3/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.9279 - accuracy: 0.4893 - val_loss: 1.0951 - val_accuracy: 0.4333\n","Epoch 4/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.9644 - accuracy: 0.3823 - val_loss: 1.1091 - val_accuracy: 0.4000\n","Epoch 5/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.8501 - accuracy: 0.3552 - val_loss: 1.0815 - val_accuracy: 0.4500\n","Epoch 6/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.7996 - accuracy: 0.5357 - val_loss: 1.0970 - val_accuracy: 0.4333\n","Epoch 7/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.7069 - accuracy: 0.4252 - val_loss: 1.0459 - val_accuracy: 0.4167\n","Epoch 8/20\n","6/6 [==============================] - 1s 240ms/step - loss: 1.8008 - accuracy: 0.5636 - val_loss: 1.0523 - val_accuracy: 0.4667\n","Epoch 9/20\n","6/6 [==============================] - 1s 241ms/step - loss: 1.4919 - accuracy: 0.6940 - val_loss: 0.9939 - val_accuracy: 0.5500\n","Epoch 10/20\n","6/6 [==============================] - 2s 423ms/step - loss: 1.3700 - accuracy: 0.6219 - val_loss: 1.0329 - val_accuracy: 0.5167\n","Epoch 11/20\n","6/6 [==============================] - 1s 240ms/step - loss: 1.1964 - accuracy: 0.7243 - val_loss: 0.9598 - val_accuracy: 0.5000\n","Epoch 12/20\n","6/6 [==============================] - 1s 241ms/step - loss: 1.1187 - accuracy: 0.6946 - val_loss: 1.1052 - val_accuracy: 0.5667\n","Epoch 13/20\n","6/6 [==============================] - 1s 255ms/step - loss: 1.1088 - accuracy: 0.7844 - val_loss: 0.9731 - val_accuracy: 0.5667\n","Epoch 14/20\n","6/6 [==============================] - 1s 243ms/step - loss: 0.8364 - accuracy: 0.8346 - val_loss: 1.1412 - val_accuracy: 0.5667\n","Epoch 15/20\n","6/6 [==============================] - 1s 243ms/step - loss: 0.6731 - accuracy: 0.8757 - val_loss: 1.0149 - val_accuracy: 0.6000\n","Epoch 16/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.4157 - accuracy: 0.9594 - val_loss: 1.1183 - val_accuracy: 0.6333\n","Epoch 17/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.3491 - accuracy: 0.9438 - val_loss: 1.0938 - val_accuracy: 0.5000\n","Epoch 18/20\n","6/6 [==============================] - 1s 240ms/step - loss: 0.2873 - accuracy: 0.9735 - val_loss: 1.2729 - val_accuracy: 0.5667\n","Epoch 19/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.2652 - accuracy: 0.9736 - val_loss: 1.1494 - val_accuracy: 0.6000\n","Epoch 20/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.1786 - accuracy: 0.9866 - val_loss: 1.2824 - val_accuracy: 0.6167\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9c2a50e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9c2a50e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_5/bert/pooler/dense/kernel:0', 'tf_bert_model_5/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_5/bert/pooler/dense/kernel:0', 'tf_bert_model_5/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_5/bert/pooler/dense/kernel:0', 'tf_bert_model_5/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_5/bert/pooler/dense/kernel:0', 'tf_bert_model_5/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.6376 - accuracy: 0.2941WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 86s 2s/step - loss: 2.6125 - accuracy: 0.2927 - val_loss: 1.0912 - val_accuracy: 0.3833\n","Epoch 2/20\n","6/6 [==============================] - 1s 244ms/step - loss: 2.1030 - accuracy: 0.3263 - val_loss: 1.0712 - val_accuracy: 0.3833\n","Epoch 3/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.8733 - accuracy: 0.4572 - val_loss: 1.0612 - val_accuracy: 0.3500\n","Epoch 4/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.9850 - accuracy: 0.4367 - val_loss: 1.0838 - val_accuracy: 0.4500\n","Epoch 5/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.8899 - accuracy: 0.5469 - val_loss: 1.1433 - val_accuracy: 0.4500\n","Epoch 6/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.7622 - accuracy: 0.4193 - val_loss: 1.1291 - val_accuracy: 0.3667\n","Epoch 7/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.7594 - accuracy: 0.5763 - val_loss: 1.0979 - val_accuracy: 0.4500\n","Epoch 8/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.6171 - accuracy: 0.4964 - val_loss: 1.1453 - val_accuracy: 0.4000\n","Epoch 9/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.4613 - accuracy: 0.6705 - val_loss: 1.0822 - val_accuracy: 0.4500\n","Epoch 10/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.4587 - accuracy: 0.5714 - val_loss: 1.1705 - val_accuracy: 0.4333\n","Epoch 11/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.1321 - accuracy: 0.7983 - val_loss: 1.1177 - val_accuracy: 0.5000\n","Epoch 12/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.9979 - accuracy: 0.7624 - val_loss: 1.1367 - val_accuracy: 0.5333\n","Epoch 13/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.9185 - accuracy: 0.8464 - val_loss: 1.1713 - val_accuracy: 0.5000\n","Epoch 14/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.7294 - accuracy: 0.8145 - val_loss: 1.2806 - val_accuracy: 0.4667\n","Epoch 15/20\n","6/6 [==============================] - 1s 242ms/step - loss: 0.6658 - accuracy: 0.8892 - val_loss: 1.2292 - val_accuracy: 0.5167\n","Epoch 16/20\n","6/6 [==============================] - 1s 242ms/step - loss: 0.5030 - accuracy: 0.8958 - val_loss: 1.3812 - val_accuracy: 0.5000\n","Epoch 17/20\n","6/6 [==============================] - 2s 456ms/step - loss: 0.3768 - accuracy: 0.9513 - val_loss: 1.3012 - val_accuracy: 0.5833\n","Epoch 18/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.3044 - accuracy: 0.9510 - val_loss: 1.4165 - val_accuracy: 0.5500\n","Epoch 19/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.2149 - accuracy: 0.9785 - val_loss: 1.4271 - val_accuracy: 0.5833\n","Epoch 20/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.1887 - accuracy: 0.9773 - val_loss: 1.5455 - val_accuracy: 0.5167\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faee9a1d440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faee9a1d440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_6/bert/pooler/dense/kernel:0', 'tf_bert_model_6/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_6/bert/pooler/dense/kernel:0', 'tf_bert_model_6/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_6/bert/pooler/dense/kernel:0', 'tf_bert_model_6/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_6/bert/pooler/dense/kernel:0', 'tf_bert_model_6/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.6135 - accuracy: 0.3776WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 86s 2s/step - loss: 2.5898 - accuracy: 0.3769 - val_loss: 1.1374 - val_accuracy: 0.3833\n","Epoch 2/20\n","6/6 [==============================] - 1s 242ms/step - loss: 1.9781 - accuracy: 0.4028 - val_loss: 1.0739 - val_accuracy: 0.4667\n","Epoch 3/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.9956 - accuracy: 0.3749 - val_loss: 1.2005 - val_accuracy: 0.3333\n","Epoch 4/20\n","6/6 [==============================] - 1s 243ms/step - loss: 2.0817 - accuracy: 0.2372 - val_loss: 1.1216 - val_accuracy: 0.5000\n","Epoch 5/20\n","6/6 [==============================] - 1s 245ms/step - loss: 2.1457 - accuracy: 0.3990 - val_loss: 1.0712 - val_accuracy: 0.4667\n","Epoch 6/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.8241 - accuracy: 0.3439 - val_loss: 1.0426 - val_accuracy: 0.5167\n","Epoch 7/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.7132 - accuracy: 0.5707 - val_loss: 1.0190 - val_accuracy: 0.5167\n","Epoch 8/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.6813 - accuracy: 0.5010 - val_loss: 1.0307 - val_accuracy: 0.5167\n","Epoch 9/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.5702 - accuracy: 0.5722 - val_loss: 1.0322 - val_accuracy: 0.4667\n","Epoch 10/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.4048 - accuracy: 0.6728 - val_loss: 0.9863 - val_accuracy: 0.5333\n","Epoch 11/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.3504 - accuracy: 0.6698 - val_loss: 1.0032 - val_accuracy: 0.5667\n","Epoch 12/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.1475 - accuracy: 0.7285 - val_loss: 1.0532 - val_accuracy: 0.5333\n","Epoch 13/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.8812 - accuracy: 0.8453 - val_loss: 1.0605 - val_accuracy: 0.5500\n","Epoch 14/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.7997 - accuracy: 0.8239 - val_loss: 1.1400 - val_accuracy: 0.5000\n","Epoch 15/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.6495 - accuracy: 0.9103 - val_loss: 1.0834 - val_accuracy: 0.4667\n","Epoch 16/20\n","6/6 [==============================] - 1s 239ms/step - loss: 0.4694 - accuracy: 0.8952 - val_loss: 1.3474 - val_accuracy: 0.5167\n","Epoch 17/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.4027 - accuracy: 0.9588 - val_loss: 1.1457 - val_accuracy: 0.5333\n","Epoch 18/20\n","6/6 [==============================] - 1s 243ms/step - loss: 0.3011 - accuracy: 0.9647 - val_loss: 1.4049 - val_accuracy: 0.5000\n","Epoch 19/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.2229 - accuracy: 0.9894 - val_loss: 1.2490 - val_accuracy: 0.4667\n","Epoch 20/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.1784 - accuracy: 0.9975 - val_loss: 1.3246 - val_accuracy: 0.4667\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faee1e2d4d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:7 out of the last 7 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faee1e2d4d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_7/bert/pooler/dense/kernel:0', 'tf_bert_model_7/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_7/bert/pooler/dense/kernel:0', 'tf_bert_model_7/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_7/bert/pooler/dense/kernel:0', 'tf_bert_model_7/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_7/bert/pooler/dense/kernel:0', 'tf_bert_model_7/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.2233 - accuracy: 0.3438WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 87s 2s/step - loss: 2.2207 - accuracy: 0.3404 - val_loss: 1.1580 - val_accuracy: 0.3667\n","Epoch 2/20\n","6/6 [==============================] - 1s 243ms/step - loss: 2.0481 - accuracy: 0.3677 - val_loss: 1.0958 - val_accuracy: 0.4000\n","Epoch 3/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.9623 - accuracy: 0.3433 - val_loss: 1.0931 - val_accuracy: 0.4167\n","Epoch 4/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.8246 - accuracy: 0.4529 - val_loss: 1.0650 - val_accuracy: 0.4500\n","Epoch 5/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.7788 - accuracy: 0.4123 - val_loss: 1.0941 - val_accuracy: 0.4167\n","Epoch 6/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.7800 - accuracy: 0.5641 - val_loss: 1.0702 - val_accuracy: 0.4333\n","Epoch 7/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.6355 - accuracy: 0.5232 - val_loss: 1.0663 - val_accuracy: 0.4667\n","Epoch 8/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.5029 - accuracy: 0.6044 - val_loss: 1.0733 - val_accuracy: 0.4500\n","Epoch 9/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.3846 - accuracy: 0.6699 - val_loss: 1.0399 - val_accuracy: 0.5167\n","Epoch 10/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.1827 - accuracy: 0.7425 - val_loss: 1.0578 - val_accuracy: 0.5167\n","Epoch 11/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.0264 - accuracy: 0.7459 - val_loss: 1.1323 - val_accuracy: 0.5167\n","Epoch 12/20\n","6/6 [==============================] - 1s 242ms/step - loss: 0.8293 - accuracy: 0.8522 - val_loss: 1.1058 - val_accuracy: 0.5167\n","Epoch 13/20\n","6/6 [==============================] - 2s 433ms/step - loss: 0.7260 - accuracy: 0.8695 - val_loss: 1.2945 - val_accuracy: 0.5167\n","Epoch 14/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.5618 - accuracy: 0.9259 - val_loss: 1.0927 - val_accuracy: 0.5167\n","Epoch 15/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.4757 - accuracy: 0.8837 - val_loss: 1.4653 - val_accuracy: 0.5167\n","Epoch 16/20\n","6/6 [==============================] - 1s 241ms/step - loss: 0.3783 - accuracy: 0.9419 - val_loss: 1.1775 - val_accuracy: 0.5167\n","Epoch 17/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.3391 - accuracy: 0.9196 - val_loss: 1.5879 - val_accuracy: 0.4833\n","Epoch 18/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.2567 - accuracy: 0.9667 - val_loss: 1.3276 - val_accuracy: 0.5667\n","Epoch 19/20\n","6/6 [==============================] - 1s 242ms/step - loss: 0.2016 - accuracy: 0.9823 - val_loss: 1.5633 - val_accuracy: 0.4833\n","Epoch 20/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.1418 - accuracy: 0.9866 - val_loss: 1.3915 - val_accuracy: 0.5333\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9ee74b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:8 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9ee74b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_8/bert/pooler/dense/kernel:0', 'tf_bert_model_8/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_8/bert/pooler/dense/kernel:0', 'tf_bert_model_8/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_8/bert/pooler/dense/kernel:0', 'tf_bert_model_8/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_8/bert/pooler/dense/kernel:0', 'tf_bert_model_8/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.4286 - accuracy: 0.2916WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 87s 2s/step - loss: 2.4236 - accuracy: 0.2913 - val_loss: 1.2065 - val_accuracy: 0.3667\n","Epoch 2/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.9187 - accuracy: 0.3321 - val_loss: 1.1629 - val_accuracy: 0.3667\n","Epoch 3/20\n","6/6 [==============================] - 1s 249ms/step - loss: 2.0194 - accuracy: 0.4054 - val_loss: 1.1377 - val_accuracy: 0.3000\n","Epoch 4/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.9264 - accuracy: 0.3462 - val_loss: 1.1218 - val_accuracy: 0.3500\n","Epoch 5/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.7876 - accuracy: 0.4118 - val_loss: 1.0952 - val_accuracy: 0.3667\n","Epoch 6/20\n","6/6 [==============================] - 1s 251ms/step - loss: 1.7665 - accuracy: 0.4959 - val_loss: 1.1402 - val_accuracy: 0.3833\n","Epoch 7/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.7201 - accuracy: 0.4753 - val_loss: 1.1116 - val_accuracy: 0.3667\n","Epoch 8/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.6008 - accuracy: 0.5904 - val_loss: 1.1682 - val_accuracy: 0.3500\n","Epoch 9/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.4534 - accuracy: 0.5318 - val_loss: 1.1161 - val_accuracy: 0.3833\n","Epoch 10/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.3278 - accuracy: 0.6871 - val_loss: 1.1863 - val_accuracy: 0.4000\n","Epoch 11/20\n","6/6 [==============================] - 1s 253ms/step - loss: 1.2339 - accuracy: 0.7126 - val_loss: 1.1684 - val_accuracy: 0.4500\n","Epoch 12/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.0556 - accuracy: 0.7808 - val_loss: 1.2440 - val_accuracy: 0.4333\n","Epoch 13/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.8940 - accuracy: 0.8250 - val_loss: 1.2668 - val_accuracy: 0.4333\n","Epoch 14/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.7593 - accuracy: 0.8606 - val_loss: 1.2938 - val_accuracy: 0.4500\n","Epoch 15/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.5835 - accuracy: 0.8628 - val_loss: 1.4402 - val_accuracy: 0.4833\n","Epoch 16/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.4899 - accuracy: 0.9122 - val_loss: 1.4604 - val_accuracy: 0.4667\n","Epoch 17/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.3627 - accuracy: 0.9431 - val_loss: 1.5198 - val_accuracy: 0.4500\n","Epoch 18/20\n","6/6 [==============================] - 1s 252ms/step - loss: 0.2630 - accuracy: 0.9762 - val_loss: 1.5283 - val_accuracy: 0.4833\n","Epoch 19/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.1935 - accuracy: 0.9797 - val_loss: 1.6132 - val_accuracy: 0.4667\n","Epoch 20/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.2264 - accuracy: 0.9829 - val_loss: 1.5823 - val_accuracy: 0.5000\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faed8331170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:9 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faed8331170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 12s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_9/bert/pooler/dense/kernel:0', 'tf_bert_model_9/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_9/bert/pooler/dense/kernel:0', 'tf_bert_model_9/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_9/bert/pooler/dense/kernel:0', 'tf_bert_model_9/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_9/bert/pooler/dense/kernel:0', 'tf_bert_model_9/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.1667 - accuracy: 0.3992WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 85s 2s/step - loss: 2.1748 - accuracy: 0.4058 - val_loss: 1.2924 - val_accuracy: 0.3667\n","Epoch 2/20\n","6/6 [==============================] - 1s 248ms/step - loss: 2.2702 - accuracy: 0.2336 - val_loss: 1.1445 - val_accuracy: 0.3333\n","Epoch 3/20\n","6/6 [==============================] - 1s 247ms/step - loss: 2.0031 - accuracy: 0.5148 - val_loss: 1.0663 - val_accuracy: 0.4500\n","Epoch 4/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.8397 - accuracy: 0.3382 - val_loss: 1.0764 - val_accuracy: 0.4333\n","Epoch 5/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.8530 - accuracy: 0.4799 - val_loss: 1.0701 - val_accuracy: 0.3667\n","Epoch 6/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.8184 - accuracy: 0.5193 - val_loss: 1.0708 - val_accuracy: 0.4500\n","Epoch 7/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.7687 - accuracy: 0.4913 - val_loss: 1.0920 - val_accuracy: 0.4833\n","Epoch 8/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.6570 - accuracy: 0.5783 - val_loss: 1.0495 - val_accuracy: 0.4333\n","Epoch 9/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.4841 - accuracy: 0.5737 - val_loss: 1.1011 - val_accuracy: 0.5167\n","Epoch 10/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.4013 - accuracy: 0.6887 - val_loss: 1.0490 - val_accuracy: 0.5000\n","Epoch 11/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.4806 - accuracy: 0.6061 - val_loss: 1.0820 - val_accuracy: 0.5833\n","Epoch 12/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.1730 - accuracy: 0.7225 - val_loss: 1.0021 - val_accuracy: 0.5333\n","Epoch 13/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.9105 - accuracy: 0.8337 - val_loss: 1.1024 - val_accuracy: 0.5667\n","Epoch 14/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.8089 - accuracy: 0.8074 - val_loss: 1.1736 - val_accuracy: 0.5333\n","Epoch 15/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.6804 - accuracy: 0.8944 - val_loss: 1.1508 - val_accuracy: 0.5667\n","Epoch 16/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.5048 - accuracy: 0.9112 - val_loss: 1.2612 - val_accuracy: 0.5500\n","Epoch 17/20\n","6/6 [==============================] - 1s 243ms/step - loss: 0.3622 - accuracy: 0.9468 - val_loss: 1.3020 - val_accuracy: 0.5500\n","Epoch 18/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.3237 - accuracy: 0.9544 - val_loss: 1.5706 - val_accuracy: 0.4833\n","Epoch 19/20\n","6/6 [==============================] - 3s 483ms/step - loss: 0.2602 - accuracy: 0.9724 - val_loss: 1.3862 - val_accuracy: 0.5333\n","Epoch 20/20\n","6/6 [==============================] - 1s 252ms/step - loss: 0.1798 - accuracy: 0.9767 - val_loss: 1.5393 - val_accuracy: 0.5333\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:10 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faedd489e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:10 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faedd489e60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_10/bert/pooler/dense/kernel:0', 'tf_bert_model_10/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_10/bert/pooler/dense/kernel:0', 'tf_bert_model_10/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_10/bert/pooler/dense/kernel:0', 'tf_bert_model_10/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_10/bert/pooler/dense/kernel:0', 'tf_bert_model_10/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.4912 - accuracy: 0.3483WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 85s 2s/step - loss: 2.4836 - accuracy: 0.3458 - val_loss: 1.2535 - val_accuracy: 0.3833\n","Epoch 2/20\n","6/6 [==============================] - 1s 240ms/step - loss: 2.1222 - accuracy: 0.3477 - val_loss: 1.1534 - val_accuracy: 0.2833\n","Epoch 3/20\n","6/6 [==============================] - 2s 408ms/step - loss: 2.0382 - accuracy: 0.3969 - val_loss: 1.1333 - val_accuracy: 0.4000\n","Epoch 4/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.9426 - accuracy: 0.2697 - val_loss: 1.1278 - val_accuracy: 0.2833\n","Epoch 5/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.8866 - accuracy: 0.4589 - val_loss: 1.1462 - val_accuracy: 0.3667\n","Epoch 6/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.8588 - accuracy: 0.3547 - val_loss: 1.1047 - val_accuracy: 0.3500\n","Epoch 7/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.8472 - accuracy: 0.3167 - val_loss: 1.0562 - val_accuracy: 0.4333\n","Epoch 8/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.8812 - accuracy: 0.4711 - val_loss: 0.9983 - val_accuracy: 0.5500\n","Epoch 9/20\n","6/6 [==============================] - 1s 242ms/step - loss: 1.7419 - accuracy: 0.4761 - val_loss: 0.9925 - val_accuracy: 0.4667\n","Epoch 10/20\n","6/6 [==============================] - 1s 241ms/step - loss: 1.6005 - accuracy: 0.5853 - val_loss: 0.9924 - val_accuracy: 0.5333\n","Epoch 11/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.6277 - accuracy: 0.5783 - val_loss: 0.9728 - val_accuracy: 0.5167\n","Epoch 12/20\n","6/6 [==============================] - 1s 242ms/step - loss: 1.3631 - accuracy: 0.6857 - val_loss: 1.0030 - val_accuracy: 0.5167\n","Epoch 13/20\n","6/6 [==============================] - 1s 242ms/step - loss: 1.1625 - accuracy: 0.7578 - val_loss: 1.0065 - val_accuracy: 0.5167\n","Epoch 14/20\n","6/6 [==============================] - 1s 251ms/step - loss: 1.0200 - accuracy: 0.7948 - val_loss: 1.0324 - val_accuracy: 0.5000\n","Epoch 15/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.8376 - accuracy: 0.8185 - val_loss: 1.0700 - val_accuracy: 0.5167\n","Epoch 16/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.7059 - accuracy: 0.8905 - val_loss: 1.1383 - val_accuracy: 0.5167\n","Epoch 17/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.5185 - accuracy: 0.8946 - val_loss: 1.1972 - val_accuracy: 0.4333\n","Epoch 18/20\n","6/6 [==============================] - 1s 243ms/step - loss: 0.3559 - accuracy: 0.9493 - val_loss: 1.2112 - val_accuracy: 0.5167\n","Epoch 19/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.3624 - accuracy: 0.9361 - val_loss: 1.3400 - val_accuracy: 0.4167\n","Epoch 20/20\n","6/6 [==============================] - 1s 242ms/step - loss: 0.2434 - accuracy: 0.9698 - val_loss: 1.2920 - val_accuracy: 0.4500\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faec8fbcb90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faec8fbcb90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_11/bert/pooler/dense/kernel:0', 'tf_bert_model_11/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_11/bert/pooler/dense/kernel:0', 'tf_bert_model_11/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_11/bert/pooler/dense/kernel:0', 'tf_bert_model_11/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_11/bert/pooler/dense/kernel:0', 'tf_bert_model_11/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.8722 - accuracy: 0.3320WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 85s 2s/step - loss: 2.8332 - accuracy: 0.3371 - val_loss: 1.3166 - val_accuracy: 0.3333\n","Epoch 2/20\n","6/6 [==============================] - 1s 245ms/step - loss: 2.1897 - accuracy: 0.3060 - val_loss: 1.1958 - val_accuracy: 0.3333\n","Epoch 3/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.9257 - accuracy: 0.4883 - val_loss: 1.1383 - val_accuracy: 0.3833\n","Epoch 4/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.9725 - accuracy: 0.3016 - val_loss: 1.1581 - val_accuracy: 0.3167\n","Epoch 5/20\n","6/6 [==============================] - 2s 428ms/step - loss: 1.8567 - accuracy: 0.4616 - val_loss: 1.1174 - val_accuracy: 0.3667\n","Epoch 6/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.9293 - accuracy: 0.4034 - val_loss: 1.1195 - val_accuracy: 0.3333\n","Epoch 7/20\n","6/6 [==============================] - 1s 252ms/step - loss: 1.7224 - accuracy: 0.3942 - val_loss: 1.1772 - val_accuracy: 0.3833\n","Epoch 8/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.8329 - accuracy: 0.5220 - val_loss: 1.1409 - val_accuracy: 0.4000\n","Epoch 9/20\n","6/6 [==============================] - 1s 253ms/step - loss: 1.6407 - accuracy: 0.4799 - val_loss: 1.1526 - val_accuracy: 0.4333\n","Epoch 10/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.5711 - accuracy: 0.5446 - val_loss: 1.1567 - val_accuracy: 0.3833\n","Epoch 11/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.3576 - accuracy: 0.6181 - val_loss: 1.2387 - val_accuracy: 0.4000\n","Epoch 12/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.2173 - accuracy: 0.7396 - val_loss: 1.2356 - val_accuracy: 0.4167\n","Epoch 13/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.1827 - accuracy: 0.7215 - val_loss: 1.2230 - val_accuracy: 0.4333\n","Epoch 14/20\n","6/6 [==============================] - 1s 241ms/step - loss: 0.9106 - accuracy: 0.7993 - val_loss: 1.3701 - val_accuracy: 0.4667\n","Epoch 15/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.8406 - accuracy: 0.8038 - val_loss: 1.3306 - val_accuracy: 0.4833\n","Epoch 16/20\n","6/6 [==============================] - 1s 243ms/step - loss: 0.5979 - accuracy: 0.8538 - val_loss: 1.5760 - val_accuracy: 0.4000\n","Epoch 17/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.4790 - accuracy: 0.9098 - val_loss: 1.5495 - val_accuracy: 0.4333\n","Epoch 18/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.3629 - accuracy: 0.9508 - val_loss: 1.5036 - val_accuracy: 0.4833\n","Epoch 19/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.3276 - accuracy: 0.9194 - val_loss: 1.7407 - val_accuracy: 0.4167\n","Epoch 20/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.2723 - accuracy: 0.9568 - val_loss: 1.5853 - val_accuracy: 0.4667\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fada03be4d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fada03be4d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_12/bert/pooler/dense/kernel:0', 'tf_bert_model_12/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_12/bert/pooler/dense/kernel:0', 'tf_bert_model_12/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_12/bert/pooler/dense/kernel:0', 'tf_bert_model_12/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_12/bert/pooler/dense/kernel:0', 'tf_bert_model_12/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.6708 - accuracy: 0.3050WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 87s 2s/step - loss: 2.6718 - accuracy: 0.3057 - val_loss: 1.3980 - val_accuracy: 0.3333\n","Epoch 2/20\n","6/6 [==============================] - 1s 241ms/step - loss: 2.2034 - accuracy: 0.2112 - val_loss: 1.3083 - val_accuracy: 0.3000\n","Epoch 3/20\n","6/6 [==============================] - 1s 243ms/step - loss: 2.0501 - accuracy: 0.3950 - val_loss: 1.1883 - val_accuracy: 0.3333\n","Epoch 4/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.8968 - accuracy: 0.2442 - val_loss: 1.2073 - val_accuracy: 0.3667\n","Epoch 5/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.8788 - accuracy: 0.4949 - val_loss: 1.2243 - val_accuracy: 0.4167\n","Epoch 6/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.7426 - accuracy: 0.3976 - val_loss: 1.2251 - val_accuracy: 0.3500\n","Epoch 7/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.7428 - accuracy: 0.5571 - val_loss: 1.1896 - val_accuracy: 0.4000\n","Epoch 8/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.7139 - accuracy: 0.4070 - val_loss: 1.1843 - val_accuracy: 0.4333\n","Epoch 9/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.5618 - accuracy: 0.6250 - val_loss: 1.1674 - val_accuracy: 0.4667\n","Epoch 10/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.5279 - accuracy: 0.5431 - val_loss: 1.1557 - val_accuracy: 0.4833\n","Epoch 11/20\n","6/6 [==============================] - 2s 441ms/step - loss: 1.3990 - accuracy: 0.6708 - val_loss: 1.1726 - val_accuracy: 0.4667\n","Epoch 12/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.2689 - accuracy: 0.6403 - val_loss: 1.1933 - val_accuracy: 0.5667\n","Epoch 13/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.2148 - accuracy: 0.7464 - val_loss: 1.1430 - val_accuracy: 0.4667\n","Epoch 14/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.9221 - accuracy: 0.8268 - val_loss: 1.3570 - val_accuracy: 0.5500\n","Epoch 15/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.7273 - accuracy: 0.8363 - val_loss: 1.3567 - val_accuracy: 0.4333\n","Epoch 16/20\n","6/6 [==============================] - 1s 251ms/step - loss: 0.7773 - accuracy: 0.8306 - val_loss: 1.4086 - val_accuracy: 0.5500\n","Epoch 17/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.5317 - accuracy: 0.9286 - val_loss: 1.2051 - val_accuracy: 0.5500\n","Epoch 18/20\n","6/6 [==============================] - 1s 252ms/step - loss: 0.4002 - accuracy: 0.9302 - val_loss: 1.6445 - val_accuracy: 0.4833\n","Epoch 19/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.3363 - accuracy: 0.9615 - val_loss: 1.4863 - val_accuracy: 0.5000\n","Epoch 20/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.2552 - accuracy: 0.9596 - val_loss: 1.4609 - val_accuracy: 0.5000\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fada002b7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fada002b7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_13/bert/pooler/dense/kernel:0', 'tf_bert_model_13/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_13/bert/pooler/dense/kernel:0', 'tf_bert_model_13/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_13/bert/pooler/dense/kernel:0', 'tf_bert_model_13/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_13/bert/pooler/dense/kernel:0', 'tf_bert_model_13/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.4608 - accuracy: 0.3717WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 87s 2s/step - loss: 2.4512 - accuracy: 0.3703 - val_loss: 1.3186 - val_accuracy: 0.3333\n","Epoch 2/20\n","6/6 [==============================] - 1s 248ms/step - loss: 2.2260 - accuracy: 0.2899 - val_loss: 1.1822 - val_accuracy: 0.3500\n","Epoch 3/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.8637 - accuracy: 0.5020 - val_loss: 1.1513 - val_accuracy: 0.3667\n","Epoch 4/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.8679 - accuracy: 0.3016 - val_loss: 1.1719 - val_accuracy: 0.3667\n","Epoch 5/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.8786 - accuracy: 0.5526 - val_loss: 1.0710 - val_accuracy: 0.4333\n","Epoch 6/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.7516 - accuracy: 0.4564 - val_loss: 1.0569 - val_accuracy: 0.4500\n","Epoch 7/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.6308 - accuracy: 0.6022 - val_loss: 1.1383 - val_accuracy: 0.4000\n","Epoch 8/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.5699 - accuracy: 0.7029 - val_loss: 1.0352 - val_accuracy: 0.4500\n","Epoch 9/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.4352 - accuracy: 0.6305 - val_loss: 1.1063 - val_accuracy: 0.4500\n","Epoch 10/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.3441 - accuracy: 0.7359 - val_loss: 1.0617 - val_accuracy: 0.4667\n","Epoch 11/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.1327 - accuracy: 0.7477 - val_loss: 1.1224 - val_accuracy: 0.4667\n","Epoch 12/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.9667 - accuracy: 0.7990 - val_loss: 1.1503 - val_accuracy: 0.4500\n","Epoch 13/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.8419 - accuracy: 0.8379 - val_loss: 1.1842 - val_accuracy: 0.4833\n","Epoch 14/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.6990 - accuracy: 0.8644 - val_loss: 1.2299 - val_accuracy: 0.5000\n","Epoch 15/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.5221 - accuracy: 0.9430 - val_loss: 1.3315 - val_accuracy: 0.4667\n","Epoch 16/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.4696 - accuracy: 0.9274 - val_loss: 1.2214 - val_accuracy: 0.5333\n","Epoch 17/20\n","6/6 [==============================] - 1s 242ms/step - loss: 0.3944 - accuracy: 0.9430 - val_loss: 1.5988 - val_accuracy: 0.4333\n","Epoch 18/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.3126 - accuracy: 0.9715 - val_loss: 1.3106 - val_accuracy: 0.4833\n","Epoch 19/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.2240 - accuracy: 0.9664 - val_loss: 1.6489 - val_accuracy: 0.4500\n","Epoch 20/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.1782 - accuracy: 0.9869 - val_loss: 1.4813 - val_accuracy: 0.5000\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faecb5f6560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faecb5f6560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 12s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_14/bert/pooler/dense/kernel:0', 'tf_bert_model_14/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_14/bert/pooler/dense/kernel:0', 'tf_bert_model_14/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_14/bert/pooler/dense/kernel:0', 'tf_bert_model_14/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_14/bert/pooler/dense/kernel:0', 'tf_bert_model_14/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.5806 - accuracy: 0.2578WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 85s 2s/step - loss: 2.5460 - accuracy: 0.2638 - val_loss: 1.2551 - val_accuracy: 0.3333\n","Epoch 2/20\n","6/6 [==============================] - 1s 242ms/step - loss: 1.9673 - accuracy: 0.3292 - val_loss: 1.3028 - val_accuracy: 0.3000\n","Epoch 3/20\n","6/6 [==============================] - 1s 244ms/step - loss: 2.0913 - accuracy: 0.3057 - val_loss: 1.1946 - val_accuracy: 0.3500\n","Epoch 4/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.8761 - accuracy: 0.4968 - val_loss: 1.1998 - val_accuracy: 0.3667\n","Epoch 5/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.9027 - accuracy: 0.4275 - val_loss: 1.1678 - val_accuracy: 0.4000\n","Epoch 6/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.8288 - accuracy: 0.4311 - val_loss: 1.1804 - val_accuracy: 0.4000\n","Epoch 7/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.6622 - accuracy: 0.5095 - val_loss: 1.1843 - val_accuracy: 0.3167\n","Epoch 8/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.6787 - accuracy: 0.5274 - val_loss: 1.1514 - val_accuracy: 0.3833\n","Epoch 9/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.5803 - accuracy: 0.5703 - val_loss: 1.0924 - val_accuracy: 0.4000\n","Epoch 10/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.4368 - accuracy: 0.5843 - val_loss: 1.1736 - val_accuracy: 0.4500\n","Epoch 11/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.3306 - accuracy: 0.6765 - val_loss: 1.0752 - val_accuracy: 0.4167\n","Epoch 12/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.0252 - accuracy: 0.7338 - val_loss: 1.2467 - val_accuracy: 0.4500\n","Epoch 13/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.9807 - accuracy: 0.7496 - val_loss: 1.1642 - val_accuracy: 0.4333\n","Epoch 14/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.7639 - accuracy: 0.8391 - val_loss: 1.2757 - val_accuracy: 0.4667\n","Epoch 15/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.6523 - accuracy: 0.8221 - val_loss: 1.4352 - val_accuracy: 0.4500\n","Epoch 16/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.4513 - accuracy: 0.8919 - val_loss: 1.4530 - val_accuracy: 0.4667\n","Epoch 17/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.3532 - accuracy: 0.9336 - val_loss: 1.6164 - val_accuracy: 0.4833\n","Epoch 18/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.2578 - accuracy: 0.9762 - val_loss: 1.5466 - val_accuracy: 0.4167\n","Epoch 19/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.2035 - accuracy: 0.9807 - val_loss: 1.8093 - val_accuracy: 0.4500\n","Epoch 20/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.1629 - accuracy: 0.9870 - val_loss: 1.7344 - val_accuracy: 0.4500\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faf9fec4440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faf9fec4440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 12s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_15/bert/pooler/dense/kernel:0', 'tf_bert_model_15/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_15/bert/pooler/dense/kernel:0', 'tf_bert_model_15/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_15/bert/pooler/dense/kernel:0', 'tf_bert_model_15/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_15/bert/pooler/dense/kernel:0', 'tf_bert_model_15/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.7911 - accuracy: 0.2776WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 85s 2s/step - loss: 2.7376 - accuracy: 0.2819 - val_loss: 1.1838 - val_accuracy: 0.3333\n","Epoch 2/20\n","6/6 [==============================] - 1s 240ms/step - loss: 2.0380 - accuracy: 0.3401 - val_loss: 1.2219 - val_accuracy: 0.3833\n","Epoch 3/20\n","6/6 [==============================] - 1s 242ms/step - loss: 1.9073 - accuracy: 0.4360 - val_loss: 1.1021 - val_accuracy: 0.3333\n","Epoch 4/20\n","6/6 [==============================] - 1s 239ms/step - loss: 1.8490 - accuracy: 0.3453 - val_loss: 1.0935 - val_accuracy: 0.3500\n","Epoch 5/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.8699 - accuracy: 0.5060 - val_loss: 1.1010 - val_accuracy: 0.3500\n","Epoch 6/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.7589 - accuracy: 0.5068 - val_loss: 1.0887 - val_accuracy: 0.4167\n","Epoch 7/20\n","6/6 [==============================] - 1s 241ms/step - loss: 1.5331 - accuracy: 0.5924 - val_loss: 1.0829 - val_accuracy: 0.4000\n","Epoch 8/20\n","6/6 [==============================] - 1s 240ms/step - loss: 1.4745 - accuracy: 0.6573 - val_loss: 1.1168 - val_accuracy: 0.4000\n","Epoch 9/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.3319 - accuracy: 0.6969 - val_loss: 1.1251 - val_accuracy: 0.4167\n","Epoch 10/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.1342 - accuracy: 0.6840 - val_loss: 1.2292 - val_accuracy: 0.4167\n","Epoch 11/20\n","6/6 [==============================] - 1s 242ms/step - loss: 1.0931 - accuracy: 0.7979 - val_loss: 1.2504 - val_accuracy: 0.3833\n","Epoch 12/20\n","6/6 [==============================] - 1s 242ms/step - loss: 0.8816 - accuracy: 0.8093 - val_loss: 1.3539 - val_accuracy: 0.4333\n","Epoch 13/20\n","6/6 [==============================] - 1s 240ms/step - loss: 0.6541 - accuracy: 0.8841 - val_loss: 1.4526 - val_accuracy: 0.4000\n","Epoch 14/20\n","6/6 [==============================] - 1s 241ms/step - loss: 0.5260 - accuracy: 0.9084 - val_loss: 1.6554 - val_accuracy: 0.4833\n","Epoch 15/20\n","6/6 [==============================] - 1s 240ms/step - loss: 0.4866 - accuracy: 0.9214 - val_loss: 1.5369 - val_accuracy: 0.4167\n","Epoch 16/20\n","6/6 [==============================] - 1s 239ms/step - loss: 0.3463 - accuracy: 0.9538 - val_loss: 1.6538 - val_accuracy: 0.4500\n","Epoch 17/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.2770 - accuracy: 0.9565 - val_loss: 1.7298 - val_accuracy: 0.4333\n","Epoch 18/20\n","6/6 [==============================] - 1s 237ms/step - loss: 0.2147 - accuracy: 0.9831 - val_loss: 1.8351 - val_accuracy: 0.4500\n","Epoch 19/20\n","6/6 [==============================] - 1s 240ms/step - loss: 0.1738 - accuracy: 0.9758 - val_loss: 1.8353 - val_accuracy: 0.4333\n","Epoch 20/20\n","6/6 [==============================] - 2s 478ms/step - loss: 0.1456 - accuracy: 0.9833 - val_loss: 1.8582 - val_accuracy: 0.4500\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faee9b903b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faee9b903b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_16/bert/pooler/dense/kernel:0', 'tf_bert_model_16/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_16/bert/pooler/dense/kernel:0', 'tf_bert_model_16/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_16/bert/pooler/dense/kernel:0', 'tf_bert_model_16/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_16/bert/pooler/dense/kernel:0', 'tf_bert_model_16/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.6583 - accuracy: 0.3439WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 86s 2s/step - loss: 2.6463 - accuracy: 0.3353 - val_loss: 1.1958 - val_accuracy: 0.3167\n","Epoch 2/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.9393 - accuracy: 0.4639 - val_loss: 1.1450 - val_accuracy: 0.3333\n","Epoch 3/20\n","6/6 [==============================] - 1s 241ms/step - loss: 2.0348 - accuracy: 0.3113 - val_loss: 1.1413 - val_accuracy: 0.3167\n","Epoch 4/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.8431 - accuracy: 0.3432 - val_loss: 1.1180 - val_accuracy: 0.3667\n","Epoch 5/20\n","6/6 [==============================] - 2s 416ms/step - loss: 1.9344 - accuracy: 0.4597 - val_loss: 1.0726 - val_accuracy: 0.4167\n","Epoch 6/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.7297 - accuracy: 0.4174 - val_loss: 1.0792 - val_accuracy: 0.4333\n","Epoch 7/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.7849 - accuracy: 0.5705 - val_loss: 1.0246 - val_accuracy: 0.4833\n","Epoch 8/20\n","6/6 [==============================] - 1s 242ms/step - loss: 1.5624 - accuracy: 0.4953 - val_loss: 1.0479 - val_accuracy: 0.5000\n","Epoch 9/20\n","6/6 [==============================] - 1s 251ms/step - loss: 1.5085 - accuracy: 0.6547 - val_loss: 0.9918 - val_accuracy: 0.5500\n","Epoch 10/20\n","6/6 [==============================] - 1s 242ms/step - loss: 1.2512 - accuracy: 0.7077 - val_loss: 1.0123 - val_accuracy: 0.5167\n","Epoch 11/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.1700 - accuracy: 0.7491 - val_loss: 1.0499 - val_accuracy: 0.4833\n","Epoch 12/20\n","6/6 [==============================] - 1s 252ms/step - loss: 0.9413 - accuracy: 0.7986 - val_loss: 1.0971 - val_accuracy: 0.4833\n","Epoch 13/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.8341 - accuracy: 0.8482 - val_loss: 1.1266 - val_accuracy: 0.5000\n","Epoch 14/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.7060 - accuracy: 0.8628 - val_loss: 1.2074 - val_accuracy: 0.4500\n","Epoch 15/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.5511 - accuracy: 0.9162 - val_loss: 1.2667 - val_accuracy: 0.4833\n","Epoch 16/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.3741 - accuracy: 0.9614 - val_loss: 1.2311 - val_accuracy: 0.4833\n","Epoch 17/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.3169 - accuracy: 0.9316 - val_loss: 1.4464 - val_accuracy: 0.4667\n","Epoch 18/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.2283 - accuracy: 0.9919 - val_loss: 1.3021 - val_accuracy: 0.4667\n","Epoch 19/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.1818 - accuracy: 0.9810 - val_loss: 1.4874 - val_accuracy: 0.4667\n","Epoch 20/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.1487 - accuracy: 0.9917 - val_loss: 1.4437 - val_accuracy: 0.4667\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9ba90290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9ba90290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_17/bert/pooler/dense/kernel:0', 'tf_bert_model_17/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_17/bert/pooler/dense/kernel:0', 'tf_bert_model_17/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_17/bert/pooler/dense/kernel:0', 'tf_bert_model_17/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_17/bert/pooler/dense/kernel:0', 'tf_bert_model_17/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.6749 - accuracy: 0.3562WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 88s 2s/step - loss: 2.6536 - accuracy: 0.3578 - val_loss: 1.0915 - val_accuracy: 0.3167\n","Epoch 2/20\n","6/6 [==============================] - 1s 247ms/step - loss: 2.0227 - accuracy: 0.2604 - val_loss: 1.1084 - val_accuracy: 0.4000\n","Epoch 3/20\n","6/6 [==============================] - 1s 252ms/step - loss: 2.0917 - accuracy: 0.3595 - val_loss: 1.0790 - val_accuracy: 0.4333\n","Epoch 4/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.9262 - accuracy: 0.3427 - val_loss: 1.0593 - val_accuracy: 0.4500\n","Epoch 5/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.8238 - accuracy: 0.3800 - val_loss: 1.0848 - val_accuracy: 0.3833\n","Epoch 6/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.9371 - accuracy: 0.4746 - val_loss: 1.0894 - val_accuracy: 0.4167\n","Epoch 7/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.9273 - accuracy: 0.3627 - val_loss: 1.0938 - val_accuracy: 0.4333\n","Epoch 8/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.8244 - accuracy: 0.5043 - val_loss: 1.1285 - val_accuracy: 0.3667\n","Epoch 9/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.7282 - accuracy: 0.4435 - val_loss: 1.0927 - val_accuracy: 0.4333\n","Epoch 10/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.6095 - accuracy: 0.6096 - val_loss: 1.0936 - val_accuracy: 0.4667\n","Epoch 11/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.4781 - accuracy: 0.5650 - val_loss: 1.0519 - val_accuracy: 0.5333\n","Epoch 12/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.3671 - accuracy: 0.7013 - val_loss: 1.0706 - val_accuracy: 0.4333\n","Epoch 13/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.2192 - accuracy: 0.6939 - val_loss: 1.0339 - val_accuracy: 0.4833\n","Epoch 14/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.0248 - accuracy: 0.8199 - val_loss: 1.0441 - val_accuracy: 0.5000\n","Epoch 15/20\n","6/6 [==============================] - 1s 256ms/step - loss: 0.9305 - accuracy: 0.7924 - val_loss: 1.0790 - val_accuracy: 0.5000\n","Epoch 16/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.7292 - accuracy: 0.8449 - val_loss: 1.1144 - val_accuracy: 0.4167\n","Epoch 17/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.6365 - accuracy: 0.8645 - val_loss: 1.1562 - val_accuracy: 0.4833\n","Epoch 18/20\n","6/6 [==============================] - 2s 468ms/step - loss: 0.4809 - accuracy: 0.9240 - val_loss: 1.0892 - val_accuracy: 0.5500\n","Epoch 19/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.3725 - accuracy: 0.9356 - val_loss: 1.3287 - val_accuracy: 0.4500\n","Epoch 20/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.3042 - accuracy: 0.9699 - val_loss: 1.1439 - val_accuracy: 0.5167\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faee25237a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faee25237a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_18/bert/pooler/dense/kernel:0', 'tf_bert_model_18/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_18/bert/pooler/dense/kernel:0', 'tf_bert_model_18/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_18/bert/pooler/dense/kernel:0', 'tf_bert_model_18/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_18/bert/pooler/dense/kernel:0', 'tf_bert_model_18/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 3.1935 - accuracy: 0.3613WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 88s 2s/step - loss: 3.1454 - accuracy: 0.3487 - val_loss: 1.4530 - val_accuracy: 0.3000\n","Epoch 2/20\n","6/6 [==============================] - 2s 416ms/step - loss: 2.4466 - accuracy: 0.5182 - val_loss: 1.1706 - val_accuracy: 0.3833\n","Epoch 3/20\n","6/6 [==============================] - 1s 247ms/step - loss: 2.0429 - accuracy: 0.2699 - val_loss: 1.1135 - val_accuracy: 0.4667\n","Epoch 4/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.8507 - accuracy: 0.4044 - val_loss: 1.1472 - val_accuracy: 0.3333\n","Epoch 5/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.9740 - accuracy: 0.4818 - val_loss: 1.1171 - val_accuracy: 0.4333\n","Epoch 6/20\n","6/6 [==============================] - 1s 258ms/step - loss: 1.8428 - accuracy: 0.3225 - val_loss: 1.1508 - val_accuracy: 0.3500\n","Epoch 7/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.9275 - accuracy: 0.5352 - val_loss: 1.1916 - val_accuracy: 0.4000\n","Epoch 8/20\n","6/6 [==============================] - 1s 252ms/step - loss: 1.9333 - accuracy: 0.3234 - val_loss: 1.0855 - val_accuracy: 0.4167\n","Epoch 9/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.7368 - accuracy: 0.5292 - val_loss: 1.0794 - val_accuracy: 0.4167\n","Epoch 10/20\n","6/6 [==============================] - 1s 253ms/step - loss: 1.4968 - accuracy: 0.6289 - val_loss: 1.0812 - val_accuracy: 0.4000\n","Epoch 11/20\n","6/6 [==============================] - 1s 252ms/step - loss: 1.5197 - accuracy: 0.5226 - val_loss: 1.0775 - val_accuracy: 0.3500\n","Epoch 12/20\n","6/6 [==============================] - 1s 251ms/step - loss: 1.2499 - accuracy: 0.7264 - val_loss: 1.0782 - val_accuracy: 0.4667\n","Epoch 13/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.1299 - accuracy: 0.7128 - val_loss: 1.1001 - val_accuracy: 0.4000\n","Epoch 14/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.9792 - accuracy: 0.8277 - val_loss: 1.1160 - val_accuracy: 0.4167\n","Epoch 15/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.8935 - accuracy: 0.8253 - val_loss: 1.1282 - val_accuracy: 0.4167\n","Epoch 16/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.7398 - accuracy: 0.8713 - val_loss: 1.2287 - val_accuracy: 0.4000\n","Epoch 17/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.5771 - accuracy: 0.9136 - val_loss: 1.2458 - val_accuracy: 0.4000\n","Epoch 18/20\n","6/6 [==============================] - 1s 253ms/step - loss: 0.4571 - accuracy: 0.9255 - val_loss: 1.3123 - val_accuracy: 0.4000\n","Epoch 19/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.3430 - accuracy: 0.9693 - val_loss: 1.3123 - val_accuracy: 0.4333\n","Epoch 20/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.2856 - accuracy: 0.9533 - val_loss: 1.4249 - val_accuracy: 0.4000\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faec1851cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faec1851cb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_19/bert/pooler/dense/kernel:0', 'tf_bert_model_19/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_19/bert/pooler/dense/kernel:0', 'tf_bert_model_19/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_19/bert/pooler/dense/kernel:0', 'tf_bert_model_19/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_19/bert/pooler/dense/kernel:0', 'tf_bert_model_19/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.8467 - accuracy: 0.3665WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 84s 2s/step - loss: 2.8141 - accuracy: 0.3651 - val_loss: 1.2406 - val_accuracy: 0.3000\n","Epoch 2/20\n","6/6 [==============================] - 1s 245ms/step - loss: 2.1530 - accuracy: 0.3125 - val_loss: 1.0557 - val_accuracy: 0.3833\n","Epoch 3/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.8918 - accuracy: 0.4110 - val_loss: 1.0703 - val_accuracy: 0.3500\n","Epoch 4/20\n","6/6 [==============================] - 2s 424ms/step - loss: 1.9840 - accuracy: 0.3242 - val_loss: 1.0648 - val_accuracy: 0.3833\n","Epoch 5/20\n","6/6 [==============================] - 1s 254ms/step - loss: 1.8178 - accuracy: 0.5261 - val_loss: 1.1031 - val_accuracy: 0.3833\n","Epoch 6/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.8059 - accuracy: 0.3846 - val_loss: 1.0639 - val_accuracy: 0.4667\n","Epoch 7/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.7207 - accuracy: 0.4930 - val_loss: 1.0809 - val_accuracy: 0.4333\n","Epoch 8/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.6647 - accuracy: 0.5492 - val_loss: 1.0936 - val_accuracy: 0.3833\n","Epoch 9/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.5267 - accuracy: 0.5315 - val_loss: 1.0835 - val_accuracy: 0.5000\n","Epoch 10/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.3319 - accuracy: 0.7016 - val_loss: 1.0869 - val_accuracy: 0.4500\n","Epoch 11/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.2154 - accuracy: 0.6310 - val_loss: 1.1050 - val_accuracy: 0.5167\n","Epoch 12/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.2498 - accuracy: 0.7170 - val_loss: 1.0631 - val_accuracy: 0.5167\n","Epoch 13/20\n","6/6 [==============================] - 1s 251ms/step - loss: 0.9616 - accuracy: 0.8081 - val_loss: 1.0398 - val_accuracy: 0.5333\n","Epoch 14/20\n","6/6 [==============================] - 1s 253ms/step - loss: 0.8087 - accuracy: 0.7946 - val_loss: 1.0773 - val_accuracy: 0.5500\n","Epoch 15/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.6297 - accuracy: 0.8763 - val_loss: 1.0517 - val_accuracy: 0.5667\n","Epoch 16/20\n","6/6 [==============================] - 1s 257ms/step - loss: 0.5422 - accuracy: 0.9128 - val_loss: 1.0979 - val_accuracy: 0.4667\n","Epoch 17/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.5008 - accuracy: 0.8838 - val_loss: 1.1803 - val_accuracy: 0.5833\n","Epoch 18/20\n","6/6 [==============================] - 1s 243ms/step - loss: 0.3438 - accuracy: 0.9492 - val_loss: 1.2267 - val_accuracy: 0.5500\n","Epoch 19/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.2761 - accuracy: 0.9694 - val_loss: 1.3164 - val_accuracy: 0.5833\n","Epoch 20/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.2066 - accuracy: 0.9848 - val_loss: 1.3163 - val_accuracy: 0.5500\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faee9635290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faee9635290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_20/bert/pooler/dense/kernel:0', 'tf_bert_model_20/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_20/bert/pooler/dense/kernel:0', 'tf_bert_model_20/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_20/bert/pooler/dense/kernel:0', 'tf_bert_model_20/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_20/bert/pooler/dense/kernel:0', 'tf_bert_model_20/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.5745 - accuracy: 0.2572WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 87s 2s/step - loss: 2.5812 - accuracy: 0.2580 - val_loss: 1.4963 - val_accuracy: 0.3333\n","Epoch 2/20\n","6/6 [==============================] - 1s 243ms/step - loss: 2.5821 - accuracy: 0.2223 - val_loss: 1.2655 - val_accuracy: 0.3500\n","Epoch 3/20\n","6/6 [==============================] - 1s 246ms/step - loss: 2.0219 - accuracy: 0.3817 - val_loss: 1.1043 - val_accuracy: 0.4000\n","Epoch 4/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.9454 - accuracy: 0.4414 - val_loss: 1.0993 - val_accuracy: 0.4167\n","Epoch 5/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.9358 - accuracy: 0.4157 - val_loss: 1.0721 - val_accuracy: 0.4500\n","Epoch 6/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.7643 - accuracy: 0.4818 - val_loss: 1.0721 - val_accuracy: 0.4333\n","Epoch 7/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.8493 - accuracy: 0.4933 - val_loss: 1.1017 - val_accuracy: 0.4667\n","Epoch 8/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.6098 - accuracy: 0.5732 - val_loss: 1.0950 - val_accuracy: 0.4500\n","Epoch 9/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.5705 - accuracy: 0.5684 - val_loss: 1.0933 - val_accuracy: 0.4167\n","Epoch 10/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.4526 - accuracy: 0.6499 - val_loss: 1.1069 - val_accuracy: 0.3833\n","Epoch 11/20\n","6/6 [==============================] - 2s 446ms/step - loss: 1.3426 - accuracy: 0.7180 - val_loss: 1.1114 - val_accuracy: 0.4333\n","Epoch 12/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.1177 - accuracy: 0.7706 - val_loss: 1.1620 - val_accuracy: 0.4167\n","Epoch 13/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.0166 - accuracy: 0.7638 - val_loss: 1.1818 - val_accuracy: 0.4500\n","Epoch 14/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.8997 - accuracy: 0.8363 - val_loss: 1.1807 - val_accuracy: 0.4500\n","Epoch 15/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.6144 - accuracy: 0.8953 - val_loss: 1.2206 - val_accuracy: 0.5000\n","Epoch 16/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.5214 - accuracy: 0.8715 - val_loss: 1.3620 - val_accuracy: 0.4667\n","Epoch 17/20\n","6/6 [==============================] - 1s 243ms/step - loss: 0.4095 - accuracy: 0.9316 - val_loss: 1.3826 - val_accuracy: 0.4667\n","Epoch 18/20\n","6/6 [==============================] - 1s 252ms/step - loss: 0.3182 - accuracy: 0.9756 - val_loss: 1.3413 - val_accuracy: 0.4833\n","Epoch 19/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.3121 - accuracy: 0.9512 - val_loss: 1.3849 - val_accuracy: 0.4500\n","Epoch 20/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.2640 - accuracy: 0.9605 - val_loss: 1.5938 - val_accuracy: 0.5000\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9ea963b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9ea963b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_21/bert/pooler/dense/kernel:0', 'tf_bert_model_21/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_21/bert/pooler/dense/kernel:0', 'tf_bert_model_21/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_21/bert/pooler/dense/kernel:0', 'tf_bert_model_21/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_21/bert/pooler/dense/kernel:0', 'tf_bert_model_21/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.4315 - accuracy: 0.3703WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 87s 2s/step - loss: 2.4179 - accuracy: 0.3781 - val_loss: 1.1432 - val_accuracy: 0.3333\n","Epoch 2/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.9165 - accuracy: 0.4149 - val_loss: 1.1241 - val_accuracy: 0.3333\n","Epoch 3/20\n","6/6 [==============================] - 1s 247ms/step - loss: 2.0022 - accuracy: 0.4275 - val_loss: 1.1069 - val_accuracy: 0.4167\n","Epoch 4/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.7628 - accuracy: 0.2948 - val_loss: 1.0979 - val_accuracy: 0.4500\n","Epoch 5/20\n","6/6 [==============================] - 1s 244ms/step - loss: 2.0481 - accuracy: 0.4786 - val_loss: 1.1498 - val_accuracy: 0.4500\n","Epoch 6/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.8421 - accuracy: 0.3254 - val_loss: 1.1031 - val_accuracy: 0.4333\n","Epoch 7/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.7823 - accuracy: 0.5197 - val_loss: 1.0889 - val_accuracy: 0.4833\n","Epoch 8/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.7263 - accuracy: 0.4208 - val_loss: 1.0922 - val_accuracy: 0.3833\n","Epoch 9/20\n","6/6 [==============================] - 1s 242ms/step - loss: 1.6947 - accuracy: 0.5908 - val_loss: 1.0834 - val_accuracy: 0.4500\n","Epoch 10/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.3921 - accuracy: 0.6010 - val_loss: 1.1016 - val_accuracy: 0.3833\n","Epoch 11/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.3629 - accuracy: 0.6579 - val_loss: 1.0869 - val_accuracy: 0.4167\n","Epoch 12/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.1369 - accuracy: 0.7090 - val_loss: 1.0733 - val_accuracy: 0.4500\n","Epoch 13/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.0270 - accuracy: 0.7653 - val_loss: 1.1208 - val_accuracy: 0.4167\n","Epoch 14/20\n","6/6 [==============================] - 1s 255ms/step - loss: 0.9924 - accuracy: 0.7767 - val_loss: 1.1100 - val_accuracy: 0.4833\n","Epoch 15/20\n","6/6 [==============================] - 1s 243ms/step - loss: 0.6752 - accuracy: 0.8350 - val_loss: 1.2767 - val_accuracy: 0.4167\n","Epoch 16/20\n","6/6 [==============================] - 1s 241ms/step - loss: 0.5483 - accuracy: 0.9096 - val_loss: 1.2080 - val_accuracy: 0.4667\n","Epoch 17/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.4596 - accuracy: 0.9141 - val_loss: 1.4299 - val_accuracy: 0.4500\n","Epoch 18/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.4420 - accuracy: 0.9210 - val_loss: 1.2306 - val_accuracy: 0.4667\n","Epoch 19/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.3002 - accuracy: 0.9501 - val_loss: 1.5323 - val_accuracy: 0.4500\n","Epoch 20/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.2177 - accuracy: 0.9590 - val_loss: 1.3964 - val_accuracy: 0.4500\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9cf213b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9cf213b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 12s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_22/bert/pooler/dense/kernel:0', 'tf_bert_model_22/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_22/bert/pooler/dense/kernel:0', 'tf_bert_model_22/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_22/bert/pooler/dense/kernel:0', 'tf_bert_model_22/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_22/bert/pooler/dense/kernel:0', 'tf_bert_model_22/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.9073 - accuracy: 0.3125WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 85s 2s/step - loss: 2.8841 - accuracy: 0.3151 - val_loss: 1.1512 - val_accuracy: 0.3000\n","Epoch 2/20\n","6/6 [==============================] - 1s 247ms/step - loss: 2.3172 - accuracy: 0.2208 - val_loss: 1.1521 - val_accuracy: 0.4333\n","Epoch 3/20\n","6/6 [==============================] - 1s 242ms/step - loss: 1.8097 - accuracy: 0.4734 - val_loss: 1.1937 - val_accuracy: 0.3833\n","Epoch 4/20\n","6/6 [==============================] - 1s 244ms/step - loss: 2.0511 - accuracy: 0.3084 - val_loss: 1.1633 - val_accuracy: 0.3167\n","Epoch 5/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.8909 - accuracy: 0.3162 - val_loss: 1.1349 - val_accuracy: 0.5000\n","Epoch 6/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.9455 - accuracy: 0.4779 - val_loss: 1.0775 - val_accuracy: 0.3667\n","Epoch 7/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.9599 - accuracy: 0.3987 - val_loss: 1.0777 - val_accuracy: 0.4333\n","Epoch 8/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.8593 - accuracy: 0.4656 - val_loss: 1.0649 - val_accuracy: 0.4333\n","Epoch 9/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.7606 - accuracy: 0.4813 - val_loss: 1.0584 - val_accuracy: 0.4167\n","Epoch 10/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.6787 - accuracy: 0.5872 - val_loss: 1.0350 - val_accuracy: 0.4333\n","Epoch 11/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.4990 - accuracy: 0.5721 - val_loss: 1.0302 - val_accuracy: 0.4500\n","Epoch 12/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.4905 - accuracy: 0.5926 - val_loss: 1.0133 - val_accuracy: 0.5000\n","Epoch 13/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.3795 - accuracy: 0.6753 - val_loss: 0.9964 - val_accuracy: 0.5000\n","Epoch 14/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.0572 - accuracy: 0.7370 - val_loss: 1.0621 - val_accuracy: 0.4833\n","Epoch 15/20\n","6/6 [==============================] - 1s 243ms/step - loss: 0.9730 - accuracy: 0.7995 - val_loss: 1.0669 - val_accuracy: 0.4333\n","Epoch 16/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.9430 - accuracy: 0.8319 - val_loss: 1.0285 - val_accuracy: 0.5167\n","Epoch 17/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.7026 - accuracy: 0.8610 - val_loss: 1.0772 - val_accuracy: 0.4667\n","Epoch 18/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.5102 - accuracy: 0.9147 - val_loss: 1.1134 - val_accuracy: 0.4833\n","Epoch 19/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.3601 - accuracy: 0.9384 - val_loss: 1.2274 - val_accuracy: 0.4333\n","Epoch 20/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.3310 - accuracy: 0.9341 - val_loss: 1.1457 - val_accuracy: 0.5167\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faece29c680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faece29c680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 12s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_23/bert/pooler/dense/kernel:0', 'tf_bert_model_23/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_23/bert/pooler/dense/kernel:0', 'tf_bert_model_23/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_23/bert/pooler/dense/kernel:0', 'tf_bert_model_23/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_23/bert/pooler/dense/kernel:0', 'tf_bert_model_23/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.3906 - accuracy: 0.3717WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 85s 2s/step - loss: 2.3989 - accuracy: 0.3669 - val_loss: 1.4107 - val_accuracy: 0.3167\n","Epoch 2/20\n","6/6 [==============================] - 1s 244ms/step - loss: 2.1472 - accuracy: 0.2680 - val_loss: 1.1660 - val_accuracy: 0.3333\n","Epoch 3/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.8878 - accuracy: 0.4833 - val_loss: 1.0956 - val_accuracy: 0.3833\n","Epoch 4/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.7954 - accuracy: 0.3605 - val_loss: 1.0685 - val_accuracy: 0.4667\n","Epoch 5/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.6948 - accuracy: 0.5919 - val_loss: 1.0682 - val_accuracy: 0.4000\n","Epoch 6/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.6525 - accuracy: 0.5820 - val_loss: 1.0878 - val_accuracy: 0.4333\n","Epoch 7/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.6310 - accuracy: 0.5241 - val_loss: 1.0583 - val_accuracy: 0.5000\n","Epoch 8/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.5019 - accuracy: 0.6329 - val_loss: 1.0597 - val_accuracy: 0.4833\n","Epoch 9/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.3152 - accuracy: 0.7335 - val_loss: 1.0726 - val_accuracy: 0.4833\n","Epoch 10/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.2561 - accuracy: 0.6958 - val_loss: 1.0761 - val_accuracy: 0.5000\n","Epoch 11/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.0562 - accuracy: 0.7829 - val_loss: 1.1040 - val_accuracy: 0.5167\n","Epoch 12/20\n","6/6 [==============================] - 1s 254ms/step - loss: 0.9651 - accuracy: 0.7657 - val_loss: 1.1551 - val_accuracy: 0.4833\n","Epoch 13/20\n","6/6 [==============================] - 1s 251ms/step - loss: 0.7315 - accuracy: 0.8790 - val_loss: 1.1184 - val_accuracy: 0.5167\n","Epoch 14/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.6049 - accuracy: 0.8943 - val_loss: 1.1215 - val_accuracy: 0.4833\n","Epoch 15/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.5087 - accuracy: 0.8928 - val_loss: 1.0862 - val_accuracy: 0.5667\n","Epoch 16/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.3935 - accuracy: 0.9440 - val_loss: 1.1635 - val_accuracy: 0.4667\n","Epoch 17/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.2938 - accuracy: 0.9705 - val_loss: 1.1888 - val_accuracy: 0.5000\n","Epoch 18/20\n","6/6 [==============================] - 1s 253ms/step - loss: 0.2467 - accuracy: 0.9722 - val_loss: 1.2332 - val_accuracy: 0.4667\n","Epoch 19/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.1777 - accuracy: 0.9842 - val_loss: 1.2183 - val_accuracy: 0.4833\n","Epoch 20/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.1470 - accuracy: 0.9938 - val_loss: 1.2104 - val_accuracy: 0.4667\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faecb98b200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faecb98b200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 12s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_24/bert/pooler/dense/kernel:0', 'tf_bert_model_24/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_24/bert/pooler/dense/kernel:0', 'tf_bert_model_24/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_24/bert/pooler/dense/kernel:0', 'tf_bert_model_24/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_24/bert/pooler/dense/kernel:0', 'tf_bert_model_24/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.5327 - accuracy: 0.3043WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 85s 2s/step - loss: 2.5316 - accuracy: 0.3007 - val_loss: 1.2970 - val_accuracy: 0.3167\n","Epoch 2/20\n","6/6 [==============================] - 1s 243ms/step - loss: 2.1872 - accuracy: 0.4912 - val_loss: 1.1590 - val_accuracy: 0.3167\n","Epoch 3/20\n","6/6 [==============================] - 1s 246ms/step - loss: 2.0704 - accuracy: 0.1903 - val_loss: 1.0724 - val_accuracy: 0.4000\n","Epoch 4/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.9417 - accuracy: 0.4916 - val_loss: 1.1200 - val_accuracy: 0.3500\n","Epoch 5/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.9061 - accuracy: 0.3372 - val_loss: 1.1364 - val_accuracy: 0.3667\n","Epoch 6/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.9812 - accuracy: 0.3549 - val_loss: 1.1202 - val_accuracy: 0.3167\n","Epoch 7/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.8659 - accuracy: 0.4618 - val_loss: 1.0556 - val_accuracy: 0.4667\n","Epoch 8/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.7188 - accuracy: 0.5081 - val_loss: 1.0342 - val_accuracy: 0.4833\n","Epoch 9/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.7066 - accuracy: 0.5074 - val_loss: 1.0493 - val_accuracy: 0.4500\n","Epoch 10/20\n","6/6 [==============================] - 1s 251ms/step - loss: 1.5838 - accuracy: 0.6368 - val_loss: 1.0420 - val_accuracy: 0.4833\n","Epoch 11/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.5330 - accuracy: 0.5870 - val_loss: 1.0264 - val_accuracy: 0.4667\n","Epoch 12/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.2800 - accuracy: 0.7229 - val_loss: 1.0082 - val_accuracy: 0.5000\n","Epoch 13/20\n","6/6 [==============================] - 1s 254ms/step - loss: 1.2152 - accuracy: 0.6983 - val_loss: 1.0127 - val_accuracy: 0.5167\n","Epoch 14/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.9784 - accuracy: 0.8290 - val_loss: 1.0531 - val_accuracy: 0.5167\n","Epoch 15/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.8988 - accuracy: 0.7967 - val_loss: 1.0628 - val_accuracy: 0.5667\n","Epoch 16/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.7165 - accuracy: 0.8947 - val_loss: 1.0838 - val_accuracy: 0.5333\n","Epoch 17/20\n","6/6 [==============================] - 1s 251ms/step - loss: 0.5828 - accuracy: 0.8892 - val_loss: 1.0915 - val_accuracy: 0.5500\n","Epoch 18/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.4015 - accuracy: 0.9533 - val_loss: 1.0621 - val_accuracy: 0.5167\n","Epoch 19/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.3222 - accuracy: 0.9554 - val_loss: 1.2742 - val_accuracy: 0.4833\n","Epoch 20/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.3083 - accuracy: 0.9627 - val_loss: 1.1154 - val_accuracy: 0.5333\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faf9fd66f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faf9fd66f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_25/bert/pooler/dense/kernel:0', 'tf_bert_model_25/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_25/bert/pooler/dense/kernel:0', 'tf_bert_model_25/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_25/bert/pooler/dense/kernel:0', 'tf_bert_model_25/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_25/bert/pooler/dense/kernel:0', 'tf_bert_model_25/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.3496 - accuracy: 0.3295WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 86s 2s/step - loss: 2.3510 - accuracy: 0.3289 - val_loss: 1.2101 - val_accuracy: 0.3333\n","Epoch 2/20\n","6/6 [==============================] - 1s 245ms/step - loss: 2.0746 - accuracy: 0.2731 - val_loss: 1.2284 - val_accuracy: 0.4667\n","Epoch 3/20\n","6/6 [==============================] - 1s 239ms/step - loss: 2.0643 - accuracy: 0.4669 - val_loss: 1.0670 - val_accuracy: 0.4333\n","Epoch 4/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.9511 - accuracy: 0.2713 - val_loss: 1.0215 - val_accuracy: 0.5000\n","Epoch 5/20\n","6/6 [==============================] - 1s 239ms/step - loss: 1.8006 - accuracy: 0.5199 - val_loss: 0.9942 - val_accuracy: 0.4667\n","Epoch 6/20\n","6/6 [==============================] - 1s 240ms/step - loss: 1.7512 - accuracy: 0.4453 - val_loss: 0.9707 - val_accuracy: 0.4833\n","Epoch 7/20\n","6/6 [==============================] - 1s 240ms/step - loss: 1.7719 - accuracy: 0.5451 - val_loss: 0.9619 - val_accuracy: 0.5500\n","Epoch 8/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.5293 - accuracy: 0.5359 - val_loss: 0.9589 - val_accuracy: 0.5333\n","Epoch 9/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.5489 - accuracy: 0.6166 - val_loss: 0.9551 - val_accuracy: 0.5167\n","Epoch 10/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.2746 - accuracy: 0.7302 - val_loss: 0.9220 - val_accuracy: 0.6000\n","Epoch 11/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.2303 - accuracy: 0.7157 - val_loss: 0.8630 - val_accuracy: 0.5500\n","Epoch 12/20\n","6/6 [==============================] - 1s 243ms/step - loss: 0.9558 - accuracy: 0.7643 - val_loss: 0.8460 - val_accuracy: 0.6000\n","Epoch 13/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.8508 - accuracy: 0.7917 - val_loss: 0.8501 - val_accuracy: 0.6000\n","Epoch 14/20\n","6/6 [==============================] - 1s 242ms/step - loss: 0.6252 - accuracy: 0.8734 - val_loss: 0.8851 - val_accuracy: 0.5667\n","Epoch 15/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.5594 - accuracy: 0.9161 - val_loss: 0.8684 - val_accuracy: 0.6333\n","Epoch 16/20\n","6/6 [==============================] - 1s 242ms/step - loss: 0.4387 - accuracy: 0.9222 - val_loss: 0.8546 - val_accuracy: 0.6167\n","Epoch 17/20\n","6/6 [==============================] - 1s 243ms/step - loss: 0.3129 - accuracy: 0.9559 - val_loss: 0.9131 - val_accuracy: 0.5833\n","Epoch 18/20\n","6/6 [==============================] - 1s 242ms/step - loss: 0.2591 - accuracy: 0.9661 - val_loss: 0.9680 - val_accuracy: 0.5833\n","Epoch 19/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.2111 - accuracy: 0.9770 - val_loss: 1.0169 - val_accuracy: 0.5667\n","Epoch 20/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.1762 - accuracy: 0.9924 - val_loss: 0.9563 - val_accuracy: 0.6000\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faed85b7290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faed85b7290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_26/bert/pooler/dense/kernel:0', 'tf_bert_model_26/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_26/bert/pooler/dense/kernel:0', 'tf_bert_model_26/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_26/bert/pooler/dense/kernel:0', 'tf_bert_model_26/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_26/bert/pooler/dense/kernel:0', 'tf_bert_model_26/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.4385 - accuracy: 0.3257WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 86s 2s/step - loss: 2.4386 - accuracy: 0.3260 - val_loss: 1.2684 - val_accuracy: 0.3000\n","Epoch 2/20\n","6/6 [==============================] - 1s 245ms/step - loss: 2.1023 - accuracy: 0.2401 - val_loss: 1.1695 - val_accuracy: 0.3167\n","Epoch 3/20\n","6/6 [==============================] - 1s 248ms/step - loss: 2.0534 - accuracy: 0.3602 - val_loss: 1.1079 - val_accuracy: 0.3500\n","Epoch 4/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.9816 - accuracy: 0.3574 - val_loss: 1.0854 - val_accuracy: 0.3667\n","Epoch 5/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.8934 - accuracy: 0.4063 - val_loss: 1.1283 - val_accuracy: 0.3500\n","Epoch 6/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.8076 - accuracy: 0.4788 - val_loss: 1.1011 - val_accuracy: 0.4000\n","Epoch 7/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.7519 - accuracy: 0.5053 - val_loss: 1.1902 - val_accuracy: 0.2667\n","Epoch 8/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.6664 - accuracy: 0.5259 - val_loss: 1.1155 - val_accuracy: 0.4167\n","Epoch 9/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.5771 - accuracy: 0.5731 - val_loss: 1.2013 - val_accuracy: 0.2667\n","Epoch 10/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.4589 - accuracy: 0.6405 - val_loss: 1.1276 - val_accuracy: 0.4833\n","Epoch 11/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.3900 - accuracy: 0.6225 - val_loss: 1.1510 - val_accuracy: 0.3500\n","Epoch 12/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.1086 - accuracy: 0.7637 - val_loss: 1.1673 - val_accuracy: 0.3833\n","Epoch 13/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.9921 - accuracy: 0.8248 - val_loss: 1.1402 - val_accuracy: 0.4333\n","Epoch 14/20\n","6/6 [==============================] - 1s 252ms/step - loss: 0.8046 - accuracy: 0.7865 - val_loss: 1.3297 - val_accuracy: 0.4167\n","Epoch 15/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.6218 - accuracy: 0.9138 - val_loss: 1.2093 - val_accuracy: 0.4167\n","Epoch 16/20\n","6/6 [==============================] - 1s 251ms/step - loss: 0.5135 - accuracy: 0.9018 - val_loss: 1.4848 - val_accuracy: 0.4333\n","Epoch 17/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.4220 - accuracy: 0.9533 - val_loss: 1.3078 - val_accuracy: 0.4333\n","Epoch 18/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.3255 - accuracy: 0.9414 - val_loss: 1.3223 - val_accuracy: 0.4667\n","Epoch 19/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.2854 - accuracy: 0.9386 - val_loss: 1.4857 - val_accuracy: 0.4500\n","Epoch 20/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.2588 - accuracy: 0.9654 - val_loss: 1.4651 - val_accuracy: 0.4833\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9d491050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9d491050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_27/bert/pooler/dense/kernel:0', 'tf_bert_model_27/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_27/bert/pooler/dense/kernel:0', 'tf_bert_model_27/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_27/bert/pooler/dense/kernel:0', 'tf_bert_model_27/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_27/bert/pooler/dense/kernel:0', 'tf_bert_model_27/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.4221 - accuracy: 0.4018WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 85s 2s/step - loss: 2.4240 - accuracy: 0.4028 - val_loss: 1.1430 - val_accuracy: 0.3333\n","Epoch 2/20\n","6/6 [==============================] - 1s 244ms/step - loss: 2.0291 - accuracy: 0.3266 - val_loss: 1.0580 - val_accuracy: 0.4500\n","Epoch 3/20\n","6/6 [==============================] - 1s 242ms/step - loss: 1.8466 - accuracy: 0.4282 - val_loss: 1.0782 - val_accuracy: 0.3500\n","Epoch 4/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.8983 - accuracy: 0.4496 - val_loss: 1.0502 - val_accuracy: 0.4667\n","Epoch 5/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.9379 - accuracy: 0.4651 - val_loss: 1.0504 - val_accuracy: 0.4000\n","Epoch 6/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.9006 - accuracy: 0.5307 - val_loss: 1.1010 - val_accuracy: 0.4500\n","Epoch 7/20\n","6/6 [==============================] - 2s 433ms/step - loss: 1.6311 - accuracy: 0.4515 - val_loss: 1.0591 - val_accuracy: 0.4667\n","Epoch 8/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.4737 - accuracy: 0.6219 - val_loss: 1.0698 - val_accuracy: 0.4833\n","Epoch 9/20\n","6/6 [==============================] - 1s 241ms/step - loss: 1.3097 - accuracy: 0.6930 - val_loss: 1.0696 - val_accuracy: 0.4667\n","Epoch 10/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.1730 - accuracy: 0.7186 - val_loss: 1.1248 - val_accuracy: 0.4833\n","Epoch 11/20\n","6/6 [==============================] - 1s 242ms/step - loss: 1.0263 - accuracy: 0.7688 - val_loss: 1.1318 - val_accuracy: 0.4667\n","Epoch 12/20\n","6/6 [==============================] - 1s 243ms/step - loss: 0.9863 - accuracy: 0.7934 - val_loss: 1.1697 - val_accuracy: 0.4333\n","Epoch 13/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.7000 - accuracy: 0.8838 - val_loss: 1.3125 - val_accuracy: 0.4500\n","Epoch 14/20\n","6/6 [==============================] - 1s 241ms/step - loss: 0.6072 - accuracy: 0.8893 - val_loss: 1.3833 - val_accuracy: 0.5000\n","Epoch 15/20\n","6/6 [==============================] - 1s 241ms/step - loss: 0.4302 - accuracy: 0.9685 - val_loss: 1.2879 - val_accuracy: 0.5000\n","Epoch 16/20\n","6/6 [==============================] - 1s 242ms/step - loss: 0.3713 - accuracy: 0.9327 - val_loss: 1.5678 - val_accuracy: 0.5000\n","Epoch 17/20\n","6/6 [==============================] - 1s 242ms/step - loss: 0.2790 - accuracy: 0.9631 - val_loss: 1.4300 - val_accuracy: 0.5333\n","Epoch 18/20\n","6/6 [==============================] - 1s 240ms/step - loss: 0.2121 - accuracy: 0.9820 - val_loss: 1.5568 - val_accuracy: 0.5667\n","Epoch 19/20\n","6/6 [==============================] - 1s 241ms/step - loss: 0.1625 - accuracy: 0.9846 - val_loss: 1.4738 - val_accuracy: 0.5667\n","Epoch 20/20\n","6/6 [==============================] - 1s 240ms/step - loss: 0.1422 - accuracy: 0.9951 - val_loss: 1.6729 - val_accuracy: 0.5500\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faec8ea3440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faec8ea3440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_28/bert/pooler/dense/kernel:0', 'tf_bert_model_28/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_28/bert/pooler/dense/kernel:0', 'tf_bert_model_28/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_28/bert/pooler/dense/kernel:0', 'tf_bert_model_28/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_28/bert/pooler/dense/kernel:0', 'tf_bert_model_28/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.3671 - accuracy: 0.3800WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 87s 2s/step - loss: 2.3643 - accuracy: 0.3744 - val_loss: 1.2210 - val_accuracy: 0.3167\n","Epoch 2/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.8732 - accuracy: 0.5562 - val_loss: 1.2103 - val_accuracy: 0.3333\n","Epoch 3/20\n","6/6 [==============================] - 1s 243ms/step - loss: 2.0445 - accuracy: 0.2680 - val_loss: 1.1670 - val_accuracy: 0.3667\n","Epoch 4/20\n","6/6 [==============================] - 1s 251ms/step - loss: 1.8403 - accuracy: 0.5478 - val_loss: 1.1525 - val_accuracy: 0.3333\n","Epoch 5/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.7329 - accuracy: 0.3569 - val_loss: 1.2249 - val_accuracy: 0.3833\n","Epoch 6/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.7885 - accuracy: 0.5714 - val_loss: 1.1252 - val_accuracy: 0.4000\n","Epoch 7/20\n","6/6 [==============================] - 1s 251ms/step - loss: 1.7264 - accuracy: 0.4583 - val_loss: 1.1379 - val_accuracy: 0.4333\n","Epoch 8/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.4637 - accuracy: 0.6487 - val_loss: 1.1345 - val_accuracy: 0.4167\n","Epoch 9/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.2794 - accuracy: 0.7102 - val_loss: 1.1404 - val_accuracy: 0.4333\n","Epoch 10/20\n","6/6 [==============================] - 1s 251ms/step - loss: 1.1454 - accuracy: 0.7202 - val_loss: 1.2579 - val_accuracy: 0.4167\n","Epoch 11/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.9236 - accuracy: 0.8305 - val_loss: 1.2337 - val_accuracy: 0.4167\n","Epoch 12/20\n","6/6 [==============================] - 2s 450ms/step - loss: 0.9437 - accuracy: 0.7440 - val_loss: 1.3638 - val_accuracy: 0.3667\n","Epoch 13/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.7220 - accuracy: 0.8599 - val_loss: 1.2909 - val_accuracy: 0.4333\n","Epoch 14/20\n","6/6 [==============================] - 1s 254ms/step - loss: 0.5666 - accuracy: 0.8862 - val_loss: 1.4903 - val_accuracy: 0.4333\n","Epoch 15/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.4116 - accuracy: 0.9453 - val_loss: 1.4680 - val_accuracy: 0.4167\n","Epoch 16/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.3312 - accuracy: 0.9628 - val_loss: 1.4351 - val_accuracy: 0.4833\n","Epoch 17/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.2560 - accuracy: 0.9753 - val_loss: 1.5598 - val_accuracy: 0.4833\n","Epoch 18/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.2040 - accuracy: 0.9696 - val_loss: 1.5580 - val_accuracy: 0.4667\n","Epoch 19/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.1449 - accuracy: 0.9946 - val_loss: 1.6599 - val_accuracy: 0.4333\n","Epoch 20/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.1184 - accuracy: 0.9880 - val_loss: 1.7316 - val_accuracy: 0.4167\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faec19c4560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faec19c4560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_29/bert/pooler/dense/kernel:0', 'tf_bert_model_29/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_29/bert/pooler/dense/kernel:0', 'tf_bert_model_29/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_29/bert/pooler/dense/kernel:0', 'tf_bert_model_29/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_29/bert/pooler/dense/kernel:0', 'tf_bert_model_29/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.4355 - accuracy: 0.4616WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 86s 2s/step - loss: 2.4120 - accuracy: 0.4612 - val_loss: 1.2910 - val_accuracy: 0.3500\n","Epoch 2/20\n","6/6 [==============================] - 1s 241ms/step - loss: 2.0006 - accuracy: 0.4584 - val_loss: 1.0795 - val_accuracy: 0.3667\n","Epoch 3/20\n","6/6 [==============================] - 1s 245ms/step - loss: 2.0484 - accuracy: 0.3867 - val_loss: 1.1460 - val_accuracy: 0.3333\n","Epoch 4/20\n","6/6 [==============================] - 1s 242ms/step - loss: 1.9732 - accuracy: 0.2656 - val_loss: 1.1075 - val_accuracy: 0.3667\n","Epoch 5/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.9899 - accuracy: 0.4282 - val_loss: 1.0894 - val_accuracy: 0.4000\n","Epoch 6/20\n","6/6 [==============================] - 1s 240ms/step - loss: 1.8918 - accuracy: 0.3409 - val_loss: 1.0477 - val_accuracy: 0.3833\n","Epoch 7/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.7781 - accuracy: 0.5685 - val_loss: 1.0496 - val_accuracy: 0.4333\n","Epoch 8/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.8005 - accuracy: 0.4420 - val_loss: 1.0858 - val_accuracy: 0.4667\n","Epoch 9/20\n","6/6 [==============================] - 1s 242ms/step - loss: 1.7208 - accuracy: 0.4864 - val_loss: 1.0245 - val_accuracy: 0.5000\n","Epoch 10/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.5603 - accuracy: 0.6091 - val_loss: 1.0286 - val_accuracy: 0.5167\n","Epoch 11/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.4022 - accuracy: 0.6124 - val_loss: 0.9666 - val_accuracy: 0.5667\n","Epoch 12/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.2276 - accuracy: 0.7417 - val_loss: 0.9845 - val_accuracy: 0.5333\n","Epoch 13/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.1003 - accuracy: 0.7036 - val_loss: 1.0146 - val_accuracy: 0.5333\n","Epoch 14/20\n","6/6 [==============================] - 1s 241ms/step - loss: 0.8980 - accuracy: 0.7965 - val_loss: 1.0364 - val_accuracy: 0.5833\n","Epoch 15/20\n","6/6 [==============================] - 1s 240ms/step - loss: 0.7422 - accuracy: 0.8459 - val_loss: 1.0712 - val_accuracy: 0.5667\n","Epoch 16/20\n","6/6 [==============================] - 1s 240ms/step - loss: 0.6263 - accuracy: 0.8662 - val_loss: 1.1627 - val_accuracy: 0.5667\n","Epoch 17/20\n","6/6 [==============================] - 1s 242ms/step - loss: 0.4720 - accuracy: 0.9218 - val_loss: 1.1719 - val_accuracy: 0.6000\n","Epoch 18/20\n","6/6 [==============================] - 2s 482ms/step - loss: 0.3741 - accuracy: 0.9454 - val_loss: 1.2964 - val_accuracy: 0.5833\n","Epoch 19/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.2838 - accuracy: 0.9785 - val_loss: 1.3435 - val_accuracy: 0.6000\n","Epoch 20/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.2449 - accuracy: 0.9707 - val_loss: 1.3665 - val_accuracy: 0.5833\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faec42bd8c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faec42bd8c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_30/bert/pooler/dense/kernel:0', 'tf_bert_model_30/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_30/bert/pooler/dense/kernel:0', 'tf_bert_model_30/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_30/bert/pooler/dense/kernel:0', 'tf_bert_model_30/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_30/bert/pooler/dense/kernel:0', 'tf_bert_model_30/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.8561 - accuracy: 0.3625WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 86s 2s/step - loss: 2.8705 - accuracy: 0.3568 - val_loss: 1.5752 - val_accuracy: 0.3333\n","Epoch 2/20\n","6/6 [==============================] - 1s 243ms/step - loss: 2.3775 - accuracy: 0.2608 - val_loss: 1.2404 - val_accuracy: 0.3500\n","Epoch 3/20\n","6/6 [==============================] - 1s 243ms/step - loss: 2.1795 - accuracy: 0.5380 - val_loss: 1.0428 - val_accuracy: 0.5000\n","Epoch 4/20\n","6/6 [==============================] - 1s 247ms/step - loss: 2.0159 - accuracy: 0.2917 - val_loss: 1.0258 - val_accuracy: 0.5000\n","Epoch 5/20\n","6/6 [==============================] - 2s 424ms/step - loss: 1.8876 - accuracy: 0.3812 - val_loss: 1.0426 - val_accuracy: 0.4333\n","Epoch 6/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.8709 - accuracy: 0.4318 - val_loss: 1.0427 - val_accuracy: 0.4167\n","Epoch 7/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.9420 - accuracy: 0.4257 - val_loss: 1.0625 - val_accuracy: 0.3833\n","Epoch 8/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.8796 - accuracy: 0.5332 - val_loss: 1.0536 - val_accuracy: 0.4500\n","Epoch 9/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.7308 - accuracy: 0.5203 - val_loss: 1.0569 - val_accuracy: 0.4833\n","Epoch 10/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.6669 - accuracy: 0.5272 - val_loss: 1.0565 - val_accuracy: 0.4667\n","Epoch 11/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.6226 - accuracy: 0.6227 - val_loss: 1.0697 - val_accuracy: 0.4333\n","Epoch 12/20\n","6/6 [==============================] - 1s 242ms/step - loss: 1.4974 - accuracy: 0.6551 - val_loss: 1.0905 - val_accuracy: 0.4333\n","Epoch 13/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.2944 - accuracy: 0.6763 - val_loss: 1.1835 - val_accuracy: 0.4667\n","Epoch 14/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.3597 - accuracy: 0.6943 - val_loss: 1.1658 - val_accuracy: 0.3833\n","Epoch 15/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.9993 - accuracy: 0.7336 - val_loss: 1.3015 - val_accuracy: 0.4500\n","Epoch 16/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.0327 - accuracy: 0.8266 - val_loss: 1.2962 - val_accuracy: 0.3667\n","Epoch 17/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.7541 - accuracy: 0.8384 - val_loss: 1.3668 - val_accuracy: 0.4667\n","Epoch 18/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.6653 - accuracy: 0.8927 - val_loss: 1.2703 - val_accuracy: 0.4833\n","Epoch 19/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.5486 - accuracy: 0.9047 - val_loss: 1.3174 - val_accuracy: 0.4833\n","Epoch 20/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.3869 - accuracy: 0.9509 - val_loss: 1.4555 - val_accuracy: 0.4667\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faedd441b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faedd441b90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_31/bert/pooler/dense/kernel:0', 'tf_bert_model_31/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_31/bert/pooler/dense/kernel:0', 'tf_bert_model_31/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_31/bert/pooler/dense/kernel:0', 'tf_bert_model_31/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_31/bert/pooler/dense/kernel:0', 'tf_bert_model_31/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.5794 - accuracy: 0.2944WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 88s 2s/step - loss: 2.5587 - accuracy: 0.2981 - val_loss: 1.3290 - val_accuracy: 0.3500\n","Epoch 2/20\n","6/6 [==============================] - 1s 246ms/step - loss: 2.2957 - accuracy: 0.2660 - val_loss: 1.2757 - val_accuracy: 0.3833\n","Epoch 3/20\n","6/6 [==============================] - 1s 251ms/step - loss: 2.1910 - accuracy: 0.4331 - val_loss: 1.1627 - val_accuracy: 0.3833\n","Epoch 4/20\n","6/6 [==============================] - 1s 247ms/step - loss: 2.0744 - accuracy: 0.2672 - val_loss: 1.1954 - val_accuracy: 0.3333\n","Epoch 5/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.9040 - accuracy: 0.5894 - val_loss: 1.1371 - val_accuracy: 0.4000\n","Epoch 6/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.8681 - accuracy: 0.3294 - val_loss: 1.1704 - val_accuracy: 0.3000\n","Epoch 7/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.8443 - accuracy: 0.4495 - val_loss: 1.1843 - val_accuracy: 0.3333\n","Epoch 8/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.8162 - accuracy: 0.4742 - val_loss: 1.1521 - val_accuracy: 0.3667\n","Epoch 9/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.6628 - accuracy: 0.5606 - val_loss: 1.1790 - val_accuracy: 0.3667\n","Epoch 10/20\n","6/6 [==============================] - 1s 242ms/step - loss: 1.4997 - accuracy: 0.6247 - val_loss: 1.1760 - val_accuracy: 0.3667\n","Epoch 11/20\n","6/6 [==============================] - 2s 440ms/step - loss: 1.3705 - accuracy: 0.6099 - val_loss: 1.2370 - val_accuracy: 0.3833\n","Epoch 12/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.3550 - accuracy: 0.7256 - val_loss: 1.2516 - val_accuracy: 0.4000\n","Epoch 13/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.1646 - accuracy: 0.6756 - val_loss: 1.3798 - val_accuracy: 0.4333\n","Epoch 14/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.9558 - accuracy: 0.8055 - val_loss: 1.3035 - val_accuracy: 0.4167\n","Epoch 15/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.8030 - accuracy: 0.8149 - val_loss: 1.5408 - val_accuracy: 0.4167\n","Epoch 16/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.6637 - accuracy: 0.8706 - val_loss: 1.3674 - val_accuracy: 0.4833\n","Epoch 17/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.4811 - accuracy: 0.8712 - val_loss: 1.7018 - val_accuracy: 0.4000\n","Epoch 18/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.3697 - accuracy: 0.9611 - val_loss: 1.5025 - val_accuracy: 0.4167\n","Epoch 19/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.3199 - accuracy: 0.9273 - val_loss: 1.7648 - val_accuracy: 0.3833\n","Epoch 20/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.2354 - accuracy: 0.9773 - val_loss: 1.7284 - val_accuracy: 0.4167\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faec1a104d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faec1a104d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_32/bert/pooler/dense/kernel:0', 'tf_bert_model_32/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_32/bert/pooler/dense/kernel:0', 'tf_bert_model_32/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_32/bert/pooler/dense/kernel:0', 'tf_bert_model_32/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_32/bert/pooler/dense/kernel:0', 'tf_bert_model_32/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.5117 - accuracy: 0.3304WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 88s 2s/step - loss: 2.4887 - accuracy: 0.3338 - val_loss: 1.1525 - val_accuracy: 0.3000\n","Epoch 2/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.8949 - accuracy: 0.3726 - val_loss: 1.0914 - val_accuracy: 0.3667\n","Epoch 3/20\n","6/6 [==============================] - 1s 245ms/step - loss: 2.0693 - accuracy: 0.2869 - val_loss: 1.0835 - val_accuracy: 0.4000\n","Epoch 4/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.8286 - accuracy: 0.5178 - val_loss: 1.0696 - val_accuracy: 0.3833\n","Epoch 5/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.8885 - accuracy: 0.4260 - val_loss: 1.1075 - val_accuracy: 0.3833\n","Epoch 6/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.6028 - accuracy: 0.6435 - val_loss: 1.1110 - val_accuracy: 0.3667\n","Epoch 7/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.7177 - accuracy: 0.5665 - val_loss: 1.2109 - val_accuracy: 0.4000\n","Epoch 8/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.4559 - accuracy: 0.6906 - val_loss: 1.1464 - val_accuracy: 0.4333\n","Epoch 9/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.3365 - accuracy: 0.6469 - val_loss: 1.2238 - val_accuracy: 0.4667\n","Epoch 10/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.2401 - accuracy: 0.6767 - val_loss: 1.3191 - val_accuracy: 0.4167\n","Epoch 11/20\n","6/6 [==============================] - 1s 252ms/step - loss: 1.0801 - accuracy: 0.7637 - val_loss: 1.2253 - val_accuracy: 0.5000\n","Epoch 12/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.8499 - accuracy: 0.7804 - val_loss: 1.4249 - val_accuracy: 0.4167\n","Epoch 13/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.6255 - accuracy: 0.8981 - val_loss: 1.4781 - val_accuracy: 0.4833\n","Epoch 14/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.6205 - accuracy: 0.8760 - val_loss: 1.4997 - val_accuracy: 0.4000\n","Epoch 15/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.4563 - accuracy: 0.9261 - val_loss: 1.4287 - val_accuracy: 0.4833\n","Epoch 16/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.3050 - accuracy: 0.9495 - val_loss: 1.6716 - val_accuracy: 0.4667\n","Epoch 17/20\n","6/6 [==============================] - 2s 482ms/step - loss: 0.2791 - accuracy: 0.9674 - val_loss: 1.5743 - val_accuracy: 0.4833\n","Epoch 18/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.1941 - accuracy: 0.9756 - val_loss: 1.8341 - val_accuracy: 0.4333\n","Epoch 19/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.1721 - accuracy: 0.9853 - val_loss: 1.6232 - val_accuracy: 0.5167\n","Epoch 20/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.1377 - accuracy: 0.9898 - val_loss: 1.8836 - val_accuracy: 0.4667\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fada091d440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fada091d440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_33/bert/pooler/dense/kernel:0', 'tf_bert_model_33/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_33/bert/pooler/dense/kernel:0', 'tf_bert_model_33/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_33/bert/pooler/dense/kernel:0', 'tf_bert_model_33/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_33/bert/pooler/dense/kernel:0', 'tf_bert_model_33/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.9599 - accuracy: 0.3319WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 87s 2s/step - loss: 2.9156 - accuracy: 0.3425 - val_loss: 1.3964 - val_accuracy: 0.3333\n","Epoch 2/20\n","6/6 [==============================] - 1s 244ms/step - loss: 2.2588 - accuracy: 0.2860 - val_loss: 1.1499 - val_accuracy: 0.3667\n","Epoch 3/20\n","6/6 [==============================] - 2s 417ms/step - loss: 1.9245 - accuracy: 0.5733 - val_loss: 1.0221 - val_accuracy: 0.4833\n","Epoch 4/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.9637 - accuracy: 0.3739 - val_loss: 1.0196 - val_accuracy: 0.5000\n","Epoch 5/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.8687 - accuracy: 0.4103 - val_loss: 1.0734 - val_accuracy: 0.4500\n","Epoch 6/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.9365 - accuracy: 0.4924 - val_loss: 1.0495 - val_accuracy: 0.4333\n","Epoch 7/20\n","6/6 [==============================] - 1s 251ms/step - loss: 1.8130 - accuracy: 0.3791 - val_loss: 1.0429 - val_accuracy: 0.4333\n","Epoch 8/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.6894 - accuracy: 0.5702 - val_loss: 1.0303 - val_accuracy: 0.4667\n","Epoch 9/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.6166 - accuracy: 0.5867 - val_loss: 1.0330 - val_accuracy: 0.4833\n","Epoch 10/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.4199 - accuracy: 0.6677 - val_loss: 1.0628 - val_accuracy: 0.5333\n","Epoch 11/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.4224 - accuracy: 0.6239 - val_loss: 1.0325 - val_accuracy: 0.5000\n","Epoch 12/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.1871 - accuracy: 0.7597 - val_loss: 1.1218 - val_accuracy: 0.5333\n","Epoch 13/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.0598 - accuracy: 0.7675 - val_loss: 1.1193 - val_accuracy: 0.5167\n","Epoch 14/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.9456 - accuracy: 0.8514 - val_loss: 1.0779 - val_accuracy: 0.5167\n","Epoch 15/20\n","6/6 [==============================] - 1s 251ms/step - loss: 0.7163 - accuracy: 0.8433 - val_loss: 1.2850 - val_accuracy: 0.5333\n","Epoch 16/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.5635 - accuracy: 0.9102 - val_loss: 1.1919 - val_accuracy: 0.5500\n","Epoch 17/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.4588 - accuracy: 0.8997 - val_loss: 1.4298 - val_accuracy: 0.5167\n","Epoch 18/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.3851 - accuracy: 0.9331 - val_loss: 1.2014 - val_accuracy: 0.6000\n","Epoch 19/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.3274 - accuracy: 0.9394 - val_loss: 1.4589 - val_accuracy: 0.5167\n","Epoch 20/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.2531 - accuracy: 0.9702 - val_loss: 1.3370 - val_accuracy: 0.5833\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9dac1290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9dac1290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_34/bert/pooler/dense/kernel:0', 'tf_bert_model_34/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_34/bert/pooler/dense/kernel:0', 'tf_bert_model_34/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_34/bert/pooler/dense/kernel:0', 'tf_bert_model_34/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_34/bert/pooler/dense/kernel:0', 'tf_bert_model_34/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.5221 - accuracy: 0.2898WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 87s 2s/step - loss: 2.5010 - accuracy: 0.2908 - val_loss: 1.1428 - val_accuracy: 0.3000\n","Epoch 2/20\n","6/6 [==============================] - 1s 244ms/step - loss: 2.0520 - accuracy: 0.3892 - val_loss: 1.0947 - val_accuracy: 0.3833\n","Epoch 3/20\n","6/6 [==============================] - 1s 252ms/step - loss: 1.7956 - accuracy: 0.4583 - val_loss: 1.0525 - val_accuracy: 0.4667\n","Epoch 4/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.9771 - accuracy: 0.2933 - val_loss: 1.0177 - val_accuracy: 0.5000\n","Epoch 5/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.8621 - accuracy: 0.4557 - val_loss: 1.0226 - val_accuracy: 0.4667\n","Epoch 6/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.6552 - accuracy: 0.5171 - val_loss: 1.0355 - val_accuracy: 0.4667\n","Epoch 7/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.6509 - accuracy: 0.5308 - val_loss: 1.0680 - val_accuracy: 0.4833\n","Epoch 8/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.5480 - accuracy: 0.6168 - val_loss: 1.0318 - val_accuracy: 0.4833\n","Epoch 9/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.5078 - accuracy: 0.5659 - val_loss: 1.1056 - val_accuracy: 0.4667\n","Epoch 10/20\n","6/6 [==============================] - 2s 434ms/step - loss: 1.2690 - accuracy: 0.7622 - val_loss: 0.9957 - val_accuracy: 0.5000\n","Epoch 11/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.0932 - accuracy: 0.7355 - val_loss: 1.2004 - val_accuracy: 0.4333\n","Epoch 12/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.0152 - accuracy: 0.8223 - val_loss: 1.0487 - val_accuracy: 0.5667\n","Epoch 13/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.8449 - accuracy: 0.7929 - val_loss: 1.2185 - val_accuracy: 0.5000\n","Epoch 14/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.6215 - accuracy: 0.9016 - val_loss: 1.1496 - val_accuracy: 0.5500\n","Epoch 15/20\n","6/6 [==============================] - 1s 251ms/step - loss: 0.6254 - accuracy: 0.8801 - val_loss: 1.3183 - val_accuracy: 0.5167\n","Epoch 16/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.4627 - accuracy: 0.9059 - val_loss: 1.2813 - val_accuracy: 0.5333\n","Epoch 17/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.3064 - accuracy: 0.9746 - val_loss: 1.2960 - val_accuracy: 0.5500\n","Epoch 18/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.2379 - accuracy: 0.9775 - val_loss: 1.3770 - val_accuracy: 0.5333\n","Epoch 19/20\n","6/6 [==============================] - 1s 243ms/step - loss: 0.2112 - accuracy: 0.9797 - val_loss: 1.4453 - val_accuracy: 0.5167\n","Epoch 20/20\n","6/6 [==============================] - 1s 255ms/step - loss: 0.1597 - accuracy: 0.9905 - val_loss: 1.4668 - val_accuracy: 0.5833\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faee46b19e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faee46b19e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_35/bert/pooler/dense/kernel:0', 'tf_bert_model_35/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_35/bert/pooler/dense/kernel:0', 'tf_bert_model_35/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_35/bert/pooler/dense/kernel:0', 'tf_bert_model_35/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_35/bert/pooler/dense/kernel:0', 'tf_bert_model_35/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.6388 - accuracy: 0.3053WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 89s 2s/step - loss: 2.6359 - accuracy: 0.3045 - val_loss: 1.3365 - val_accuracy: 0.3833\n","Epoch 2/20\n","6/6 [==============================] - 1s 250ms/step - loss: 2.2119 - accuracy: 0.3001 - val_loss: 1.2841 - val_accuracy: 0.3500\n","Epoch 3/20\n","6/6 [==============================] - 1s 243ms/step - loss: 2.1281 - accuracy: 0.4012 - val_loss: 1.1158 - val_accuracy: 0.4000\n","Epoch 4/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.9773 - accuracy: 0.2683 - val_loss: 1.1151 - val_accuracy: 0.3667\n","Epoch 5/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.8157 - accuracy: 0.5319 - val_loss: 1.0842 - val_accuracy: 0.4500\n","Epoch 6/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.8479 - accuracy: 0.4770 - val_loss: 1.0509 - val_accuracy: 0.4000\n","Epoch 7/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.6967 - accuracy: 0.4620 - val_loss: 1.0685 - val_accuracy: 0.3833\n","Epoch 8/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.6839 - accuracy: 0.6237 - val_loss: 1.0348 - val_accuracy: 0.4500\n","Epoch 9/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.6376 - accuracy: 0.4833 - val_loss: 1.0316 - val_accuracy: 0.4667\n","Epoch 10/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.5337 - accuracy: 0.6413 - val_loss: 1.0779 - val_accuracy: 0.3833\n","Epoch 11/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.2409 - accuracy: 0.6793 - val_loss: 1.0490 - val_accuracy: 0.4667\n","Epoch 12/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.2614 - accuracy: 0.6797 - val_loss: 1.1034 - val_accuracy: 0.3833\n","Epoch 13/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.2110 - accuracy: 0.6929 - val_loss: 1.0970 - val_accuracy: 0.4167\n","Epoch 14/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.9379 - accuracy: 0.7634 - val_loss: 1.1438 - val_accuracy: 0.4500\n","Epoch 15/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.7170 - accuracy: 0.8536 - val_loss: 1.2837 - val_accuracy: 0.4000\n","Epoch 16/20\n","6/6 [==============================] - 1s 256ms/step - loss: 0.6350 - accuracy: 0.8810 - val_loss: 1.2368 - val_accuracy: 0.5333\n","Epoch 17/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.4957 - accuracy: 0.9042 - val_loss: 1.3199 - val_accuracy: 0.4500\n","Epoch 18/20\n","6/6 [==============================] - 1s 242ms/step - loss: 0.3642 - accuracy: 0.9326 - val_loss: 1.3085 - val_accuracy: 0.4833\n","Epoch 19/20\n","6/6 [==============================] - 1s 243ms/step - loss: 0.3076 - accuracy: 0.9622 - val_loss: 1.4081 - val_accuracy: 0.5000\n","Epoch 20/20\n","6/6 [==============================] - 2s 479ms/step - loss: 0.2283 - accuracy: 0.9814 - val_loss: 1.5724 - val_accuracy: 0.5167\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faecdf92f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faecdf92f80> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_36/bert/pooler/dense/kernel:0', 'tf_bert_model_36/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_36/bert/pooler/dense/kernel:0', 'tf_bert_model_36/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_36/bert/pooler/dense/kernel:0', 'tf_bert_model_36/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_36/bert/pooler/dense/kernel:0', 'tf_bert_model_36/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.3871 - accuracy: 0.2893WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 88s 2s/step - loss: 2.3793 - accuracy: 0.2822 - val_loss: 1.1874 - val_accuracy: 0.3000\n","Epoch 2/20\n","6/6 [==============================] - 1s 243ms/step - loss: 2.0335 - accuracy: 0.4266 - val_loss: 1.1168 - val_accuracy: 0.3500\n","Epoch 3/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.8993 - accuracy: 0.3504 - val_loss: 1.1697 - val_accuracy: 0.3500\n","Epoch 4/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.9202 - accuracy: 0.4514 - val_loss: 1.1437 - val_accuracy: 0.3667\n","Epoch 5/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.8840 - accuracy: 0.3346 - val_loss: 1.2140 - val_accuracy: 0.2833\n","Epoch 6/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.8742 - accuracy: 0.4571 - val_loss: 1.1490 - val_accuracy: 0.4000\n","Epoch 7/20\n","6/6 [==============================] - 2s 426ms/step - loss: 1.8727 - accuracy: 0.4062 - val_loss: 1.1517 - val_accuracy: 0.2833\n","Epoch 8/20\n","6/6 [==============================] - 1s 252ms/step - loss: 1.7393 - accuracy: 0.5038 - val_loss: 1.1774 - val_accuracy: 0.2500\n","Epoch 9/20\n","6/6 [==============================] - 1s 252ms/step - loss: 1.5983 - accuracy: 0.5514 - val_loss: 1.1627 - val_accuracy: 0.3667\n","Epoch 10/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.5545 - accuracy: 0.5971 - val_loss: 1.2195 - val_accuracy: 0.3000\n","Epoch 11/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.4113 - accuracy: 0.6395 - val_loss: 1.3019 - val_accuracy: 0.3500\n","Epoch 12/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.3949 - accuracy: 0.6452 - val_loss: 1.2712 - val_accuracy: 0.3167\n","Epoch 13/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.1350 - accuracy: 0.7996 - val_loss: 1.2327 - val_accuracy: 0.4000\n","Epoch 14/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.9883 - accuracy: 0.7645 - val_loss: 1.2764 - val_accuracy: 0.3833\n","Epoch 15/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.7649 - accuracy: 0.8660 - val_loss: 1.3145 - val_accuracy: 0.4000\n","Epoch 16/20\n","6/6 [==============================] - 1s 252ms/step - loss: 0.7001 - accuracy: 0.8611 - val_loss: 1.6345 - val_accuracy: 0.3333\n","Epoch 17/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.5961 - accuracy: 0.8982 - val_loss: 1.3516 - val_accuracy: 0.4333\n","Epoch 18/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.4156 - accuracy: 0.9518 - val_loss: 1.5404 - val_accuracy: 0.3500\n","Epoch 19/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.3765 - accuracy: 0.9069 - val_loss: 1.6165 - val_accuracy: 0.3500\n","Epoch 20/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.2262 - accuracy: 0.9840 - val_loss: 1.7164 - val_accuracy: 0.3667\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faee207a560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faee207a560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_37/bert/pooler/dense/kernel:0', 'tf_bert_model_37/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_37/bert/pooler/dense/kernel:0', 'tf_bert_model_37/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_37/bert/pooler/dense/kernel:0', 'tf_bert_model_37/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_37/bert/pooler/dense/kernel:0', 'tf_bert_model_37/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.5043 - accuracy: 0.3617WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 88s 2s/step - loss: 2.4823 - accuracy: 0.3584 - val_loss: 1.0805 - val_accuracy: 0.3833\n","Epoch 2/20\n","6/6 [==============================] - 1s 242ms/step - loss: 1.9706 - accuracy: 0.4721 - val_loss: 1.0736 - val_accuracy: 0.4167\n","Epoch 3/20\n","6/6 [==============================] - 1s 244ms/step - loss: 2.0237 - accuracy: 0.2575 - val_loss: 1.1602 - val_accuracy: 0.3667\n","Epoch 4/20\n","6/6 [==============================] - 1s 249ms/step - loss: 2.1684 - accuracy: 0.4554 - val_loss: 1.1167 - val_accuracy: 0.4167\n","Epoch 5/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.8984 - accuracy: 0.2572 - val_loss: 1.0971 - val_accuracy: 0.4500\n","Epoch 6/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.7377 - accuracy: 0.5731 - val_loss: 1.0847 - val_accuracy: 0.3833\n","Epoch 7/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.9048 - accuracy: 0.4546 - val_loss: 1.0976 - val_accuracy: 0.4333\n","Epoch 8/20\n","6/6 [==============================] - 1s 251ms/step - loss: 1.6855 - accuracy: 0.4609 - val_loss: 1.1260 - val_accuracy: 0.3667\n","Epoch 9/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.6900 - accuracy: 0.5930 - val_loss: 1.0538 - val_accuracy: 0.4000\n","Epoch 10/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.5713 - accuracy: 0.5108 - val_loss: 1.0861 - val_accuracy: 0.4333\n","Epoch 11/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.4123 - accuracy: 0.6737 - val_loss: 1.0382 - val_accuracy: 0.4833\n","Epoch 12/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.2926 - accuracy: 0.6654 - val_loss: 1.0760 - val_accuracy: 0.4667\n","Epoch 13/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.1404 - accuracy: 0.7041 - val_loss: 1.0948 - val_accuracy: 0.5000\n","Epoch 14/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.0655 - accuracy: 0.7903 - val_loss: 1.1030 - val_accuracy: 0.4667\n","Epoch 15/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.8068 - accuracy: 0.8192 - val_loss: 1.1880 - val_accuracy: 0.4667\n","Epoch 16/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.6492 - accuracy: 0.8639 - val_loss: 1.3020 - val_accuracy: 0.5000\n","Epoch 17/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.5445 - accuracy: 0.9001 - val_loss: 1.3166 - val_accuracy: 0.4833\n","Epoch 18/20\n","6/6 [==============================] - 2s 465ms/step - loss: 0.3650 - accuracy: 0.9429 - val_loss: 1.2586 - val_accuracy: 0.5000\n","Epoch 19/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.2877 - accuracy: 0.9373 - val_loss: 1.4472 - val_accuracy: 0.4833\n","Epoch 20/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.2150 - accuracy: 0.9811 - val_loss: 1.3548 - val_accuracy: 0.4833\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faebf23e170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faebf23e170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_38/bert/pooler/dense/kernel:0', 'tf_bert_model_38/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_38/bert/pooler/dense/kernel:0', 'tf_bert_model_38/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_38/bert/pooler/dense/kernel:0', 'tf_bert_model_38/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_38/bert/pooler/dense/kernel:0', 'tf_bert_model_38/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.8491 - accuracy: 0.2394WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 88s 2s/step - loss: 2.8153 - accuracy: 0.2476 - val_loss: 1.4668 - val_accuracy: 0.3333\n","Epoch 2/20\n","6/6 [==============================] - 1s 245ms/step - loss: 2.4608 - accuracy: 0.2394 - val_loss: 1.1727 - val_accuracy: 0.4000\n","Epoch 3/20\n","6/6 [==============================] - 2s 409ms/step - loss: 1.9216 - accuracy: 0.2689 - val_loss: 1.1421 - val_accuracy: 0.3333\n","Epoch 4/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.9283 - accuracy: 0.4516 - val_loss: 1.1654 - val_accuracy: 0.3833\n","Epoch 5/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.9718 - accuracy: 0.3969 - val_loss: 1.1359 - val_accuracy: 0.3667\n","Epoch 6/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.7888 - accuracy: 0.4605 - val_loss: 1.1445 - val_accuracy: 0.3500\n","Epoch 7/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.6902 - accuracy: 0.5703 - val_loss: 1.1411 - val_accuracy: 0.3500\n","Epoch 8/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.5606 - accuracy: 0.5734 - val_loss: 1.1559 - val_accuracy: 0.3667\n","Epoch 9/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.4155 - accuracy: 0.6800 - val_loss: 1.1535 - val_accuracy: 0.3833\n","Epoch 10/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.4328 - accuracy: 0.6626 - val_loss: 1.1792 - val_accuracy: 0.4333\n","Epoch 11/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.1804 - accuracy: 0.8049 - val_loss: 1.1785 - val_accuracy: 0.4000\n","Epoch 12/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.1058 - accuracy: 0.7218 - val_loss: 1.2515 - val_accuracy: 0.4333\n","Epoch 13/20\n","6/6 [==============================] - 1s 243ms/step - loss: 0.9127 - accuracy: 0.8592 - val_loss: 1.2158 - val_accuracy: 0.4500\n","Epoch 14/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.7421 - accuracy: 0.8297 - val_loss: 1.3943 - val_accuracy: 0.4833\n","Epoch 15/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.6565 - accuracy: 0.8957 - val_loss: 1.3133 - val_accuracy: 0.4500\n","Epoch 16/20\n","6/6 [==============================] - 1s 243ms/step - loss: 0.5333 - accuracy: 0.8642 - val_loss: 1.5821 - val_accuracy: 0.5167\n","Epoch 17/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.3758 - accuracy: 0.9564 - val_loss: 1.2680 - val_accuracy: 0.4333\n","Epoch 18/20\n","6/6 [==============================] - 1s 242ms/step - loss: 0.3455 - accuracy: 0.9307 - val_loss: 1.4780 - val_accuracy: 0.5000\n","Epoch 19/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.2448 - accuracy: 0.9683 - val_loss: 1.3561 - val_accuracy: 0.5333\n","Epoch 20/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.1990 - accuracy: 0.9760 - val_loss: 1.4820 - val_accuracy: 0.5000\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faec9543170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faec9543170> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_39/bert/pooler/dense/kernel:0', 'tf_bert_model_39/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_39/bert/pooler/dense/kernel:0', 'tf_bert_model_39/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_39/bert/pooler/dense/kernel:0', 'tf_bert_model_39/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_39/bert/pooler/dense/kernel:0', 'tf_bert_model_39/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.3918 - accuracy: 0.3711WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 86s 2s/step - loss: 2.3837 - accuracy: 0.3761 - val_loss: 1.1037 - val_accuracy: 0.3500\n","Epoch 2/20\n","6/6 [==============================] - 1s 247ms/step - loss: 2.0246 - accuracy: 0.2733 - val_loss: 1.1496 - val_accuracy: 0.2833\n","Epoch 3/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.8989 - accuracy: 0.5005 - val_loss: 1.1209 - val_accuracy: 0.3667\n","Epoch 4/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.9343 - accuracy: 0.3388 - val_loss: 1.0747 - val_accuracy: 0.4333\n","Epoch 5/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.8580 - accuracy: 0.3805 - val_loss: 1.0896 - val_accuracy: 0.4167\n","Epoch 6/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.8123 - accuracy: 0.4948 - val_loss: 1.0479 - val_accuracy: 0.4667\n","Epoch 7/20\n","6/6 [==============================] - 2s 436ms/step - loss: 1.8150 - accuracy: 0.3841 - val_loss: 1.1171 - val_accuracy: 0.4167\n","Epoch 8/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.7854 - accuracy: 0.5834 - val_loss: 1.0871 - val_accuracy: 0.4500\n","Epoch 9/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.4634 - accuracy: 0.5618 - val_loss: 1.0863 - val_accuracy: 0.4500\n","Epoch 10/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.3640 - accuracy: 0.6407 - val_loss: 1.1178 - val_accuracy: 0.4667\n","Epoch 11/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.3278 - accuracy: 0.6837 - val_loss: 1.1237 - val_accuracy: 0.4833\n","Epoch 12/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.0874 - accuracy: 0.7287 - val_loss: 1.2248 - val_accuracy: 0.3833\n","Epoch 13/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.0020 - accuracy: 0.7714 - val_loss: 1.2157 - val_accuracy: 0.5000\n","Epoch 14/20\n","6/6 [==============================] - 1s 242ms/step - loss: 0.7920 - accuracy: 0.7904 - val_loss: 1.5341 - val_accuracy: 0.3500\n","Epoch 15/20\n","6/6 [==============================] - 1s 241ms/step - loss: 0.6646 - accuracy: 0.8625 - val_loss: 1.4182 - val_accuracy: 0.5000\n","Epoch 16/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.4917 - accuracy: 0.9012 - val_loss: 1.6268 - val_accuracy: 0.4167\n","Epoch 17/20\n","6/6 [==============================] - 1s 243ms/step - loss: 0.3369 - accuracy: 0.9228 - val_loss: 1.7553 - val_accuracy: 0.4000\n","Epoch 18/20\n","6/6 [==============================] - 1s 243ms/step - loss: 0.3274 - accuracy: 0.9387 - val_loss: 1.8207 - val_accuracy: 0.4333\n","Epoch 19/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.2657 - accuracy: 0.9328 - val_loss: 1.9562 - val_accuracy: 0.3667\n","Epoch 20/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.1857 - accuracy: 0.9869 - val_loss: 1.9363 - val_accuracy: 0.4167\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faed80bdb90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faed80bdb90> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_40/bert/pooler/dense/kernel:0', 'tf_bert_model_40/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_40/bert/pooler/dense/kernel:0', 'tf_bert_model_40/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_40/bert/pooler/dense/kernel:0', 'tf_bert_model_40/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_40/bert/pooler/dense/kernel:0', 'tf_bert_model_40/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.8414 - accuracy: 0.2907WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 89s 2s/step - loss: 2.8152 - accuracy: 0.2942 - val_loss: 1.3188 - val_accuracy: 0.3333\n","Epoch 2/20\n","6/6 [==============================] - 1s 243ms/step - loss: 2.1385 - accuracy: 0.2368 - val_loss: 1.2799 - val_accuracy: 0.3167\n","Epoch 3/20\n","6/6 [==============================] - 1s 246ms/step - loss: 2.0433 - accuracy: 0.4072 - val_loss: 1.1289 - val_accuracy: 0.3500\n","Epoch 4/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.9888 - accuracy: 0.2843 - val_loss: 1.1206 - val_accuracy: 0.3333\n","Epoch 5/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.8025 - accuracy: 0.4913 - val_loss: 1.1568 - val_accuracy: 0.3333\n","Epoch 6/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.9021 - accuracy: 0.3987 - val_loss: 1.1390 - val_accuracy: 0.3667\n","Epoch 7/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.8137 - accuracy: 0.3691 - val_loss: 1.1310 - val_accuracy: 0.3167\n","Epoch 8/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.7964 - accuracy: 0.4247 - val_loss: 1.1136 - val_accuracy: 0.3167\n","Epoch 9/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.7191 - accuracy: 0.5000 - val_loss: 1.1247 - val_accuracy: 0.3000\n","Epoch 10/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.6346 - accuracy: 0.5682 - val_loss: 1.1109 - val_accuracy: 0.3500\n","Epoch 11/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.5500 - accuracy: 0.5447 - val_loss: 1.1620 - val_accuracy: 0.4000\n","Epoch 12/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.5963 - accuracy: 0.6141 - val_loss: 1.1061 - val_accuracy: 0.4167\n","Epoch 13/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.3758 - accuracy: 0.6592 - val_loss: 1.1526 - val_accuracy: 0.4667\n","Epoch 14/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.1351 - accuracy: 0.7220 - val_loss: 1.1922 - val_accuracy: 0.4500\n","Epoch 15/20\n","6/6 [==============================] - 2s 460ms/step - loss: 1.1129 - accuracy: 0.7429 - val_loss: 1.1948 - val_accuracy: 0.5333\n","Epoch 16/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.8527 - accuracy: 0.8508 - val_loss: 1.1409 - val_accuracy: 0.5333\n","Epoch 17/20\n","6/6 [==============================] - 1s 257ms/step - loss: 0.7675 - accuracy: 0.8382 - val_loss: 1.3282 - val_accuracy: 0.4667\n","Epoch 18/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.5619 - accuracy: 0.9433 - val_loss: 1.2287 - val_accuracy: 0.5000\n","Epoch 19/20\n","6/6 [==============================] - 1s 243ms/step - loss: 0.4131 - accuracy: 0.9361 - val_loss: 1.4661 - val_accuracy: 0.4667\n","Epoch 20/20\n","6/6 [==============================] - 1s 243ms/step - loss: 0.3401 - accuracy: 0.9478 - val_loss: 1.4312 - val_accuracy: 0.5667\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faee9b164d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faee9b164d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_41/bert/pooler/dense/kernel:0', 'tf_bert_model_41/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_41/bert/pooler/dense/kernel:0', 'tf_bert_model_41/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_41/bert/pooler/dense/kernel:0', 'tf_bert_model_41/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_41/bert/pooler/dense/kernel:0', 'tf_bert_model_41/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.2471 - accuracy: 0.3679WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 89s 2s/step - loss: 2.2565 - accuracy: 0.3641 - val_loss: 1.0807 - val_accuracy: 0.4667\n","Epoch 2/20\n","6/6 [==============================] - 1s 244ms/step - loss: 2.0926 - accuracy: 0.3058 - val_loss: 1.0783 - val_accuracy: 0.4167\n","Epoch 3/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.9986 - accuracy: 0.3095 - val_loss: 1.1099 - val_accuracy: 0.3667\n","Epoch 4/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.8554 - accuracy: 0.4714 - val_loss: 1.1331 - val_accuracy: 0.5333\n","Epoch 5/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.7874 - accuracy: 0.4568 - val_loss: 1.0892 - val_accuracy: 0.4833\n","Epoch 6/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.6421 - accuracy: 0.5548 - val_loss: 1.1056 - val_accuracy: 0.4500\n","Epoch 7/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.4752 - accuracy: 0.6241 - val_loss: 1.0834 - val_accuracy: 0.5333\n","Epoch 8/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.3580 - accuracy: 0.6462 - val_loss: 1.1241 - val_accuracy: 0.5000\n","Epoch 9/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.0953 - accuracy: 0.7546 - val_loss: 1.1174 - val_accuracy: 0.5000\n","Epoch 10/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.9838 - accuracy: 0.7449 - val_loss: 1.1674 - val_accuracy: 0.4500\n","Epoch 11/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.8510 - accuracy: 0.8215 - val_loss: 1.1549 - val_accuracy: 0.4833\n","Epoch 12/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.6758 - accuracy: 0.8352 - val_loss: 1.3301 - val_accuracy: 0.4500\n","Epoch 13/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.5606 - accuracy: 0.9148 - val_loss: 1.3071 - val_accuracy: 0.4667\n","Epoch 14/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.4363 - accuracy: 0.9058 - val_loss: 1.4766 - val_accuracy: 0.4833\n","Epoch 15/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.3149 - accuracy: 0.9502 - val_loss: 1.4883 - val_accuracy: 0.4333\n","Epoch 16/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.2831 - accuracy: 0.9567 - val_loss: 1.5186 - val_accuracy: 0.4667\n","Epoch 17/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.2308 - accuracy: 0.9514 - val_loss: 1.6431 - val_accuracy: 0.4500\n","Epoch 18/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.1688 - accuracy: 0.9944 - val_loss: 1.4902 - val_accuracy: 0.5167\n","Epoch 19/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.1225 - accuracy: 0.9796 - val_loss: 1.6448 - val_accuracy: 0.4833\n","Epoch 20/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.1383 - accuracy: 0.9939 - val_loss: 1.6082 - val_accuracy: 0.5000\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faecb6c2290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faecb6c2290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_42/bert/pooler/dense/kernel:0', 'tf_bert_model_42/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_42/bert/pooler/dense/kernel:0', 'tf_bert_model_42/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_42/bert/pooler/dense/kernel:0', 'tf_bert_model_42/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_42/bert/pooler/dense/kernel:0', 'tf_bert_model_42/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 3.8408 - accuracy: 0.3552WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 85s 2s/step - loss: 3.7173 - accuracy: 0.3487 - val_loss: 1.1694 - val_accuracy: 0.2833\n","Epoch 2/20\n","6/6 [==============================] - 2s 415ms/step - loss: 2.2208 - accuracy: 0.4638 - val_loss: 1.2925 - val_accuracy: 0.3333\n","Epoch 3/20\n","6/6 [==============================] - 1s 245ms/step - loss: 2.1137 - accuracy: 0.2475 - val_loss: 1.1229 - val_accuracy: 0.3167\n","Epoch 4/20\n","6/6 [==============================] - 1s 253ms/step - loss: 1.9104 - accuracy: 0.3751 - val_loss: 1.1370 - val_accuracy: 0.4167\n","Epoch 5/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.9270 - accuracy: 0.4325 - val_loss: 1.1604 - val_accuracy: 0.3667\n","Epoch 6/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.9694 - accuracy: 0.2622 - val_loss: 1.1376 - val_accuracy: 0.3500\n","Epoch 7/20\n","6/6 [==============================] - 1s 251ms/step - loss: 1.8784 - accuracy: 0.4129 - val_loss: 1.2047 - val_accuracy: 0.3667\n","Epoch 8/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.9606 - accuracy: 0.3949 - val_loss: 1.1268 - val_accuracy: 0.3333\n","Epoch 9/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.8379 - accuracy: 0.3828 - val_loss: 1.1277 - val_accuracy: 0.4167\n","Epoch 10/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.6596 - accuracy: 0.5587 - val_loss: 1.1156 - val_accuracy: 0.4333\n","Epoch 11/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.7789 - accuracy: 0.5154 - val_loss: 1.1236 - val_accuracy: 0.3667\n","Epoch 12/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.5521 - accuracy: 0.5586 - val_loss: 1.1114 - val_accuracy: 0.4333\n","Epoch 13/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.3988 - accuracy: 0.7321 - val_loss: 1.1093 - val_accuracy: 0.4000\n","Epoch 14/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.3417 - accuracy: 0.5392 - val_loss: 1.1582 - val_accuracy: 0.4000\n","Epoch 15/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.1977 - accuracy: 0.7909 - val_loss: 1.1190 - val_accuracy: 0.5167\n","Epoch 16/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.0770 - accuracy: 0.6876 - val_loss: 1.1933 - val_accuracy: 0.4333\n","Epoch 17/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.8410 - accuracy: 0.8577 - val_loss: 1.1829 - val_accuracy: 0.4667\n","Epoch 18/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.6695 - accuracy: 0.8619 - val_loss: 1.2434 - val_accuracy: 0.4000\n","Epoch 19/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.5748 - accuracy: 0.8829 - val_loss: 1.2978 - val_accuracy: 0.4833\n","Epoch 20/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.4626 - accuracy: 0.9544 - val_loss: 1.3801 - val_accuracy: 0.4333\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faec19a7c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faec19a7c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_43/bert/pooler/dense/kernel:0', 'tf_bert_model_43/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_43/bert/pooler/dense/kernel:0', 'tf_bert_model_43/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_43/bert/pooler/dense/kernel:0', 'tf_bert_model_43/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_43/bert/pooler/dense/kernel:0', 'tf_bert_model_43/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.6880 - accuracy: 0.3093WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 87s 2s/step - loss: 2.6569 - accuracy: 0.3153 - val_loss: 1.3499 - val_accuracy: 0.3167\n","Epoch 2/20\n","6/6 [==============================] - 1s 239ms/step - loss: 2.1017 - accuracy: 0.2256 - val_loss: 1.1261 - val_accuracy: 0.3833\n","Epoch 3/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.8510 - accuracy: 0.5161 - val_loss: 1.1567 - val_accuracy: 0.3833\n","Epoch 4/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.9799 - accuracy: 0.2957 - val_loss: 1.1396 - val_accuracy: 0.3833\n","Epoch 5/20\n","6/6 [==============================] - 2s 423ms/step - loss: 1.9047 - accuracy: 0.5501 - val_loss: 1.1307 - val_accuracy: 0.3833\n","Epoch 6/20\n","6/6 [==============================] - 1s 242ms/step - loss: 1.8141 - accuracy: 0.3498 - val_loss: 1.0419 - val_accuracy: 0.5167\n","Epoch 7/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.6362 - accuracy: 0.5768 - val_loss: 1.0085 - val_accuracy: 0.5167\n","Epoch 8/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.4522 - accuracy: 0.6483 - val_loss: 1.0127 - val_accuracy: 0.4333\n","Epoch 9/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.4576 - accuracy: 0.5945 - val_loss: 1.0111 - val_accuracy: 0.5333\n","Epoch 10/20\n","6/6 [==============================] - 1s 242ms/step - loss: 1.2235 - accuracy: 0.7557 - val_loss: 0.9673 - val_accuracy: 0.5000\n","Epoch 11/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.1961 - accuracy: 0.7071 - val_loss: 0.9677 - val_accuracy: 0.5167\n","Epoch 12/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.0194 - accuracy: 0.7648 - val_loss: 0.9927 - val_accuracy: 0.4667\n","Epoch 13/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.8644 - accuracy: 0.8385 - val_loss: 0.9730 - val_accuracy: 0.5333\n","Epoch 14/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.7186 - accuracy: 0.8519 - val_loss: 1.1399 - val_accuracy: 0.5000\n","Epoch 15/20\n","6/6 [==============================] - 1s 242ms/step - loss: 0.6094 - accuracy: 0.8754 - val_loss: 1.0086 - val_accuracy: 0.5667\n","Epoch 16/20\n","6/6 [==============================] - 1s 242ms/step - loss: 0.4139 - accuracy: 0.9603 - val_loss: 1.1097 - val_accuracy: 0.4667\n","Epoch 17/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.3083 - accuracy: 0.9544 - val_loss: 1.2457 - val_accuracy: 0.4833\n","Epoch 18/20\n","6/6 [==============================] - 1s 243ms/step - loss: 0.3303 - accuracy: 0.9618 - val_loss: 1.1117 - val_accuracy: 0.5333\n","Epoch 19/20\n","6/6 [==============================] - 1s 242ms/step - loss: 0.2200 - accuracy: 0.9801 - val_loss: 1.3249 - val_accuracy: 0.4833\n","Epoch 20/20\n","6/6 [==============================] - 1s 243ms/step - loss: 0.1868 - accuracy: 0.9879 - val_loss: 1.1761 - val_accuracy: 0.5167\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9d8978c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9d8978c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_44/bert/pooler/dense/kernel:0', 'tf_bert_model_44/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_44/bert/pooler/dense/kernel:0', 'tf_bert_model_44/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_44/bert/pooler/dense/kernel:0', 'tf_bert_model_44/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_44/bert/pooler/dense/kernel:0', 'tf_bert_model_44/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.7373 - accuracy: 0.3716WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 89s 2s/step - loss: 2.7240 - accuracy: 0.3646 - val_loss: 1.2028 - val_accuracy: 0.3500\n","Epoch 2/20\n","6/6 [==============================] - 1s 242ms/step - loss: 2.0789 - accuracy: 0.5495 - val_loss: 1.1299 - val_accuracy: 0.3667\n","Epoch 3/20\n","6/6 [==============================] - 1s 244ms/step - loss: 2.0086 - accuracy: 0.2647 - val_loss: 1.0898 - val_accuracy: 0.4000\n","Epoch 4/20\n","6/6 [==============================] - 1s 245ms/step - loss: 2.0935 - accuracy: 0.4706 - val_loss: 1.0606 - val_accuracy: 0.4333\n","Epoch 5/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.7838 - accuracy: 0.3052 - val_loss: 1.0599 - val_accuracy: 0.5167\n","Epoch 6/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.7635 - accuracy: 0.4884 - val_loss: 1.0620 - val_accuracy: 0.4333\n","Epoch 7/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.7922 - accuracy: 0.4603 - val_loss: 1.0503 - val_accuracy: 0.5000\n","Epoch 8/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.8017 - accuracy: 0.4837 - val_loss: 1.0809 - val_accuracy: 0.4333\n","Epoch 9/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.7196 - accuracy: 0.5379 - val_loss: 1.0274 - val_accuracy: 0.5000\n","Epoch 10/20\n","6/6 [==============================] - 1s 242ms/step - loss: 1.5584 - accuracy: 0.5276 - val_loss: 1.0285 - val_accuracy: 0.4833\n","Epoch 11/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.3699 - accuracy: 0.6989 - val_loss: 1.0927 - val_accuracy: 0.4833\n","Epoch 12/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.2322 - accuracy: 0.7518 - val_loss: 1.0839 - val_accuracy: 0.4833\n","Epoch 13/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.1334 - accuracy: 0.7346 - val_loss: 1.1429 - val_accuracy: 0.4500\n","Epoch 14/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.0582 - accuracy: 0.7459 - val_loss: 1.1416 - val_accuracy: 0.4667\n","Epoch 15/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.7364 - accuracy: 0.8272 - val_loss: 1.4003 - val_accuracy: 0.4667\n","Epoch 16/20\n","6/6 [==============================] - 2s 455ms/step - loss: 0.6983 - accuracy: 0.8871 - val_loss: 1.2431 - val_accuracy: 0.4500\n","Epoch 17/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.5115 - accuracy: 0.9179 - val_loss: 1.5120 - val_accuracy: 0.4833\n","Epoch 18/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.4367 - accuracy: 0.9471 - val_loss: 1.2726 - val_accuracy: 0.5167\n","Epoch 19/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.3345 - accuracy: 0.9477 - val_loss: 1.6028 - val_accuracy: 0.4333\n","Epoch 20/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.3040 - accuracy: 0.9615 - val_loss: 1.3625 - val_accuracy: 0.4833\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9b8ed200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9b8ed200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_45/bert/pooler/dense/kernel:0', 'tf_bert_model_45/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_45/bert/pooler/dense/kernel:0', 'tf_bert_model_45/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_45/bert/pooler/dense/kernel:0', 'tf_bert_model_45/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_45/bert/pooler/dense/kernel:0', 'tf_bert_model_45/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.6311 - accuracy: 0.3594WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 89s 2s/step - loss: 2.6295 - accuracy: 0.3601 - val_loss: 1.2377 - val_accuracy: 0.3333\n","Epoch 2/20\n","6/6 [==============================] - 1s 243ms/step - loss: 2.0866 - accuracy: 0.4134 - val_loss: 1.2728 - val_accuracy: 0.3333\n","Epoch 3/20\n","6/6 [==============================] - 1s 244ms/step - loss: 2.0407 - accuracy: 0.3142 - val_loss: 1.1555 - val_accuracy: 0.3167\n","Epoch 4/20\n","6/6 [==============================] - 1s 249ms/step - loss: 2.0510 - accuracy: 0.5541 - val_loss: 1.1536 - val_accuracy: 0.3333\n","Epoch 5/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.9219 - accuracy: 0.3550 - val_loss: 1.1861 - val_accuracy: 0.3167\n","Epoch 6/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.8603 - accuracy: 0.3167 - val_loss: 1.1342 - val_accuracy: 0.3667\n","Epoch 7/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.6751 - accuracy: 0.5359 - val_loss: 1.1073 - val_accuracy: 0.4333\n","Epoch 8/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.6873 - accuracy: 0.4822 - val_loss: 1.1162 - val_accuracy: 0.3667\n","Epoch 9/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.6097 - accuracy: 0.5496 - val_loss: 1.1102 - val_accuracy: 0.3833\n","Epoch 10/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.4698 - accuracy: 0.6127 - val_loss: 1.1260 - val_accuracy: 0.4167\n","Epoch 11/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.4888 - accuracy: 0.6240 - val_loss: 1.1555 - val_accuracy: 0.4167\n","Epoch 12/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.2892 - accuracy: 0.7253 - val_loss: 1.1642 - val_accuracy: 0.4500\n","Epoch 13/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.0436 - accuracy: 0.7613 - val_loss: 1.1907 - val_accuracy: 0.4500\n","Epoch 14/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.9259 - accuracy: 0.7910 - val_loss: 1.2385 - val_accuracy: 0.4333\n","Epoch 15/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.8058 - accuracy: 0.8599 - val_loss: 1.2749 - val_accuracy: 0.4667\n","Epoch 16/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.6043 - accuracy: 0.9165 - val_loss: 1.3504 - val_accuracy: 0.4167\n","Epoch 17/20\n","6/6 [==============================] - 1s 242ms/step - loss: 0.4906 - accuracy: 0.9189 - val_loss: 1.3091 - val_accuracy: 0.4333\n","Epoch 18/20\n","6/6 [==============================] - 1s 242ms/step - loss: 0.4196 - accuracy: 0.9366 - val_loss: 1.4449 - val_accuracy: 0.4333\n","Epoch 19/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.3185 - accuracy: 0.9630 - val_loss: 1.4123 - val_accuracy: 0.4500\n","Epoch 20/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.2762 - accuracy: 0.9760 - val_loss: 1.4625 - val_accuracy: 0.4333\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9d43c680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9d43c680> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_46/bert/pooler/dense/kernel:0', 'tf_bert_model_46/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_46/bert/pooler/dense/kernel:0', 'tf_bert_model_46/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_46/bert/pooler/dense/kernel:0', 'tf_bert_model_46/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_46/bert/pooler/dense/kernel:0', 'tf_bert_model_46/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.3179 - accuracy: 0.3608WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 88s 2s/step - loss: 2.3233 - accuracy: 0.3568 - val_loss: 1.1527 - val_accuracy: 0.4500\n","Epoch 2/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.9825 - accuracy: 0.3249 - val_loss: 1.2666 - val_accuracy: 0.3667\n","Epoch 3/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.9430 - accuracy: 0.4874 - val_loss: 1.1517 - val_accuracy: 0.4167\n","Epoch 4/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.8911 - accuracy: 0.3919 - val_loss: 1.1913 - val_accuracy: 0.3833\n","Epoch 5/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.9251 - accuracy: 0.4142 - val_loss: 1.1620 - val_accuracy: 0.3667\n","Epoch 6/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.7365 - accuracy: 0.4548 - val_loss: 1.1975 - val_accuracy: 0.4000\n","Epoch 7/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.7151 - accuracy: 0.6027 - val_loss: 1.1556 - val_accuracy: 0.3500\n","Epoch 8/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.6522 - accuracy: 0.5492 - val_loss: 1.1862 - val_accuracy: 0.4333\n","Epoch 9/20\n","6/6 [==============================] - 1s 251ms/step - loss: 1.5003 - accuracy: 0.6562 - val_loss: 1.1019 - val_accuracy: 0.4167\n","Epoch 10/20\n","6/6 [==============================] - 1s 251ms/step - loss: 1.2582 - accuracy: 0.7146 - val_loss: 1.1224 - val_accuracy: 0.4500\n","Epoch 11/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.2746 - accuracy: 0.6471 - val_loss: 1.1321 - val_accuracy: 0.4333\n","Epoch 12/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.1034 - accuracy: 0.7749 - val_loss: 1.1494 - val_accuracy: 0.4167\n","Epoch 13/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.9585 - accuracy: 0.7821 - val_loss: 1.1757 - val_accuracy: 0.4167\n","Epoch 14/20\n","6/6 [==============================] - 1s 243ms/step - loss: 0.7276 - accuracy: 0.8850 - val_loss: 1.2488 - val_accuracy: 0.4167\n","Epoch 15/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.5947 - accuracy: 0.9072 - val_loss: 1.2921 - val_accuracy: 0.4000\n","Epoch 16/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.4688 - accuracy: 0.9379 - val_loss: 1.4068 - val_accuracy: 0.4167\n","Epoch 17/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.3530 - accuracy: 0.9557 - val_loss: 1.3119 - val_accuracy: 0.4500\n","Epoch 18/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.3017 - accuracy: 0.9687 - val_loss: 1.4332 - val_accuracy: 0.4000\n","Epoch 19/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.2463 - accuracy: 0.9484 - val_loss: 1.4303 - val_accuracy: 0.4500\n","Epoch 20/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.1968 - accuracy: 0.9790 - val_loss: 1.5540 - val_accuracy: 0.4333\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faec3e8e7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faec3e8e7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_47/bert/pooler/dense/kernel:0', 'tf_bert_model_47/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_47/bert/pooler/dense/kernel:0', 'tf_bert_model_47/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_47/bert/pooler/dense/kernel:0', 'tf_bert_model_47/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_47/bert/pooler/dense/kernel:0', 'tf_bert_model_47/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.6536 - accuracy: 0.3204WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 86s 2s/step - loss: 2.6268 - accuracy: 0.3182 - val_loss: 1.1209 - val_accuracy: 0.3833\n","Epoch 2/20\n","6/6 [==============================] - 2s 412ms/step - loss: 2.2086 - accuracy: 0.2749 - val_loss: 1.0994 - val_accuracy: 0.3667\n","Epoch 3/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.9262 - accuracy: 0.4425 - val_loss: 1.0922 - val_accuracy: 0.4000\n","Epoch 4/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.9604 - accuracy: 0.2696 - val_loss: 1.0890 - val_accuracy: 0.3833\n","Epoch 5/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.9435 - accuracy: 0.5183 - val_loss: 1.0661 - val_accuracy: 0.4167\n","Epoch 6/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.9012 - accuracy: 0.3355 - val_loss: 1.0637 - val_accuracy: 0.4833\n","Epoch 7/20\n","6/6 [==============================] - 1s 251ms/step - loss: 1.7677 - accuracy: 0.4926 - val_loss: 1.0608 - val_accuracy: 0.4000\n","Epoch 8/20\n","6/6 [==============================] - 1s 251ms/step - loss: 1.7807 - accuracy: 0.3612 - val_loss: 1.0619 - val_accuracy: 0.4667\n","Epoch 9/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.7943 - accuracy: 0.5519 - val_loss: 1.0595 - val_accuracy: 0.4000\n","Epoch 10/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.7068 - accuracy: 0.4729 - val_loss: 1.0363 - val_accuracy: 0.5333\n","Epoch 11/20\n","6/6 [==============================] - 1s 251ms/step - loss: 1.4955 - accuracy: 0.6192 - val_loss: 1.0425 - val_accuracy: 0.5333\n","Epoch 12/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.4538 - accuracy: 0.6131 - val_loss: 1.0197 - val_accuracy: 0.5167\n","Epoch 13/20\n","6/6 [==============================] - 1s 254ms/step - loss: 1.2520 - accuracy: 0.7194 - val_loss: 1.0454 - val_accuracy: 0.5667\n","Epoch 14/20\n","6/6 [==============================] - 1s 256ms/step - loss: 1.0517 - accuracy: 0.7820 - val_loss: 1.0497 - val_accuracy: 0.4833\n","Epoch 15/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.9326 - accuracy: 0.7754 - val_loss: 1.1850 - val_accuracy: 0.5000\n","Epoch 16/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.6734 - accuracy: 0.8513 - val_loss: 1.2565 - val_accuracy: 0.4833\n","Epoch 17/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.4953 - accuracy: 0.9427 - val_loss: 1.2547 - val_accuracy: 0.5333\n","Epoch 18/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.4562 - accuracy: 0.9272 - val_loss: 1.3548 - val_accuracy: 0.5000\n","Epoch 19/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.3324 - accuracy: 0.9637 - val_loss: 1.3596 - val_accuracy: 0.5000\n","Epoch 20/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.2717 - accuracy: 0.9465 - val_loss: 1.4162 - val_accuracy: 0.5000\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9cbb9200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9cbb9200> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_48/bert/pooler/dense/kernel:0', 'tf_bert_model_48/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_48/bert/pooler/dense/kernel:0', 'tf_bert_model_48/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_48/bert/pooler/dense/kernel:0', 'tf_bert_model_48/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_48/bert/pooler/dense/kernel:0', 'tf_bert_model_48/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 3.1474 - accuracy: 0.2823WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 89s 2s/step - loss: 3.1013 - accuracy: 0.2907 - val_loss: 1.1732 - val_accuracy: 0.4167\n","Epoch 2/20\n","6/6 [==============================] - 1s 247ms/step - loss: 2.2086 - accuracy: 0.2751 - val_loss: 1.1370 - val_accuracy: 0.3000\n","Epoch 3/20\n","6/6 [==============================] - 1s 245ms/step - loss: 2.0722 - accuracy: 0.4692 - val_loss: 1.0627 - val_accuracy: 0.4500\n","Epoch 4/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.9372 - accuracy: 0.2907 - val_loss: 1.0615 - val_accuracy: 0.4167\n","Epoch 5/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.9815 - accuracy: 0.3798 - val_loss: 1.0670 - val_accuracy: 0.3500\n","Epoch 6/20\n","6/6 [==============================] - 1s 244ms/step - loss: 2.0301 - accuracy: 0.4516 - val_loss: 1.0889 - val_accuracy: 0.4500\n","Epoch 7/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.8693 - accuracy: 0.2817 - val_loss: 1.0662 - val_accuracy: 0.4167\n","Epoch 8/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.9747 - accuracy: 0.5057 - val_loss: 1.0512 - val_accuracy: 0.4500\n","Epoch 9/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.8326 - accuracy: 0.3776 - val_loss: 1.0478 - val_accuracy: 0.4333\n","Epoch 10/20\n","6/6 [==============================] - 1s 259ms/step - loss: 1.8121 - accuracy: 0.4436 - val_loss: 1.0318 - val_accuracy: 0.4500\n","Epoch 11/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.7668 - accuracy: 0.4927 - val_loss: 1.0535 - val_accuracy: 0.5333\n","Epoch 12/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.8014 - accuracy: 0.4791 - val_loss: 1.0515 - val_accuracy: 0.5167\n","Epoch 13/20\n","6/6 [==============================] - 2s 450ms/step - loss: 1.6820 - accuracy: 0.5589 - val_loss: 1.0665 - val_accuracy: 0.5000\n","Epoch 14/20\n","6/6 [==============================] - 1s 252ms/step - loss: 1.4095 - accuracy: 0.6515 - val_loss: 1.1163 - val_accuracy: 0.5000\n","Epoch 15/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.3572 - accuracy: 0.6531 - val_loss: 1.0557 - val_accuracy: 0.5000\n","Epoch 16/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.0764 - accuracy: 0.7738 - val_loss: 1.1473 - val_accuracy: 0.4667\n","Epoch 17/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.0016 - accuracy: 0.7830 - val_loss: 1.1656 - val_accuracy: 0.5333\n","Epoch 18/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.7414 - accuracy: 0.8471 - val_loss: 1.2607 - val_accuracy: 0.5000\n","Epoch 19/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.6114 - accuracy: 0.8470 - val_loss: 1.5846 - val_accuracy: 0.4833\n","Epoch 20/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.5552 - accuracy: 0.9017 - val_loss: 1.3360 - val_accuracy: 0.5000\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9cc784d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9cc784d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_49/bert/pooler/dense/kernel:0', 'tf_bert_model_49/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_49/bert/pooler/dense/kernel:0', 'tf_bert_model_49/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_49/bert/pooler/dense/kernel:0', 'tf_bert_model_49/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_49/bert/pooler/dense/kernel:0', 'tf_bert_model_49/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.2455 - accuracy: 0.3547WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 90s 2s/step - loss: 2.2497 - accuracy: 0.3520 - val_loss: 1.2547 - val_accuracy: 0.3167\n","Epoch 2/20\n","6/6 [==============================] - 1s 252ms/step - loss: 2.0058 - accuracy: 0.3905 - val_loss: 1.2891 - val_accuracy: 0.3333\n","Epoch 3/20\n","6/6 [==============================] - 1s 250ms/step - loss: 2.1370 - accuracy: 0.3672 - val_loss: 1.2668 - val_accuracy: 0.3167\n","Epoch 4/20\n","6/6 [==============================] - 1s 255ms/step - loss: 1.9745 - accuracy: 0.3257 - val_loss: 1.2120 - val_accuracy: 0.2667\n","Epoch 5/20\n","6/6 [==============================] - 1s 251ms/step - loss: 1.9199 - accuracy: 0.4263 - val_loss: 1.1759 - val_accuracy: 0.3333\n","Epoch 6/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.8032 - accuracy: 0.4225 - val_loss: 1.1893 - val_accuracy: 0.3167\n","Epoch 7/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.8260 - accuracy: 0.5121 - val_loss: 1.2443 - val_accuracy: 0.3833\n","Epoch 8/20\n","6/6 [==============================] - 1s 256ms/step - loss: 1.8024 - accuracy: 0.3960 - val_loss: 1.3055 - val_accuracy: 0.2833\n","Epoch 9/20\n","6/6 [==============================] - 1s 256ms/step - loss: 1.7325 - accuracy: 0.5705 - val_loss: 1.2360 - val_accuracy: 0.3667\n","Epoch 10/20\n","6/6 [==============================] - 1s 253ms/step - loss: 1.6724 - accuracy: 0.4196 - val_loss: 1.2139 - val_accuracy: 0.2667\n","Epoch 11/20\n","6/6 [==============================] - 1s 256ms/step - loss: 1.4865 - accuracy: 0.6679 - val_loss: 1.2583 - val_accuracy: 0.3667\n","Epoch 12/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.5666 - accuracy: 0.4790 - val_loss: 1.2359 - val_accuracy: 0.3667\n","Epoch 13/20\n","6/6 [==============================] - 1s 254ms/step - loss: 1.2770 - accuracy: 0.6497 - val_loss: 1.2631 - val_accuracy: 0.3167\n","Epoch 14/20\n","6/6 [==============================] - 1s 257ms/step - loss: 1.2269 - accuracy: 0.6786 - val_loss: 1.1944 - val_accuracy: 0.4667\n","Epoch 15/20\n","6/6 [==============================] - 1s 251ms/step - loss: 0.9956 - accuracy: 0.7095 - val_loss: 1.2831 - val_accuracy: 0.4000\n","Epoch 16/20\n","6/6 [==============================] - 1s 251ms/step - loss: 0.8090 - accuracy: 0.8384 - val_loss: 1.3057 - val_accuracy: 0.3500\n","Epoch 17/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.6950 - accuracy: 0.8254 - val_loss: 1.3008 - val_accuracy: 0.4333\n","Epoch 18/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.5823 - accuracy: 0.9142 - val_loss: 1.2821 - val_accuracy: 0.4000\n","Epoch 19/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.5333 - accuracy: 0.8598 - val_loss: 1.3213 - val_accuracy: 0.4000\n","Epoch 20/20\n","6/6 [==============================] - 1s 251ms/step - loss: 0.4608 - accuracy: 0.9317 - val_loss: 1.2566 - val_accuracy: 0.4333\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9d8d1440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9d8d1440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 12s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_50/bert/pooler/dense/kernel:0', 'tf_bert_model_50/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_50/bert/pooler/dense/kernel:0', 'tf_bert_model_50/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_50/bert/pooler/dense/kernel:0', 'tf_bert_model_50/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_50/bert/pooler/dense/kernel:0', 'tf_bert_model_50/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.5047 - accuracy: 0.2747WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 88s 2s/step - loss: 2.4888 - accuracy: 0.2749 - val_loss: 1.2477 - val_accuracy: 0.3333\n","Epoch 2/20\n","6/6 [==============================] - 1s 252ms/step - loss: 2.2552 - accuracy: 0.2291 - val_loss: 1.1435 - val_accuracy: 0.4000\n","Epoch 3/20\n","6/6 [==============================] - 1s 246ms/step - loss: 2.1411 - accuracy: 0.3362 - val_loss: 1.1157 - val_accuracy: 0.3500\n","Epoch 4/20\n","6/6 [==============================] - 1s 245ms/step - loss: 2.0080 - accuracy: 0.3708 - val_loss: 1.1041 - val_accuracy: 0.4000\n","Epoch 5/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.9737 - accuracy: 0.2899 - val_loss: 1.0982 - val_accuracy: 0.4167\n","Epoch 6/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.9216 - accuracy: 0.4079 - val_loss: 1.0824 - val_accuracy: 0.4167\n","Epoch 7/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.8470 - accuracy: 0.3688 - val_loss: 1.1143 - val_accuracy: 0.3500\n","Epoch 8/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.7766 - accuracy: 0.5972 - val_loss: 1.1087 - val_accuracy: 0.4000\n","Epoch 9/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.7072 - accuracy: 0.4548 - val_loss: 1.1532 - val_accuracy: 0.3667\n","Epoch 10/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.5285 - accuracy: 0.6567 - val_loss: 1.1119 - val_accuracy: 0.4000\n","Epoch 11/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.3097 - accuracy: 0.6312 - val_loss: 1.1385 - val_accuracy: 0.4667\n","Epoch 12/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.2082 - accuracy: 0.7611 - val_loss: 1.1706 - val_accuracy: 0.4333\n","Epoch 13/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.0390 - accuracy: 0.7839 - val_loss: 1.1622 - val_accuracy: 0.4667\n","Epoch 14/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.8969 - accuracy: 0.7506 - val_loss: 1.2787 - val_accuracy: 0.3500\n","Epoch 15/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.7902 - accuracy: 0.8685 - val_loss: 1.2447 - val_accuracy: 0.4667\n","Epoch 16/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.5741 - accuracy: 0.8772 - val_loss: 1.3453 - val_accuracy: 0.4167\n","Epoch 17/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.4429 - accuracy: 0.9272 - val_loss: 1.3039 - val_accuracy: 0.4833\n","Epoch 18/20\n","6/6 [==============================] - 1s 243ms/step - loss: 0.3031 - accuracy: 0.9606 - val_loss: 1.3403 - val_accuracy: 0.4667\n","Epoch 19/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.2467 - accuracy: 0.9786 - val_loss: 1.3905 - val_accuracy: 0.4333\n","Epoch 20/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.2026 - accuracy: 0.9629 - val_loss: 1.5476 - val_accuracy: 0.4833\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faed0a38a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faed0a38a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 12s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_51/bert/pooler/dense/kernel:0', 'tf_bert_model_51/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_51/bert/pooler/dense/kernel:0', 'tf_bert_model_51/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_51/bert/pooler/dense/kernel:0', 'tf_bert_model_51/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_51/bert/pooler/dense/kernel:0', 'tf_bert_model_51/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.2480 - accuracy: 0.3682WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 88s 2s/step - loss: 2.2359 - accuracy: 0.3699 - val_loss: 1.1594 - val_accuracy: 0.3333\n","Epoch 2/20\n","6/6 [==============================] - 1s 247ms/step - loss: 2.0869 - accuracy: 0.2804 - val_loss: 1.0962 - val_accuracy: 0.3667\n","Epoch 3/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.8670 - accuracy: 0.3865 - val_loss: 1.0580 - val_accuracy: 0.4167\n","Epoch 4/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.8878 - accuracy: 0.4183 - val_loss: 1.0601 - val_accuracy: 0.4833\n","Epoch 5/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.9564 - accuracy: 0.4189 - val_loss: 1.0349 - val_accuracy: 0.5167\n","Epoch 6/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.7933 - accuracy: 0.4214 - val_loss: 1.0514 - val_accuracy: 0.4167\n","Epoch 7/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.8028 - accuracy: 0.5540 - val_loss: 1.0415 - val_accuracy: 0.4667\n","Epoch 8/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.6500 - accuracy: 0.4589 - val_loss: 1.0118 - val_accuracy: 0.5333\n","Epoch 9/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.6325 - accuracy: 0.6073 - val_loss: 0.9757 - val_accuracy: 0.5000\n","Epoch 10/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.4214 - accuracy: 0.6772 - val_loss: 0.9808 - val_accuracy: 0.5500\n","Epoch 11/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.1568 - accuracy: 0.7416 - val_loss: 1.0203 - val_accuracy: 0.5833\n","Epoch 12/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.0419 - accuracy: 0.7703 - val_loss: 1.0996 - val_accuracy: 0.5500\n","Epoch 13/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.8642 - accuracy: 0.7917 - val_loss: 1.0718 - val_accuracy: 0.5500\n","Epoch 14/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.6743 - accuracy: 0.8565 - val_loss: 1.1506 - val_accuracy: 0.5500\n","Epoch 15/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.5004 - accuracy: 0.8959 - val_loss: 1.2335 - val_accuracy: 0.5500\n","Epoch 16/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.3434 - accuracy: 0.9515 - val_loss: 1.3205 - val_accuracy: 0.5333\n","Epoch 17/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.2722 - accuracy: 0.9728 - val_loss: 1.2836 - val_accuracy: 0.5500\n","Epoch 18/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.2083 - accuracy: 0.9858 - val_loss: 1.3988 - val_accuracy: 0.5667\n","Epoch 19/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.1447 - accuracy: 0.9985 - val_loss: 1.3702 - val_accuracy: 0.5667\n","Epoch 20/20\n","6/6 [==============================] - 1s 253ms/step - loss: 0.1241 - accuracy: 0.9932 - val_loss: 1.5187 - val_accuracy: 0.5333\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9f700d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9f700d40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 12s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_52/bert/pooler/dense/kernel:0', 'tf_bert_model_52/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_52/bert/pooler/dense/kernel:0', 'tf_bert_model_52/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_52/bert/pooler/dense/kernel:0', 'tf_bert_model_52/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_52/bert/pooler/dense/kernel:0', 'tf_bert_model_52/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.8056 - accuracy: 0.2722WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 88s 2s/step - loss: 2.7885 - accuracy: 0.2783 - val_loss: 1.6341 - val_accuracy: 0.3667\n","Epoch 2/20\n","6/6 [==============================] - 1s 248ms/step - loss: 2.4682 - accuracy: 0.3560 - val_loss: 1.3101 - val_accuracy: 0.3333\n","Epoch 3/20\n","6/6 [==============================] - 1s 246ms/step - loss: 2.0629 - accuracy: 0.2487 - val_loss: 1.2059 - val_accuracy: 0.3667\n","Epoch 4/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.9003 - accuracy: 0.4830 - val_loss: 1.1324 - val_accuracy: 0.4333\n","Epoch 5/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.8270 - accuracy: 0.4385 - val_loss: 1.1363 - val_accuracy: 0.3667\n","Epoch 6/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.7553 - accuracy: 0.4089 - val_loss: 1.2523 - val_accuracy: 0.4333\n","Epoch 7/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.9554 - accuracy: 0.5642 - val_loss: 1.1796 - val_accuracy: 0.3667\n","Epoch 8/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.6766 - accuracy: 0.4006 - val_loss: 1.1933 - val_accuracy: 0.4833\n","Epoch 9/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.5812 - accuracy: 0.6305 - val_loss: 1.1528 - val_accuracy: 0.4167\n","Epoch 10/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.4539 - accuracy: 0.6175 - val_loss: 1.1623 - val_accuracy: 0.4167\n","Epoch 11/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.2569 - accuracy: 0.6700 - val_loss: 1.2689 - val_accuracy: 0.4833\n","Epoch 12/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.2312 - accuracy: 0.7836 - val_loss: 1.2119 - val_accuracy: 0.4667\n","Epoch 13/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.0232 - accuracy: 0.7321 - val_loss: 1.2974 - val_accuracy: 0.4833\n","Epoch 14/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.8328 - accuracy: 0.8496 - val_loss: 1.3075 - val_accuracy: 0.4667\n","Epoch 15/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.6763 - accuracy: 0.8866 - val_loss: 1.3998 - val_accuracy: 0.4167\n","Epoch 16/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.5275 - accuracy: 0.9012 - val_loss: 1.3775 - val_accuracy: 0.4833\n","Epoch 17/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.4182 - accuracy: 0.9155 - val_loss: 1.5461 - val_accuracy: 0.4500\n","Epoch 18/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.3496 - accuracy: 0.9622 - val_loss: 1.5445 - val_accuracy: 0.4833\n","Epoch 19/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.2438 - accuracy: 0.9496 - val_loss: 1.6785 - val_accuracy: 0.4833\n","Epoch 20/20\n","6/6 [==============================] - 3s 497ms/step - loss: 0.1696 - accuracy: 0.9850 - val_loss: 1.7324 - val_accuracy: 0.4667\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faedd95a320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faedd95a320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_53/bert/pooler/dense/kernel:0', 'tf_bert_model_53/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_53/bert/pooler/dense/kernel:0', 'tf_bert_model_53/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_53/bert/pooler/dense/kernel:0', 'tf_bert_model_53/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_53/bert/pooler/dense/kernel:0', 'tf_bert_model_53/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.3492 - accuracy: 0.3747WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 88s 2s/step - loss: 2.3452 - accuracy: 0.3766 - val_loss: 1.1699 - val_accuracy: 0.3500\n","Epoch 2/20\n","6/6 [==============================] - 1s 251ms/step - loss: 1.9577 - accuracy: 0.3567 - val_loss: 1.1108 - val_accuracy: 0.3833\n","Epoch 3/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.7623 - accuracy: 0.4187 - val_loss: 1.1217 - val_accuracy: 0.4000\n","Epoch 4/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.7730 - accuracy: 0.4328 - val_loss: 1.1049 - val_accuracy: 0.3833\n","Epoch 5/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.6882 - accuracy: 0.4471 - val_loss: 1.1101 - val_accuracy: 0.4000\n","Epoch 6/20\n","6/6 [==============================] - 2s 431ms/step - loss: 1.5370 - accuracy: 0.6707 - val_loss: 1.0887 - val_accuracy: 0.4000\n","Epoch 7/20\n","6/6 [==============================] - 1s 251ms/step - loss: 1.4328 - accuracy: 0.5826 - val_loss: 1.0878 - val_accuracy: 0.4667\n","Epoch 8/20\n","6/6 [==============================] - 1s 253ms/step - loss: 1.2525 - accuracy: 0.6652 - val_loss: 1.1002 - val_accuracy: 0.4000\n","Epoch 9/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.0951 - accuracy: 0.7329 - val_loss: 1.1123 - val_accuracy: 0.4167\n","Epoch 10/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.9703 - accuracy: 0.7372 - val_loss: 1.1885 - val_accuracy: 0.4500\n","Epoch 11/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.8272 - accuracy: 0.8409 - val_loss: 1.2240 - val_accuracy: 0.4667\n","Epoch 12/20\n","6/6 [==============================] - 1s 254ms/step - loss: 0.7828 - accuracy: 0.8000 - val_loss: 1.2776 - val_accuracy: 0.4667\n","Epoch 13/20\n","6/6 [==============================] - 1s 253ms/step - loss: 0.7073 - accuracy: 0.8568 - val_loss: 1.2311 - val_accuracy: 0.4500\n","Epoch 14/20\n","6/6 [==============================] - 1s 252ms/step - loss: 0.5464 - accuracy: 0.8442 - val_loss: 1.3490 - val_accuracy: 0.4333\n","Epoch 15/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.4159 - accuracy: 0.9410 - val_loss: 1.2533 - val_accuracy: 0.4667\n","Epoch 16/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.2757 - accuracy: 0.9474 - val_loss: 1.4235 - val_accuracy: 0.4667\n","Epoch 17/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.2161 - accuracy: 0.9860 - val_loss: 1.3508 - val_accuracy: 0.4667\n","Epoch 18/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.1977 - accuracy: 0.9717 - val_loss: 1.5285 - val_accuracy: 0.4500\n","Epoch 19/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.1483 - accuracy: 0.9844 - val_loss: 1.4282 - val_accuracy: 0.4667\n","Epoch 20/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.1184 - accuracy: 0.9885 - val_loss: 1.4564 - val_accuracy: 0.4500\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faed82ef560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faed82ef560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_54/bert/pooler/dense/kernel:0', 'tf_bert_model_54/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_54/bert/pooler/dense/kernel:0', 'tf_bert_model_54/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_54/bert/pooler/dense/kernel:0', 'tf_bert_model_54/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_54/bert/pooler/dense/kernel:0', 'tf_bert_model_54/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.3978 - accuracy: 0.3780WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 90s 2s/step - loss: 2.3826 - accuracy: 0.3761 - val_loss: 1.1545 - val_accuracy: 0.3833\n","Epoch 2/20\n","6/6 [==============================] - 1s 249ms/step - loss: 2.0619 - accuracy: 0.2822 - val_loss: 1.0730 - val_accuracy: 0.3833\n","Epoch 3/20\n","6/6 [==============================] - 1s 251ms/step - loss: 1.9829 - accuracy: 0.4077 - val_loss: 1.0624 - val_accuracy: 0.3500\n","Epoch 4/20\n","6/6 [==============================] - 1s 251ms/step - loss: 1.8029 - accuracy: 0.4341 - val_loss: 1.1127 - val_accuracy: 0.4167\n","Epoch 5/20\n","6/6 [==============================] - 1s 251ms/step - loss: 1.9913 - accuracy: 0.4633 - val_loss: 1.1313 - val_accuracy: 0.3833\n","Epoch 6/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.7313 - accuracy: 0.4226 - val_loss: 1.0671 - val_accuracy: 0.5333\n","Epoch 7/20\n","6/6 [==============================] - 1s 252ms/step - loss: 1.4892 - accuracy: 0.6091 - val_loss: 1.0567 - val_accuracy: 0.4333\n","Epoch 8/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.4764 - accuracy: 0.6186 - val_loss: 1.0473 - val_accuracy: 0.4333\n","Epoch 9/20\n","6/6 [==============================] - 1s 252ms/step - loss: 1.2090 - accuracy: 0.7192 - val_loss: 1.0653 - val_accuracy: 0.5167\n","Epoch 10/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.0908 - accuracy: 0.7785 - val_loss: 1.0862 - val_accuracy: 0.4833\n","Epoch 11/20\n","6/6 [==============================] - 1s 252ms/step - loss: 1.0152 - accuracy: 0.7550 - val_loss: 1.1111 - val_accuracy: 0.5500\n","Epoch 12/20\n","6/6 [==============================] - 1s 252ms/step - loss: 0.8971 - accuracy: 0.8421 - val_loss: 1.1500 - val_accuracy: 0.5167\n","Epoch 13/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.7870 - accuracy: 0.8333 - val_loss: 1.1881 - val_accuracy: 0.5500\n","Epoch 14/20\n","6/6 [==============================] - 1s 253ms/step - loss: 0.5474 - accuracy: 0.9096 - val_loss: 1.2300 - val_accuracy: 0.5333\n","Epoch 15/20\n","6/6 [==============================] - 1s 252ms/step - loss: 0.5594 - accuracy: 0.8898 - val_loss: 1.2042 - val_accuracy: 0.5667\n","Epoch 16/20\n","6/6 [==============================] - 2s 462ms/step - loss: 0.3642 - accuracy: 0.9529 - val_loss: 1.2368 - val_accuracy: 0.5000\n","Epoch 17/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.3173 - accuracy: 0.9695 - val_loss: 1.2355 - val_accuracy: 0.5500\n","Epoch 18/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.2417 - accuracy: 0.9554 - val_loss: 1.4241 - val_accuracy: 0.5333\n","Epoch 19/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.1819 - accuracy: 0.9912 - val_loss: 1.2320 - val_accuracy: 0.5000\n","Epoch 20/20\n","6/6 [==============================] - 1s 253ms/step - loss: 0.1688 - accuracy: 0.9882 - val_loss: 1.3992 - val_accuracy: 0.5167\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faedce3ee60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faedce3ee60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_55/bert/pooler/dense/kernel:0', 'tf_bert_model_55/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_55/bert/pooler/dense/kernel:0', 'tf_bert_model_55/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_55/bert/pooler/dense/kernel:0', 'tf_bert_model_55/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_55/bert/pooler/dense/kernel:0', 'tf_bert_model_55/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.8920 - accuracy: 0.3135WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 90s 2s/step - loss: 2.8660 - accuracy: 0.3212 - val_loss: 1.1656 - val_accuracy: 0.4000\n","Epoch 2/20\n","6/6 [==============================] - 1s 251ms/step - loss: 2.1362 - accuracy: 0.2651 - val_loss: 1.1089 - val_accuracy: 0.4000\n","Epoch 3/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.9449 - accuracy: 0.4525 - val_loss: 1.0917 - val_accuracy: 0.4000\n","Epoch 4/20\n","6/6 [==============================] - 1s 249ms/step - loss: 2.0029 - accuracy: 0.3691 - val_loss: 1.0893 - val_accuracy: 0.4000\n","Epoch 5/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.9469 - accuracy: 0.3419 - val_loss: 1.0803 - val_accuracy: 0.4333\n","Epoch 6/20\n","6/6 [==============================] - 1s 253ms/step - loss: 1.8943 - accuracy: 0.4787 - val_loss: 1.0437 - val_accuracy: 0.4833\n","Epoch 7/20\n","6/6 [==============================] - 1s 252ms/step - loss: 1.7910 - accuracy: 0.4487 - val_loss: 1.0326 - val_accuracy: 0.4500\n","Epoch 8/20\n","6/6 [==============================] - 1s 251ms/step - loss: 1.7825 - accuracy: 0.4343 - val_loss: 1.1017 - val_accuracy: 0.4333\n","Epoch 9/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.7293 - accuracy: 0.5341 - val_loss: 1.0397 - val_accuracy: 0.4667\n","Epoch 10/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.7077 - accuracy: 0.4592 - val_loss: 1.0800 - val_accuracy: 0.4167\n","Epoch 11/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.5927 - accuracy: 0.5720 - val_loss: 1.0587 - val_accuracy: 0.4167\n","Epoch 12/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.5157 - accuracy: 0.5745 - val_loss: 1.0249 - val_accuracy: 0.4833\n","Epoch 13/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.2066 - accuracy: 0.6915 - val_loss: 1.1402 - val_accuracy: 0.4500\n","Epoch 14/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.3450 - accuracy: 0.6755 - val_loss: 1.0768 - val_accuracy: 0.4667\n","Epoch 15/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.0552 - accuracy: 0.7477 - val_loss: 1.1877 - val_accuracy: 0.4833\n","Epoch 16/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.9030 - accuracy: 0.8245 - val_loss: 1.1270 - val_accuracy: 0.4667\n","Epoch 17/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.7100 - accuracy: 0.8614 - val_loss: 1.2019 - val_accuracy: 0.5000\n","Epoch 18/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.5459 - accuracy: 0.8984 - val_loss: 1.1992 - val_accuracy: 0.4667\n","Epoch 19/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.5170 - accuracy: 0.9326 - val_loss: 1.3518 - val_accuracy: 0.5000\n","Epoch 20/20\n","6/6 [==============================] - 1s 254ms/step - loss: 0.4410 - accuracy: 0.9161 - val_loss: 1.3090 - val_accuracy: 0.4833\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faec417d7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faec417d7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_56/bert/pooler/dense/kernel:0', 'tf_bert_model_56/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_56/bert/pooler/dense/kernel:0', 'tf_bert_model_56/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_56/bert/pooler/dense/kernel:0', 'tf_bert_model_56/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_56/bert/pooler/dense/kernel:0', 'tf_bert_model_56/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.7988 - accuracy: 0.2605WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 87s 2s/step - loss: 2.7943 - accuracy: 0.2616 - val_loss: 1.4159 - val_accuracy: 0.3000\n","Epoch 2/20\n","6/6 [==============================] - 1s 249ms/step - loss: 2.2819 - accuracy: 0.2245 - val_loss: 1.1089 - val_accuracy: 0.4167\n","Epoch 3/20\n","6/6 [==============================] - 1s 251ms/step - loss: 1.9240 - accuracy: 0.3467 - val_loss: 1.0961 - val_accuracy: 0.3833\n","Epoch 4/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.9181 - accuracy: 0.4548 - val_loss: 1.1320 - val_accuracy: 0.3000\n","Epoch 5/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.8664 - accuracy: 0.3708 - val_loss: 1.0657 - val_accuracy: 0.4000\n","Epoch 6/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.7951 - accuracy: 0.5064 - val_loss: 1.0641 - val_accuracy: 0.3833\n","Epoch 7/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.6666 - accuracy: 0.4955 - val_loss: 1.0782 - val_accuracy: 0.3500\n","Epoch 8/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.6570 - accuracy: 0.5454 - val_loss: 1.0847 - val_accuracy: 0.3833\n","Epoch 9/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.4415 - accuracy: 0.6919 - val_loss: 1.0823 - val_accuracy: 0.4167\n","Epoch 10/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.3750 - accuracy: 0.6772 - val_loss: 1.1234 - val_accuracy: 0.4167\n","Epoch 11/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.2487 - accuracy: 0.7614 - val_loss: 1.1547 - val_accuracy: 0.4333\n","Epoch 12/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.1217 - accuracy: 0.7969 - val_loss: 1.1519 - val_accuracy: 0.4667\n","Epoch 13/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.9041 - accuracy: 0.7699 - val_loss: 1.2672 - val_accuracy: 0.4667\n","Epoch 14/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.8112 - accuracy: 0.8414 - val_loss: 1.2310 - val_accuracy: 0.5167\n","Epoch 15/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.6009 - accuracy: 0.8721 - val_loss: 1.3905 - val_accuracy: 0.4667\n","Epoch 16/20\n","6/6 [==============================] - 1s 251ms/step - loss: 0.4534 - accuracy: 0.9345 - val_loss: 1.4015 - val_accuracy: 0.4833\n","Epoch 17/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.3944 - accuracy: 0.9475 - val_loss: 1.4806 - val_accuracy: 0.4333\n","Epoch 18/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.2819 - accuracy: 0.9628 - val_loss: 1.3658 - val_accuracy: 0.5000\n","Epoch 19/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.2292 - accuracy: 0.9683 - val_loss: 1.6043 - val_accuracy: 0.5000\n","Epoch 20/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.1846 - accuracy: 0.9933 - val_loss: 1.6100 - val_accuracy: 0.5000\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faed37be440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faed37be440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 12s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_57/bert/pooler/dense/kernel:0', 'tf_bert_model_57/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_57/bert/pooler/dense/kernel:0', 'tf_bert_model_57/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_57/bert/pooler/dense/kernel:0', 'tf_bert_model_57/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_57/bert/pooler/dense/kernel:0', 'tf_bert_model_57/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.8876 - accuracy: 0.3134WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 88s 2s/step - loss: 2.8389 - accuracy: 0.3118 - val_loss: 1.1714 - val_accuracy: 0.3667\n","Epoch 2/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.9826 - accuracy: 0.3974 - val_loss: 1.0541 - val_accuracy: 0.4333\n","Epoch 3/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.8967 - accuracy: 0.3453 - val_loss: 1.0891 - val_accuracy: 0.4000\n","Epoch 4/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.8700 - accuracy: 0.4514 - val_loss: 1.0364 - val_accuracy: 0.4833\n","Epoch 5/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.8211 - accuracy: 0.4026 - val_loss: 1.0362 - val_accuracy: 0.4833\n","Epoch 6/20\n","6/6 [==============================] - 1s 241ms/step - loss: 1.8325 - accuracy: 0.5493 - val_loss: 1.0914 - val_accuracy: 0.4000\n","Epoch 7/20\n","6/6 [==============================] - 1s 241ms/step - loss: 1.6403 - accuracy: 0.4833 - val_loss: 1.0171 - val_accuracy: 0.4500\n","Epoch 8/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.5575 - accuracy: 0.6699 - val_loss: 1.0256 - val_accuracy: 0.4667\n","Epoch 9/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.4197 - accuracy: 0.5554 - val_loss: 0.9742 - val_accuracy: 0.5333\n","Epoch 10/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.3358 - accuracy: 0.7295 - val_loss: 0.9953 - val_accuracy: 0.5167\n","Epoch 11/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.0865 - accuracy: 0.7381 - val_loss: 0.9436 - val_accuracy: 0.5167\n","Epoch 12/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.0270 - accuracy: 0.7765 - val_loss: 0.9840 - val_accuracy: 0.5333\n","Epoch 13/20\n","6/6 [==============================] - 1s 243ms/step - loss: 0.8117 - accuracy: 0.8241 - val_loss: 0.9540 - val_accuracy: 0.4833\n","Epoch 14/20\n","6/6 [==============================] - 1s 254ms/step - loss: 0.6182 - accuracy: 0.8987 - val_loss: 0.9698 - val_accuracy: 0.4833\n","Epoch 15/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.6448 - accuracy: 0.8715 - val_loss: 0.9781 - val_accuracy: 0.5000\n","Epoch 16/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.4225 - accuracy: 0.9448 - val_loss: 1.0342 - val_accuracy: 0.5000\n","Epoch 17/20\n","6/6 [==============================] - 1s 251ms/step - loss: 0.3579 - accuracy: 0.9276 - val_loss: 1.0456 - val_accuracy: 0.5000\n","Epoch 18/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.2799 - accuracy: 0.9574 - val_loss: 1.0211 - val_accuracy: 0.5167\n","Epoch 19/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.1968 - accuracy: 0.9769 - val_loss: 1.1035 - val_accuracy: 0.5333\n","Epoch 20/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.2234 - accuracy: 0.9723 - val_loss: 1.0381 - val_accuracy: 0.5167\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9bd868c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9bd868c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_58/bert/pooler/dense/kernel:0', 'tf_bert_model_58/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_58/bert/pooler/dense/kernel:0', 'tf_bert_model_58/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_58/bert/pooler/dense/kernel:0', 'tf_bert_model_58/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_58/bert/pooler/dense/kernel:0', 'tf_bert_model_58/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.6456 - accuracy: 0.3786WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 86s 2s/step - loss: 2.6264 - accuracy: 0.3751 - val_loss: 1.2869 - val_accuracy: 0.3500\n","Epoch 2/20\n","6/6 [==============================] - 2s 418ms/step - loss: 2.0506 - accuracy: 0.4135 - val_loss: 1.1402 - val_accuracy: 0.3833\n","Epoch 3/20\n","6/6 [==============================] - 1s 253ms/step - loss: 1.9834 - accuracy: 0.3383 - val_loss: 1.0952 - val_accuracy: 0.4333\n","Epoch 4/20\n","6/6 [==============================] - 1s 251ms/step - loss: 2.0152 - accuracy: 0.2824 - val_loss: 1.1342 - val_accuracy: 0.3333\n","Epoch 5/20\n","6/6 [==============================] - 1s 251ms/step - loss: 1.9133 - accuracy: 0.4017 - val_loss: 1.1274 - val_accuracy: 0.3167\n","Epoch 6/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.9294 - accuracy: 0.4023 - val_loss: 1.1755 - val_accuracy: 0.3500\n","Epoch 7/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.8905 - accuracy: 0.3962 - val_loss: 1.1305 - val_accuracy: 0.3000\n","Epoch 8/20\n","6/6 [==============================] - 1s 253ms/step - loss: 1.8392 - accuracy: 0.5430 - val_loss: 1.1974 - val_accuracy: 0.4500\n","Epoch 9/20\n","6/6 [==============================] - 1s 251ms/step - loss: 1.7319 - accuracy: 0.4734 - val_loss: 1.1148 - val_accuracy: 0.4000\n","Epoch 10/20\n","6/6 [==============================] - 1s 253ms/step - loss: 1.6284 - accuracy: 0.5698 - val_loss: 1.1451 - val_accuracy: 0.4167\n","Epoch 11/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.6036 - accuracy: 0.5966 - val_loss: 1.1505 - val_accuracy: 0.4167\n","Epoch 12/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.3385 - accuracy: 0.6842 - val_loss: 1.1706 - val_accuracy: 0.4167\n","Epoch 13/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.1698 - accuracy: 0.7704 - val_loss: 1.2278 - val_accuracy: 0.3667\n","Epoch 14/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.0415 - accuracy: 0.7230 - val_loss: 1.2608 - val_accuracy: 0.4500\n","Epoch 15/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.8335 - accuracy: 0.8477 - val_loss: 1.2777 - val_accuracy: 0.4333\n","Epoch 16/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.7041 - accuracy: 0.8608 - val_loss: 1.3574 - val_accuracy: 0.4000\n","Epoch 17/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.5370 - accuracy: 0.8926 - val_loss: 1.4440 - val_accuracy: 0.4167\n","Epoch 18/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.4317 - accuracy: 0.9251 - val_loss: 1.4216 - val_accuracy: 0.4333\n","Epoch 19/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.3328 - accuracy: 0.9459 - val_loss: 1.5147 - val_accuracy: 0.4333\n","Epoch 20/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.2339 - accuracy: 0.9875 - val_loss: 1.5967 - val_accuracy: 0.4500\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faee53ed7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faee53ed7a0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_59/bert/pooler/dense/kernel:0', 'tf_bert_model_59/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_59/bert/pooler/dense/kernel:0', 'tf_bert_model_59/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_59/bert/pooler/dense/kernel:0', 'tf_bert_model_59/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_59/bert/pooler/dense/kernel:0', 'tf_bert_model_59/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.4584 - accuracy: 0.3972WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 87s 2s/step - loss: 2.4477 - accuracy: 0.3952 - val_loss: 1.2320 - val_accuracy: 0.3333\n","Epoch 2/20\n","6/6 [==============================] - 1s 243ms/step - loss: 2.1607 - accuracy: 0.3242 - val_loss: 1.1736 - val_accuracy: 0.3167\n","Epoch 3/20\n","6/6 [==============================] - 1s 243ms/step - loss: 2.1082 - accuracy: 0.3805 - val_loss: 1.1664 - val_accuracy: 0.3500\n","Epoch 4/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.9068 - accuracy: 0.4244 - val_loss: 1.1299 - val_accuracy: 0.3000\n","Epoch 5/20\n","6/6 [==============================] - 2s 420ms/step - loss: 1.9847 - accuracy: 0.2958 - val_loss: 1.1191 - val_accuracy: 0.3667\n","Epoch 6/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.8001 - accuracy: 0.4178 - val_loss: 1.0677 - val_accuracy: 0.3833\n","Epoch 7/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.7681 - accuracy: 0.5178 - val_loss: 1.0500 - val_accuracy: 0.4667\n","Epoch 8/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.7339 - accuracy: 0.3905 - val_loss: 1.0366 - val_accuracy: 0.4667\n","Epoch 9/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.7553 - accuracy: 0.5507 - val_loss: 1.0352 - val_accuracy: 0.5167\n","Epoch 10/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.6048 - accuracy: 0.5408 - val_loss: 1.0437 - val_accuracy: 0.5167\n","Epoch 11/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.4768 - accuracy: 0.6674 - val_loss: 0.9974 - val_accuracy: 0.5167\n","Epoch 12/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.2947 - accuracy: 0.6563 - val_loss: 1.0353 - val_accuracy: 0.5333\n","Epoch 13/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.2947 - accuracy: 0.7042 - val_loss: 1.0800 - val_accuracy: 0.5667\n","Epoch 14/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.1104 - accuracy: 0.6679 - val_loss: 1.1628 - val_accuracy: 0.4833\n","Epoch 15/20\n","6/6 [==============================] - 1s 251ms/step - loss: 0.9205 - accuracy: 0.8269 - val_loss: 1.1122 - val_accuracy: 0.5667\n","Epoch 16/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.7192 - accuracy: 0.8093 - val_loss: 1.2982 - val_accuracy: 0.4000\n","Epoch 17/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.5651 - accuracy: 0.9198 - val_loss: 1.1060 - val_accuracy: 0.5333\n","Epoch 18/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.4739 - accuracy: 0.8981 - val_loss: 1.4090 - val_accuracy: 0.4167\n","Epoch 19/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.3676 - accuracy: 0.9636 - val_loss: 1.1865 - val_accuracy: 0.5333\n","Epoch 20/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.2717 - accuracy: 0.9769 - val_loss: 1.3920 - val_accuracy: 0.4167\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faed810ed40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faed810ed40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_60/bert/pooler/dense/kernel:0', 'tf_bert_model_60/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_60/bert/pooler/dense/kernel:0', 'tf_bert_model_60/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_60/bert/pooler/dense/kernel:0', 'tf_bert_model_60/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_60/bert/pooler/dense/kernel:0', 'tf_bert_model_60/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 3.2365 - accuracy: 0.2938WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 88s 2s/step - loss: 3.1649 - accuracy: 0.3010 - val_loss: 1.1317 - val_accuracy: 0.3167\n","Epoch 2/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.9972 - accuracy: 0.3842 - val_loss: 1.1101 - val_accuracy: 0.3500\n","Epoch 3/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.9429 - accuracy: 0.4253 - val_loss: 1.1191 - val_accuracy: 0.3833\n","Epoch 4/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.9134 - accuracy: 0.2681 - val_loss: 1.1179 - val_accuracy: 0.3500\n","Epoch 5/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.8920 - accuracy: 0.3119 - val_loss: 1.1471 - val_accuracy: 0.3500\n","Epoch 6/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.9402 - accuracy: 0.4695 - val_loss: 1.1384 - val_accuracy: 0.3667\n","Epoch 7/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.8756 - accuracy: 0.3163 - val_loss: 1.0962 - val_accuracy: 0.3333\n","Epoch 8/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.9165 - accuracy: 0.5657 - val_loss: 1.0784 - val_accuracy: 0.4167\n","Epoch 9/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.7300 - accuracy: 0.4622 - val_loss: 1.0668 - val_accuracy: 0.4333\n","Epoch 10/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.5941 - accuracy: 0.5967 - val_loss: 1.0663 - val_accuracy: 0.4500\n","Epoch 11/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.5925 - accuracy: 0.6365 - val_loss: 1.1021 - val_accuracy: 0.5000\n","Epoch 12/20\n","6/6 [==============================] - 1s 242ms/step - loss: 1.3719 - accuracy: 0.6361 - val_loss: 1.1331 - val_accuracy: 0.4500\n","Epoch 13/20\n","6/6 [==============================] - 2s 457ms/step - loss: 1.1997 - accuracy: 0.7375 - val_loss: 1.1900 - val_accuracy: 0.5000\n","Epoch 14/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.2028 - accuracy: 0.7258 - val_loss: 1.1703 - val_accuracy: 0.5000\n","Epoch 15/20\n","6/6 [==============================] - 1s 243ms/step - loss: 0.8860 - accuracy: 0.8330 - val_loss: 1.1786 - val_accuracy: 0.4833\n","Epoch 16/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.7199 - accuracy: 0.8563 - val_loss: 1.2285 - val_accuracy: 0.5333\n","Epoch 17/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.5376 - accuracy: 0.9269 - val_loss: 1.3024 - val_accuracy: 0.5667\n","Epoch 18/20\n","6/6 [==============================] - 1s 243ms/step - loss: 0.3170 - accuracy: 0.9667 - val_loss: 1.3507 - val_accuracy: 0.5667\n","Epoch 19/20\n","6/6 [==============================] - 1s 243ms/step - loss: 0.2618 - accuracy: 0.9629 - val_loss: 1.3776 - val_accuracy: 0.5333\n","Epoch 20/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.2006 - accuracy: 0.9814 - val_loss: 1.4874 - val_accuracy: 0.5167\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faece372560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faece372560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_61/bert/pooler/dense/kernel:0', 'tf_bert_model_61/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_61/bert/pooler/dense/kernel:0', 'tf_bert_model_61/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_61/bert/pooler/dense/kernel:0', 'tf_bert_model_61/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_61/bert/pooler/dense/kernel:0', 'tf_bert_model_61/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.5909 - accuracy: 0.3155WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 89s 2s/step - loss: 2.5744 - accuracy: 0.3144 - val_loss: 1.2570 - val_accuracy: 0.3333\n","Epoch 2/20\n","6/6 [==============================] - 1s 246ms/step - loss: 2.3027 - accuracy: 0.2419 - val_loss: 1.0883 - val_accuracy: 0.4167\n","Epoch 3/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.9505 - accuracy: 0.4670 - val_loss: 1.1011 - val_accuracy: 0.4167\n","Epoch 4/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.9218 - accuracy: 0.3762 - val_loss: 1.0886 - val_accuracy: 0.4333\n","Epoch 5/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.8542 - accuracy: 0.4756 - val_loss: 1.0764 - val_accuracy: 0.4833\n","Epoch 6/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.8171 - accuracy: 0.4227 - val_loss: 1.0251 - val_accuracy: 0.4833\n","Epoch 7/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.6130 - accuracy: 0.5542 - val_loss: 1.0211 - val_accuracy: 0.5333\n","Epoch 8/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.5219 - accuracy: 0.6521 - val_loss: 0.9925 - val_accuracy: 0.5500\n","Epoch 9/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.4100 - accuracy: 0.5972 - val_loss: 0.9850 - val_accuracy: 0.5667\n","Epoch 10/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.1830 - accuracy: 0.7967 - val_loss: 0.9466 - val_accuracy: 0.5333\n","Epoch 11/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.0531 - accuracy: 0.8103 - val_loss: 0.9628 - val_accuracy: 0.5500\n","Epoch 12/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.8611 - accuracy: 0.8504 - val_loss: 1.0320 - val_accuracy: 0.5500\n","Epoch 13/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.7409 - accuracy: 0.8503 - val_loss: 1.0515 - val_accuracy: 0.5833\n","Epoch 14/20\n","6/6 [==============================] - 1s 251ms/step - loss: 0.5587 - accuracy: 0.9358 - val_loss: 1.1103 - val_accuracy: 0.5833\n","Epoch 15/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.3764 - accuracy: 0.9603 - val_loss: 1.1371 - val_accuracy: 0.6000\n","Epoch 16/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.3021 - accuracy: 0.9690 - val_loss: 1.1763 - val_accuracy: 0.5833\n","Epoch 17/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.2447 - accuracy: 0.9770 - val_loss: 1.2016 - val_accuracy: 0.6000\n","Epoch 18/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.2386 - accuracy: 0.9640 - val_loss: 1.2390 - val_accuracy: 0.6333\n","Epoch 19/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.1733 - accuracy: 0.9851 - val_loss: 1.2492 - val_accuracy: 0.6000\n","Epoch 20/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.1416 - accuracy: 0.9869 - val_loss: 1.3532 - val_accuracy: 0.5833\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9fa8f560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9fa8f560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 12s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_62/bert/pooler/dense/kernel:0', 'tf_bert_model_62/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_62/bert/pooler/dense/kernel:0', 'tf_bert_model_62/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_62/bert/pooler/dense/kernel:0', 'tf_bert_model_62/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_62/bert/pooler/dense/kernel:0', 'tf_bert_model_62/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.4457 - accuracy: 0.3484WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 89s 2s/step - loss: 2.4211 - accuracy: 0.3496 - val_loss: 1.1286 - val_accuracy: 0.3833\n","Epoch 2/20\n","6/6 [==============================] - 1s 248ms/step - loss: 2.1326 - accuracy: 0.3045 - val_loss: 1.0933 - val_accuracy: 0.3500\n","Epoch 3/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.9684 - accuracy: 0.2839 - val_loss: 1.0842 - val_accuracy: 0.3500\n","Epoch 4/20\n","6/6 [==============================] - 1s 248ms/step - loss: 2.0797 - accuracy: 0.4300 - val_loss: 1.0476 - val_accuracy: 0.4833\n","Epoch 5/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.8890 - accuracy: 0.3725 - val_loss: 1.0229 - val_accuracy: 0.5000\n","Epoch 6/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.8176 - accuracy: 0.4510 - val_loss: 0.9932 - val_accuracy: 0.5833\n","Epoch 7/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.6610 - accuracy: 0.5649 - val_loss: 0.9757 - val_accuracy: 0.5667\n","Epoch 8/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.5383 - accuracy: 0.6322 - val_loss: 0.9530 - val_accuracy: 0.5500\n","Epoch 9/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.4137 - accuracy: 0.6499 - val_loss: 0.9527 - val_accuracy: 0.5833\n","Epoch 10/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.2766 - accuracy: 0.6742 - val_loss: 1.0457 - val_accuracy: 0.5667\n","Epoch 11/20\n","6/6 [==============================] - 1s 253ms/step - loss: 1.1862 - accuracy: 0.7860 - val_loss: 0.9603 - val_accuracy: 0.6167\n","Epoch 12/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.0126 - accuracy: 0.7895 - val_loss: 1.1165 - val_accuracy: 0.5500\n","Epoch 13/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.8478 - accuracy: 0.8303 - val_loss: 1.0185 - val_accuracy: 0.6667\n","Epoch 14/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.6704 - accuracy: 0.8462 - val_loss: 1.1643 - val_accuracy: 0.5500\n","Epoch 15/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.4956 - accuracy: 0.9211 - val_loss: 1.1000 - val_accuracy: 0.6000\n","Epoch 16/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.3800 - accuracy: 0.9339 - val_loss: 1.3172 - val_accuracy: 0.5000\n","Epoch 17/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.3406 - accuracy: 0.9621 - val_loss: 1.0984 - val_accuracy: 0.6333\n","Epoch 18/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.2220 - accuracy: 0.9524 - val_loss: 1.2920 - val_accuracy: 0.5833\n","Epoch 19/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.1511 - accuracy: 0.9892 - val_loss: 1.2958 - val_accuracy: 0.6167\n","Epoch 20/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.1275 - accuracy: 0.9877 - val_loss: 1.3632 - val_accuracy: 0.6167\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faec4a8a4d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faec4a8a4d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_63/bert/pooler/dense/kernel:0', 'tf_bert_model_63/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_63/bert/pooler/dense/kernel:0', 'tf_bert_model_63/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_63/bert/pooler/dense/kernel:0', 'tf_bert_model_63/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_63/bert/pooler/dense/kernel:0', 'tf_bert_model_63/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 3.0462 - accuracy: 0.2666WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 87s 2s/step - loss: 2.9922 - accuracy: 0.2773 - val_loss: 1.2629 - val_accuracy: 0.3500\n","Epoch 2/20\n","6/6 [==============================] - 2s 420ms/step - loss: 2.0977 - accuracy: 0.2709 - val_loss: 1.1901 - val_accuracy: 0.3667\n","Epoch 3/20\n","6/6 [==============================] - 1s 254ms/step - loss: 1.8992 - accuracy: 0.5577 - val_loss: 1.1428 - val_accuracy: 0.3667\n","Epoch 4/20\n","6/6 [==============================] - 1s 247ms/step - loss: 2.0082 - accuracy: 0.2620 - val_loss: 1.1019 - val_accuracy: 0.4500\n","Epoch 5/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.8386 - accuracy: 0.4735 - val_loss: 1.1166 - val_accuracy: 0.4333\n","Epoch 6/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.8780 - accuracy: 0.4832 - val_loss: 1.0915 - val_accuracy: 0.4500\n","Epoch 7/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.6524 - accuracy: 0.5632 - val_loss: 1.1319 - val_accuracy: 0.4500\n","Epoch 8/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.6152 - accuracy: 0.5786 - val_loss: 1.1122 - val_accuracy: 0.5167\n","Epoch 9/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.4845 - accuracy: 0.5973 - val_loss: 1.1136 - val_accuracy: 0.4833\n","Epoch 10/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.2791 - accuracy: 0.6642 - val_loss: 1.1335 - val_accuracy: 0.4667\n","Epoch 11/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.1020 - accuracy: 0.7823 - val_loss: 1.1387 - val_accuracy: 0.5000\n","Epoch 12/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.9623 - accuracy: 0.7974 - val_loss: 1.2460 - val_accuracy: 0.4333\n","Epoch 13/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.0559 - accuracy: 0.7543 - val_loss: 1.1658 - val_accuracy: 0.5167\n","Epoch 14/20\n","6/6 [==============================] - 1s 243ms/step - loss: 0.7087 - accuracy: 0.8288 - val_loss: 1.3668 - val_accuracy: 0.4167\n","Epoch 15/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.6286 - accuracy: 0.8835 - val_loss: 1.2474 - val_accuracy: 0.4333\n","Epoch 16/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.3760 - accuracy: 0.9436 - val_loss: 1.4908 - val_accuracy: 0.4333\n","Epoch 17/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.3633 - accuracy: 0.9483 - val_loss: 1.4383 - val_accuracy: 0.4667\n","Epoch 18/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.2895 - accuracy: 0.9426 - val_loss: 1.5082 - val_accuracy: 0.4667\n","Epoch 19/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.2138 - accuracy: 0.9844 - val_loss: 1.6954 - val_accuracy: 0.4667\n","Epoch 20/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.1799 - accuracy: 0.9906 - val_loss: 1.5919 - val_accuracy: 0.4500\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9cde19e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9cde19e0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_64/bert/pooler/dense/kernel:0', 'tf_bert_model_64/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_64/bert/pooler/dense/kernel:0', 'tf_bert_model_64/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_64/bert/pooler/dense/kernel:0', 'tf_bert_model_64/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_64/bert/pooler/dense/kernel:0', 'tf_bert_model_64/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.6743 - accuracy: 0.3334WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 86s 2s/step - loss: 2.6358 - accuracy: 0.3315 - val_loss: 1.1353 - val_accuracy: 0.3667\n","Epoch 2/20\n","6/6 [==============================] - 2s 418ms/step - loss: 1.9768 - accuracy: 0.4156 - val_loss: 1.0915 - val_accuracy: 0.3500\n","Epoch 3/20\n","6/6 [==============================] - 1s 249ms/step - loss: 2.1029 - accuracy: 0.3000 - val_loss: 1.1634 - val_accuracy: 0.4000\n","Epoch 4/20\n","6/6 [==============================] - 1s 253ms/step - loss: 1.9989 - accuracy: 0.3851 - val_loss: 1.0723 - val_accuracy: 0.4500\n","Epoch 5/20\n","6/6 [==============================] - 1s 251ms/step - loss: 1.9381 - accuracy: 0.3884 - val_loss: 1.0623 - val_accuracy: 0.4667\n","Epoch 6/20\n","6/6 [==============================] - 1s 254ms/step - loss: 1.6859 - accuracy: 0.4753 - val_loss: 1.0083 - val_accuracy: 0.5000\n","Epoch 7/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.7160 - accuracy: 0.5692 - val_loss: 1.0049 - val_accuracy: 0.4833\n","Epoch 8/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.6834 - accuracy: 0.5232 - val_loss: 1.0020 - val_accuracy: 0.5000\n","Epoch 9/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.5248 - accuracy: 0.6337 - val_loss: 0.9920 - val_accuracy: 0.5333\n","Epoch 10/20\n","6/6 [==============================] - 1s 242ms/step - loss: 1.4086 - accuracy: 0.6714 - val_loss: 0.9903 - val_accuracy: 0.5667\n","Epoch 11/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.2879 - accuracy: 0.7047 - val_loss: 0.9644 - val_accuracy: 0.6000\n","Epoch 12/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.0272 - accuracy: 0.8185 - val_loss: 0.9621 - val_accuracy: 0.6000\n","Epoch 13/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.9228 - accuracy: 0.8440 - val_loss: 0.9434 - val_accuracy: 0.6500\n","Epoch 14/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.8134 - accuracy: 0.8441 - val_loss: 0.9436 - val_accuracy: 0.5833\n","Epoch 15/20\n","6/6 [==============================] - 1s 241ms/step - loss: 0.7020 - accuracy: 0.8263 - val_loss: 1.1144 - val_accuracy: 0.5833\n","Epoch 16/20\n","6/6 [==============================] - 1s 243ms/step - loss: 0.5045 - accuracy: 0.9162 - val_loss: 0.9941 - val_accuracy: 0.5667\n","Epoch 17/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.3831 - accuracy: 0.9513 - val_loss: 1.1408 - val_accuracy: 0.5667\n","Epoch 18/20\n","6/6 [==============================] - 1s 243ms/step - loss: 0.2433 - accuracy: 0.9815 - val_loss: 1.0573 - val_accuracy: 0.6333\n","Epoch 19/20\n","6/6 [==============================] - 1s 242ms/step - loss: 0.2384 - accuracy: 0.9812 - val_loss: 1.0853 - val_accuracy: 0.6333\n","Epoch 20/20\n","6/6 [==============================] - 1s 242ms/step - loss: 0.2100 - accuracy: 0.9746 - val_loss: 1.1966 - val_accuracy: 0.5833\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9d586710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9d586710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_65/bert/pooler/dense/kernel:0', 'tf_bert_model_65/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_65/bert/pooler/dense/kernel:0', 'tf_bert_model_65/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_65/bert/pooler/dense/kernel:0', 'tf_bert_model_65/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_65/bert/pooler/dense/kernel:0', 'tf_bert_model_65/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 3.0338 - accuracy: 0.3272WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 87s 2s/step - loss: 2.9905 - accuracy: 0.3255 - val_loss: 1.3671 - val_accuracy: 0.3333\n","Epoch 2/20\n","6/6 [==============================] - 1s 246ms/step - loss: 2.2731 - accuracy: 0.5405 - val_loss: 1.1519 - val_accuracy: 0.3833\n","Epoch 3/20\n","6/6 [==============================] - 1s 255ms/step - loss: 2.0822 - accuracy: 0.2618 - val_loss: 1.1143 - val_accuracy: 0.3167\n","Epoch 4/20\n","6/6 [==============================] - 1s 246ms/step - loss: 2.0825 - accuracy: 0.4236 - val_loss: 1.0831 - val_accuracy: 0.4000\n","Epoch 5/20\n","6/6 [==============================] - 2s 430ms/step - loss: 1.8897 - accuracy: 0.3831 - val_loss: 1.0775 - val_accuracy: 0.4333\n","Epoch 6/20\n","6/6 [==============================] - 1s 248ms/step - loss: 2.0324 - accuracy: 0.4191 - val_loss: 1.2041 - val_accuracy: 0.4000\n","Epoch 7/20\n","6/6 [==============================] - 1s 251ms/step - loss: 1.8361 - accuracy: 0.3098 - val_loss: 1.1512 - val_accuracy: 0.3667\n","Epoch 8/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.9154 - accuracy: 0.4320 - val_loss: 1.2391 - val_accuracy: 0.3667\n","Epoch 9/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.7574 - accuracy: 0.4867 - val_loss: 1.1212 - val_accuracy: 0.4167\n","Epoch 10/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.5222 - accuracy: 0.5778 - val_loss: 1.1445 - val_accuracy: 0.4167\n","Epoch 11/20\n","6/6 [==============================] - 1s 255ms/step - loss: 1.5415 - accuracy: 0.6241 - val_loss: 1.1395 - val_accuracy: 0.3833\n","Epoch 12/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.3343 - accuracy: 0.5838 - val_loss: 1.1636 - val_accuracy: 0.4333\n","Epoch 13/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.2264 - accuracy: 0.7365 - val_loss: 1.1959 - val_accuracy: 0.4333\n","Epoch 14/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.0399 - accuracy: 0.7849 - val_loss: 1.1862 - val_accuracy: 0.5000\n","Epoch 15/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.8178 - accuracy: 0.8413 - val_loss: 1.2446 - val_accuracy: 0.5167\n","Epoch 16/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.6700 - accuracy: 0.8864 - val_loss: 1.2591 - val_accuracy: 0.5000\n","Epoch 17/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.5956 - accuracy: 0.9136 - val_loss: 1.3199 - val_accuracy: 0.5333\n","Epoch 18/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.4870 - accuracy: 0.9180 - val_loss: 1.3523 - val_accuracy: 0.5333\n","Epoch 19/20\n","6/6 [==============================] - 1s 252ms/step - loss: 0.3392 - accuracy: 0.9511 - val_loss: 1.3975 - val_accuracy: 0.4833\n","Epoch 20/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.2954 - accuracy: 0.9481 - val_loss: 1.5085 - val_accuracy: 0.4333\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faed3286c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faed3286c20> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_66/bert/pooler/dense/kernel:0', 'tf_bert_model_66/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_66/bert/pooler/dense/kernel:0', 'tf_bert_model_66/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_66/bert/pooler/dense/kernel:0', 'tf_bert_model_66/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_66/bert/pooler/dense/kernel:0', 'tf_bert_model_66/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.3600 - accuracy: 0.3396WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 90s 2s/step - loss: 2.3630 - accuracy: 0.3491 - val_loss: 1.3231 - val_accuracy: 0.3667\n","Epoch 2/20\n","6/6 [==============================] - 1s 248ms/step - loss: 2.4331 - accuracy: 0.2395 - val_loss: 1.0881 - val_accuracy: 0.4000\n","Epoch 3/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.8403 - accuracy: 0.5528 - val_loss: 1.1226 - val_accuracy: 0.3000\n","Epoch 4/20\n","6/6 [==============================] - 1s 251ms/step - loss: 1.9093 - accuracy: 0.4239 - val_loss: 1.1541 - val_accuracy: 0.3833\n","Epoch 5/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.9207 - accuracy: 0.3184 - val_loss: 1.1509 - val_accuracy: 0.3333\n","Epoch 6/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.8775 - accuracy: 0.5528 - val_loss: 1.1485 - val_accuracy: 0.4500\n","Epoch 7/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.8159 - accuracy: 0.3412 - val_loss: 1.0840 - val_accuracy: 0.4333\n","Epoch 8/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.6444 - accuracy: 0.5108 - val_loss: 1.1118 - val_accuracy: 0.3833\n","Epoch 9/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.5104 - accuracy: 0.6816 - val_loss: 1.0522 - val_accuracy: 0.4500\n","Epoch 10/20\n","6/6 [==============================] - 1s 253ms/step - loss: 1.3734 - accuracy: 0.6032 - val_loss: 1.0708 - val_accuracy: 0.4333\n","Epoch 11/20\n","6/6 [==============================] - 1s 251ms/step - loss: 1.2784 - accuracy: 0.6853 - val_loss: 1.0948 - val_accuracy: 0.4500\n","Epoch 12/20\n","6/6 [==============================] - 2s 479ms/step - loss: 1.0702 - accuracy: 0.7552 - val_loss: 1.0654 - val_accuracy: 0.4667\n","Epoch 13/20\n","6/6 [==============================] - 1s 251ms/step - loss: 0.9778 - accuracy: 0.7686 - val_loss: 1.1681 - val_accuracy: 0.4667\n","Epoch 14/20\n","6/6 [==============================] - 1s 253ms/step - loss: 0.7258 - accuracy: 0.8278 - val_loss: 1.2807 - val_accuracy: 0.4500\n","Epoch 15/20\n","6/6 [==============================] - 1s 253ms/step - loss: 0.6347 - accuracy: 0.8847 - val_loss: 1.2832 - val_accuracy: 0.4667\n","Epoch 16/20\n","6/6 [==============================] - 1s 254ms/step - loss: 0.4798 - accuracy: 0.9295 - val_loss: 1.4086 - val_accuracy: 0.4500\n","Epoch 17/20\n","6/6 [==============================] - 1s 252ms/step - loss: 0.3665 - accuracy: 0.9604 - val_loss: 1.3828 - val_accuracy: 0.4667\n","Epoch 18/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.3381 - accuracy: 0.9335 - val_loss: 1.5107 - val_accuracy: 0.4500\n","Epoch 19/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.2566 - accuracy: 0.9648 - val_loss: 1.7269 - val_accuracy: 0.3833\n","Epoch 20/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.2299 - accuracy: 0.9783 - val_loss: 1.3938 - val_accuracy: 0.4833\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fada0e89290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fada0e89290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_67/bert/pooler/dense/kernel:0', 'tf_bert_model_67/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_67/bert/pooler/dense/kernel:0', 'tf_bert_model_67/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_67/bert/pooler/dense/kernel:0', 'tf_bert_model_67/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_67/bert/pooler/dense/kernel:0', 'tf_bert_model_67/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.8504 - accuracy: 0.3221WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 90s 2s/step - loss: 2.8039 - accuracy: 0.3200 - val_loss: 1.2136 - val_accuracy: 0.3167\n","Epoch 2/20\n","6/6 [==============================] - 1s 250ms/step - loss: 2.2523 - accuracy: 0.4477 - val_loss: 1.1446 - val_accuracy: 0.3667\n","Epoch 3/20\n","6/6 [==============================] - 1s 253ms/step - loss: 1.8822 - accuracy: 0.3046 - val_loss: 1.0984 - val_accuracy: 0.3333\n","Epoch 4/20\n","6/6 [==============================] - 1s 244ms/step - loss: 2.0087 - accuracy: 0.4232 - val_loss: 1.1533 - val_accuracy: 0.4167\n","Epoch 5/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.8999 - accuracy: 0.3770 - val_loss: 1.0888 - val_accuracy: 0.5000\n","Epoch 6/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.9421 - accuracy: 0.4146 - val_loss: 1.0419 - val_accuracy: 0.4333\n","Epoch 7/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.7916 - accuracy: 0.4219 - val_loss: 1.0415 - val_accuracy: 0.4333\n","Epoch 8/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.7005 - accuracy: 0.5005 - val_loss: 1.0346 - val_accuracy: 0.4667\n","Epoch 9/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.7056 - accuracy: 0.5044 - val_loss: 1.0191 - val_accuracy: 0.4167\n","Epoch 10/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.5303 - accuracy: 0.6202 - val_loss: 1.0427 - val_accuracy: 0.4833\n","Epoch 11/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.4369 - accuracy: 0.6629 - val_loss: 1.0158 - val_accuracy: 0.4333\n","Epoch 12/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.3374 - accuracy: 0.6226 - val_loss: 1.0602 - val_accuracy: 0.5167\n","Epoch 13/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.0982 - accuracy: 0.7897 - val_loss: 1.0281 - val_accuracy: 0.4333\n","Epoch 14/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.9569 - accuracy: 0.8280 - val_loss: 1.0432 - val_accuracy: 0.4667\n","Epoch 15/20\n","6/6 [==============================] - 1s 252ms/step - loss: 0.8445 - accuracy: 0.7754 - val_loss: 1.2497 - val_accuracy: 0.4333\n","Epoch 16/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.6151 - accuracy: 0.9033 - val_loss: 1.1720 - val_accuracy: 0.4833\n","Epoch 17/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.4818 - accuracy: 0.9146 - val_loss: 1.3189 - val_accuracy: 0.4667\n","Epoch 18/20\n","6/6 [==============================] - 1s 254ms/step - loss: 0.3440 - accuracy: 0.9529 - val_loss: 1.3250 - val_accuracy: 0.5167\n","Epoch 19/20\n","6/6 [==============================] - 1s 256ms/step - loss: 0.3169 - accuracy: 0.9708 - val_loss: 1.3336 - val_accuracy: 0.5500\n","Epoch 20/20\n","6/6 [==============================] - 1s 254ms/step - loss: 0.2440 - accuracy: 0.9624 - val_loss: 1.3884 - val_accuracy: 0.5500\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9d9063b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9d9063b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_68/bert/pooler/dense/kernel:0', 'tf_bert_model_68/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_68/bert/pooler/dense/kernel:0', 'tf_bert_model_68/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_68/bert/pooler/dense/kernel:0', 'tf_bert_model_68/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_68/bert/pooler/dense/kernel:0', 'tf_bert_model_68/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 3.0209 - accuracy: 0.3860WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 87s 2s/step - loss: 2.9668 - accuracy: 0.3766 - val_loss: 1.1438 - val_accuracy: 0.3500\n","Epoch 2/20\n","6/6 [==============================] - 2s 418ms/step - loss: 2.1423 - accuracy: 0.4471 - val_loss: 1.0715 - val_accuracy: 0.4167\n","Epoch 3/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.9218 - accuracy: 0.3372 - val_loss: 1.1042 - val_accuracy: 0.3167\n","Epoch 4/20\n","6/6 [==============================] - 1s 251ms/step - loss: 1.9223 - accuracy: 0.4954 - val_loss: 1.1063 - val_accuracy: 0.4000\n","Epoch 5/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.7476 - accuracy: 0.4014 - val_loss: 1.0980 - val_accuracy: 0.3333\n","Epoch 6/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.6750 - accuracy: 0.5507 - val_loss: 1.1733 - val_accuracy: 0.3167\n","Epoch 7/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.7410 - accuracy: 0.4760 - val_loss: 1.0750 - val_accuracy: 0.3667\n","Epoch 8/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.4638 - accuracy: 0.6386 - val_loss: 1.1174 - val_accuracy: 0.3833\n","Epoch 9/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.4312 - accuracy: 0.7020 - val_loss: 1.1141 - val_accuracy: 0.3833\n","Epoch 10/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.2116 - accuracy: 0.7167 - val_loss: 1.1494 - val_accuracy: 0.3667\n","Epoch 11/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.2193 - accuracy: 0.7016 - val_loss: 1.1503 - val_accuracy: 0.3667\n","Epoch 12/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.9994 - accuracy: 0.8138 - val_loss: 1.1811 - val_accuracy: 0.4167\n","Epoch 13/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.8230 - accuracy: 0.8542 - val_loss: 1.1907 - val_accuracy: 0.4000\n","Epoch 14/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.6025 - accuracy: 0.8878 - val_loss: 1.3164 - val_accuracy: 0.4167\n","Epoch 15/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.5772 - accuracy: 0.9120 - val_loss: 1.3218 - val_accuracy: 0.4000\n","Epoch 16/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.4422 - accuracy: 0.9322 - val_loss: 1.3490 - val_accuracy: 0.4333\n","Epoch 17/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.3831 - accuracy: 0.9481 - val_loss: 1.2837 - val_accuracy: 0.4667\n","Epoch 18/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.2766 - accuracy: 0.9641 - val_loss: 1.4035 - val_accuracy: 0.4833\n","Epoch 19/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.1987 - accuracy: 0.9930 - val_loss: 1.3562 - val_accuracy: 0.4833\n","Epoch 20/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.1915 - accuracy: 0.9804 - val_loss: 1.4127 - val_accuracy: 0.4500\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faeddbcdcb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faeddbcdcb0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_69/bert/pooler/dense/kernel:0', 'tf_bert_model_69/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_69/bert/pooler/dense/kernel:0', 'tf_bert_model_69/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_69/bert/pooler/dense/kernel:0', 'tf_bert_model_69/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_69/bert/pooler/dense/kernel:0', 'tf_bert_model_69/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.4979 - accuracy: 0.3251WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 87s 2s/step - loss: 2.5001 - accuracy: 0.3196 - val_loss: 1.1685 - val_accuracy: 0.3667\n","Epoch 2/20\n","6/6 [==============================] - 1s 248ms/step - loss: 2.1326 - accuracy: 0.3006 - val_loss: 1.1135 - val_accuracy: 0.3500\n","Epoch 3/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.9246 - accuracy: 0.4058 - val_loss: 1.0669 - val_accuracy: 0.3833\n","Epoch 4/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.9456 - accuracy: 0.3674 - val_loss: 1.0710 - val_accuracy: 0.3833\n","Epoch 5/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.8597 - accuracy: 0.5108 - val_loss: 1.1058 - val_accuracy: 0.3500\n","Epoch 6/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.8560 - accuracy: 0.3969 - val_loss: 1.0806 - val_accuracy: 0.4167\n","Epoch 7/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.7124 - accuracy: 0.5554 - val_loss: 1.1204 - val_accuracy: 0.3500\n","Epoch 8/20\n","6/6 [==============================] - 2s 429ms/step - loss: 1.7191 - accuracy: 0.5929 - val_loss: 1.0875 - val_accuracy: 0.4333\n","Epoch 9/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.5145 - accuracy: 0.5698 - val_loss: 1.0865 - val_accuracy: 0.4500\n","Epoch 10/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.4420 - accuracy: 0.6388 - val_loss: 1.1201 - val_accuracy: 0.4167\n","Epoch 11/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.3251 - accuracy: 0.7281 - val_loss: 1.1180 - val_accuracy: 0.4167\n","Epoch 12/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.1356 - accuracy: 0.7461 - val_loss: 1.1654 - val_accuracy: 0.4667\n","Epoch 13/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.9732 - accuracy: 0.7768 - val_loss: 1.1494 - val_accuracy: 0.5167\n","Epoch 14/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.7641 - accuracy: 0.8408 - val_loss: 1.2840 - val_accuracy: 0.4333\n","Epoch 15/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.6786 - accuracy: 0.9188 - val_loss: 1.2261 - val_accuracy: 0.4667\n","Epoch 16/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.5128 - accuracy: 0.9194 - val_loss: 1.3138 - val_accuracy: 0.5000\n","Epoch 17/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.4223 - accuracy: 0.9462 - val_loss: 1.2819 - val_accuracy: 0.4833\n","Epoch 18/20\n","6/6 [==============================] - 1s 243ms/step - loss: 0.3438 - accuracy: 0.9424 - val_loss: 1.3728 - val_accuracy: 0.5000\n","Epoch 19/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.2649 - accuracy: 0.9797 - val_loss: 1.3533 - val_accuracy: 0.4833\n","Epoch 20/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.1895 - accuracy: 0.9845 - val_loss: 1.4872 - val_accuracy: 0.4833\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9c50e440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9c50e440> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_70/bert/pooler/dense/kernel:0', 'tf_bert_model_70/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_70/bert/pooler/dense/kernel:0', 'tf_bert_model_70/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_70/bert/pooler/dense/kernel:0', 'tf_bert_model_70/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_70/bert/pooler/dense/kernel:0', 'tf_bert_model_70/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.4832 - accuracy: 0.3468WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 90s 2s/step - loss: 2.4766 - accuracy: 0.3445 - val_loss: 1.2497 - val_accuracy: 0.3333\n","Epoch 2/20\n","6/6 [==============================] - 1s 244ms/step - loss: 2.0658 - accuracy: 0.4275 - val_loss: 1.0903 - val_accuracy: 0.4333\n","Epoch 3/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.9826 - accuracy: 0.2894 - val_loss: 1.0549 - val_accuracy: 0.4667\n","Epoch 4/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.8771 - accuracy: 0.3722 - val_loss: 1.0393 - val_accuracy: 0.5000\n","Epoch 5/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.9569 - accuracy: 0.4019 - val_loss: 1.0261 - val_accuracy: 0.5500\n","Epoch 6/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.8178 - accuracy: 0.4408 - val_loss: 1.0058 - val_accuracy: 0.5667\n","Epoch 7/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.6860 - accuracy: 0.4855 - val_loss: 0.9997 - val_accuracy: 0.5500\n","Epoch 8/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.6782 - accuracy: 0.5449 - val_loss: 1.0155 - val_accuracy: 0.5333\n","Epoch 9/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.7236 - accuracy: 0.5033 - val_loss: 1.0085 - val_accuracy: 0.6000\n","Epoch 10/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.4775 - accuracy: 0.6150 - val_loss: 1.1222 - val_accuracy: 0.4000\n","Epoch 11/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.5501 - accuracy: 0.6532 - val_loss: 1.0411 - val_accuracy: 0.5667\n","Epoch 12/20\n","6/6 [==============================] - 1s 251ms/step - loss: 1.2722 - accuracy: 0.6658 - val_loss: 1.1329 - val_accuracy: 0.4333\n","Epoch 13/20\n","6/6 [==============================] - 1s 253ms/step - loss: 1.1558 - accuracy: 0.7428 - val_loss: 1.0668 - val_accuracy: 0.5833\n","Epoch 14/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.8567 - accuracy: 0.7744 - val_loss: 1.2269 - val_accuracy: 0.4500\n","Epoch 15/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.7950 - accuracy: 0.8561 - val_loss: 1.0865 - val_accuracy: 0.6167\n","Epoch 16/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.6614 - accuracy: 0.8606 - val_loss: 1.2834 - val_accuracy: 0.4167\n","Epoch 17/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.4433 - accuracy: 0.9282 - val_loss: 1.1351 - val_accuracy: 0.5667\n","Epoch 18/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.3953 - accuracy: 0.9136 - val_loss: 1.3133 - val_accuracy: 0.4667\n","Epoch 19/20\n","6/6 [==============================] - 2s 471ms/step - loss: 0.2528 - accuracy: 0.9660 - val_loss: 1.2948 - val_accuracy: 0.5000\n","Epoch 20/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.2420 - accuracy: 0.9637 - val_loss: 1.3138 - val_accuracy: 0.5167\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faec4b9aef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faec4b9aef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_71/bert/pooler/dense/kernel:0', 'tf_bert_model_71/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_71/bert/pooler/dense/kernel:0', 'tf_bert_model_71/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_71/bert/pooler/dense/kernel:0', 'tf_bert_model_71/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_71/bert/pooler/dense/kernel:0', 'tf_bert_model_71/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.5561 - accuracy: 0.3172WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 90s 2s/step - loss: 2.5343 - accuracy: 0.3154 - val_loss: 1.3039 - val_accuracy: 0.3167\n","Epoch 2/20\n","6/6 [==============================] - 1s 246ms/step - loss: 2.2474 - accuracy: 0.3629 - val_loss: 1.1356 - val_accuracy: 0.4000\n","Epoch 3/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.8793 - accuracy: 0.3554 - val_loss: 1.1372 - val_accuracy: 0.3500\n","Epoch 4/20\n","6/6 [==============================] - 2s 423ms/step - loss: 1.9146 - accuracy: 0.3038 - val_loss: 1.1307 - val_accuracy: 0.3500\n","Epoch 5/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.8845 - accuracy: 0.3009 - val_loss: 1.1599 - val_accuracy: 0.2833\n","Epoch 6/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.8782 - accuracy: 0.4330 - val_loss: 1.1874 - val_accuracy: 0.3500\n","Epoch 7/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.8782 - accuracy: 0.3416 - val_loss: 1.1216 - val_accuracy: 0.3167\n","Epoch 8/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.8328 - accuracy: 0.4961 - val_loss: 1.0501 - val_accuracy: 0.4000\n","Epoch 9/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.5932 - accuracy: 0.5286 - val_loss: 1.0469 - val_accuracy: 0.4167\n","Epoch 10/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.4960 - accuracy: 0.6360 - val_loss: 1.0197 - val_accuracy: 0.4833\n","Epoch 11/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.3616 - accuracy: 0.6653 - val_loss: 1.0004 - val_accuracy: 0.4333\n","Epoch 12/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.1977 - accuracy: 0.7438 - val_loss: 0.9838 - val_accuracy: 0.5000\n","Epoch 13/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.0642 - accuracy: 0.7501 - val_loss: 0.9912 - val_accuracy: 0.4833\n","Epoch 14/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.9429 - accuracy: 0.8232 - val_loss: 0.9911 - val_accuracy: 0.5167\n","Epoch 15/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.6645 - accuracy: 0.8531 - val_loss: 0.9922 - val_accuracy: 0.5167\n","Epoch 16/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.6130 - accuracy: 0.8429 - val_loss: 1.1840 - val_accuracy: 0.5000\n","Epoch 17/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.5248 - accuracy: 0.9174 - val_loss: 0.9942 - val_accuracy: 0.5333\n","Epoch 18/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.3754 - accuracy: 0.9143 - val_loss: 1.2891 - val_accuracy: 0.4833\n","Epoch 19/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.3745 - accuracy: 0.9545 - val_loss: 1.0607 - val_accuracy: 0.5333\n","Epoch 20/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.2393 - accuracy: 0.9692 - val_loss: 1.1691 - val_accuracy: 0.5333\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9f487290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9f487290> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_72/bert/pooler/dense/kernel:0', 'tf_bert_model_72/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_72/bert/pooler/dense/kernel:0', 'tf_bert_model_72/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_72/bert/pooler/dense/kernel:0', 'tf_bert_model_72/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_72/bert/pooler/dense/kernel:0', 'tf_bert_model_72/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.4845 - accuracy: 0.3230WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 86s 2s/step - loss: 2.4547 - accuracy: 0.3349 - val_loss: 1.1036 - val_accuracy: 0.3667\n","Epoch 2/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.9982 - accuracy: 0.2727 - val_loss: 1.0860 - val_accuracy: 0.4833\n","Epoch 3/20\n","6/6 [==============================] - 1s 249ms/step - loss: 2.0030 - accuracy: 0.3946 - val_loss: 1.0737 - val_accuracy: 0.5333\n","Epoch 4/20\n","6/6 [==============================] - 1s 248ms/step - loss: 2.0027 - accuracy: 0.4057 - val_loss: 1.0635 - val_accuracy: 0.4167\n","Epoch 5/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.8170 - accuracy: 0.3724 - val_loss: 1.0521 - val_accuracy: 0.4000\n","Epoch 6/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.7910 - accuracy: 0.4963 - val_loss: 1.0227 - val_accuracy: 0.5333\n","Epoch 7/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.7926 - accuracy: 0.4909 - val_loss: 1.0077 - val_accuracy: 0.5000\n","Epoch 8/20\n","6/6 [==============================] - 2s 434ms/step - loss: 1.6122 - accuracy: 0.5817 - val_loss: 0.9980 - val_accuracy: 0.5000\n","Epoch 9/20\n","6/6 [==============================] - 1s 251ms/step - loss: 1.4410 - accuracy: 0.5756 - val_loss: 1.0104 - val_accuracy: 0.5000\n","Epoch 10/20\n","6/6 [==============================] - 1s 254ms/step - loss: 1.3545 - accuracy: 0.7008 - val_loss: 1.0292 - val_accuracy: 0.4500\n","Epoch 11/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.2470 - accuracy: 0.7240 - val_loss: 1.0625 - val_accuracy: 0.4833\n","Epoch 12/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.9742 - accuracy: 0.8020 - val_loss: 1.0499 - val_accuracy: 0.5333\n","Epoch 13/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.8017 - accuracy: 0.8609 - val_loss: 1.1343 - val_accuracy: 0.5000\n","Epoch 14/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.6694 - accuracy: 0.9044 - val_loss: 1.1183 - val_accuracy: 0.4833\n","Epoch 15/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.4569 - accuracy: 0.9143 - val_loss: 1.2060 - val_accuracy: 0.5167\n","Epoch 16/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.3747 - accuracy: 0.9451 - val_loss: 1.2297 - val_accuracy: 0.5167\n","Epoch 17/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.3010 - accuracy: 0.9669 - val_loss: 1.3845 - val_accuracy: 0.4833\n","Epoch 18/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.2242 - accuracy: 0.9753 - val_loss: 1.3531 - val_accuracy: 0.4833\n","Epoch 19/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.1856 - accuracy: 0.9932 - val_loss: 1.3992 - val_accuracy: 0.4833\n","Epoch 20/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.1381 - accuracy: 0.9833 - val_loss: 1.4528 - val_accuracy: 0.4833\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9e797ef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9e797ef0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_73/bert/pooler/dense/kernel:0', 'tf_bert_model_73/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_73/bert/pooler/dense/kernel:0', 'tf_bert_model_73/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_73/bert/pooler/dense/kernel:0', 'tf_bert_model_73/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_73/bert/pooler/dense/kernel:0', 'tf_bert_model_73/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.5085 - accuracy: 0.3795WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 90s 2s/step - loss: 2.5103 - accuracy: 0.3770 - val_loss: 1.3062 - val_accuracy: 0.3500\n","Epoch 2/20\n","6/6 [==============================] - 1s 243ms/step - loss: 2.1120 - accuracy: 0.5081 - val_loss: 1.2035 - val_accuracy: 0.3333\n","Epoch 3/20\n","6/6 [==============================] - 1s 248ms/step - loss: 2.0505 - accuracy: 0.2675 - val_loss: 1.1275 - val_accuracy: 0.4167\n","Epoch 4/20\n","6/6 [==============================] - 1s 244ms/step - loss: 2.0925 - accuracy: 0.4836 - val_loss: 1.0980 - val_accuracy: 0.3333\n","Epoch 5/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.9682 - accuracy: 0.2228 - val_loss: 1.0742 - val_accuracy: 0.4333\n","Epoch 6/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.9297 - accuracy: 0.4207 - val_loss: 1.0489 - val_accuracy: 0.4167\n","Epoch 7/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.8052 - accuracy: 0.5442 - val_loss: 1.0309 - val_accuracy: 0.4667\n","Epoch 8/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.7332 - accuracy: 0.4868 - val_loss: 0.9917 - val_accuracy: 0.5000\n","Epoch 9/20\n","6/6 [==============================] - 1s 243ms/step - loss: 1.6557 - accuracy: 0.5637 - val_loss: 0.9897 - val_accuracy: 0.4667\n","Epoch 10/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.5225 - accuracy: 0.6392 - val_loss: 0.9831 - val_accuracy: 0.5000\n","Epoch 11/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.3686 - accuracy: 0.6779 - val_loss: 1.0092 - val_accuracy: 0.4833\n","Epoch 12/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.2041 - accuracy: 0.6964 - val_loss: 1.0116 - val_accuracy: 0.5167\n","Epoch 13/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.0366 - accuracy: 0.7459 - val_loss: 0.9812 - val_accuracy: 0.5000\n","Epoch 14/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.9421 - accuracy: 0.8366 - val_loss: 0.9975 - val_accuracy: 0.5167\n","Epoch 15/20\n","6/6 [==============================] - 2s 478ms/step - loss: 0.7227 - accuracy: 0.8403 - val_loss: 1.0143 - val_accuracy: 0.5333\n","Epoch 16/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.5189 - accuracy: 0.9453 - val_loss: 1.0421 - val_accuracy: 0.5167\n","Epoch 17/20\n","6/6 [==============================] - 1s 252ms/step - loss: 0.4407 - accuracy: 0.9208 - val_loss: 1.0202 - val_accuracy: 0.6000\n","Epoch 18/20\n","6/6 [==============================] - 1s 252ms/step - loss: 0.3016 - accuracy: 0.9734 - val_loss: 0.9911 - val_accuracy: 0.5500\n","Epoch 19/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.2420 - accuracy: 0.9720 - val_loss: 1.0152 - val_accuracy: 0.6167\n","Epoch 20/20\n","6/6 [==============================] - 1s 254ms/step - loss: 0.2180 - accuracy: 0.9764 - val_loss: 1.0296 - val_accuracy: 0.6000\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9da543b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9da543b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_74/bert/pooler/dense/kernel:0', 'tf_bert_model_74/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_74/bert/pooler/dense/kernel:0', 'tf_bert_model_74/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_74/bert/pooler/dense/kernel:0', 'tf_bert_model_74/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_74/bert/pooler/dense/kernel:0', 'tf_bert_model_74/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.6581 - accuracy: 0.3088WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 89s 2s/step - loss: 2.6543 - accuracy: 0.3149 - val_loss: 1.4312 - val_accuracy: 0.4500\n","Epoch 2/20\n","6/6 [==============================] - 2s 417ms/step - loss: 2.3233 - accuracy: 0.2750 - val_loss: 1.3289 - val_accuracy: 0.3000\n","Epoch 3/20\n","6/6 [==============================] - 1s 252ms/step - loss: 2.0732 - accuracy: 0.4972 - val_loss: 1.1460 - val_accuracy: 0.3833\n","Epoch 4/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.9557 - accuracy: 0.2423 - val_loss: 1.1565 - val_accuracy: 0.3833\n","Epoch 5/20\n","6/6 [==============================] - 1s 251ms/step - loss: 2.0919 - accuracy: 0.5211 - val_loss: 1.1387 - val_accuracy: 0.3667\n","Epoch 6/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.9200 - accuracy: 0.2205 - val_loss: 1.0724 - val_accuracy: 0.4000\n","Epoch 7/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.7543 - accuracy: 0.4826 - val_loss: 1.0411 - val_accuracy: 0.5000\n","Epoch 8/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.7387 - accuracy: 0.4951 - val_loss: 1.0151 - val_accuracy: 0.5000\n","Epoch 9/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.6390 - accuracy: 0.4388 - val_loss: 1.0059 - val_accuracy: 0.5333\n","Epoch 10/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.5576 - accuracy: 0.6541 - val_loss: 1.0192 - val_accuracy: 0.4667\n","Epoch 11/20\n","6/6 [==============================] - 1s 256ms/step - loss: 1.4384 - accuracy: 0.5492 - val_loss: 0.9869 - val_accuracy: 0.5500\n","Epoch 12/20\n","6/6 [==============================] - 1s 247ms/step - loss: 1.3802 - accuracy: 0.6615 - val_loss: 0.9545 - val_accuracy: 0.5333\n","Epoch 13/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.0768 - accuracy: 0.7948 - val_loss: 0.9477 - val_accuracy: 0.5500\n","Epoch 14/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.9060 - accuracy: 0.8253 - val_loss: 1.0024 - val_accuracy: 0.5833\n","Epoch 15/20\n","6/6 [==============================] - 1s 245ms/step - loss: 0.8143 - accuracy: 0.8500 - val_loss: 0.9798 - val_accuracy: 0.5833\n","Epoch 16/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.6155 - accuracy: 0.8732 - val_loss: 1.1358 - val_accuracy: 0.5667\n","Epoch 17/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.5497 - accuracy: 0.9397 - val_loss: 0.9825 - val_accuracy: 0.5500\n","Epoch 18/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.3927 - accuracy: 0.9115 - val_loss: 1.3065 - val_accuracy: 0.5333\n","Epoch 19/20\n","6/6 [==============================] - 1s 252ms/step - loss: 0.3618 - accuracy: 0.9626 - val_loss: 1.0520 - val_accuracy: 0.5500\n","Epoch 20/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.2724 - accuracy: 0.9453 - val_loss: 1.2577 - val_accuracy: 0.5833\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9c1958c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9c1958c0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_75/bert/pooler/dense/kernel:0', 'tf_bert_model_75/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_75/bert/pooler/dense/kernel:0', 'tf_bert_model_75/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_75/bert/pooler/dense/kernel:0', 'tf_bert_model_75/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_75/bert/pooler/dense/kernel:0', 'tf_bert_model_75/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.5441 - accuracy: 0.3888WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 90s 2s/step - loss: 2.5215 - accuracy: 0.3813 - val_loss: 1.2327 - val_accuracy: 0.3333\n","Epoch 2/20\n","6/6 [==============================] - 1s 245ms/step - loss: 2.1884 - accuracy: 0.4467 - val_loss: 1.1428 - val_accuracy: 0.4167\n","Epoch 3/20\n","6/6 [==============================] - 1s 244ms/step - loss: 1.9416 - accuracy: 0.3087 - val_loss: 1.1569 - val_accuracy: 0.4000\n","Epoch 4/20\n","6/6 [==============================] - 1s 244ms/step - loss: 2.0081 - accuracy: 0.4211 - val_loss: 1.1583 - val_accuracy: 0.3833\n","Epoch 5/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.7997 - accuracy: 0.4289 - val_loss: 1.1215 - val_accuracy: 0.3500\n","Epoch 6/20\n","6/6 [==============================] - 1s 246ms/step - loss: 1.6138 - accuracy: 0.5865 - val_loss: 1.1359 - val_accuracy: 0.4167\n","Epoch 7/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.5740 - accuracy: 0.5334 - val_loss: 1.1514 - val_accuracy: 0.3833\n","Epoch 8/20\n","6/6 [==============================] - 1s 249ms/step - loss: 1.4981 - accuracy: 0.5987 - val_loss: 1.1357 - val_accuracy: 0.4167\n","Epoch 9/20\n","6/6 [==============================] - 2s 450ms/step - loss: 1.3365 - accuracy: 0.6351 - val_loss: 1.1590 - val_accuracy: 0.4500\n","Epoch 10/20\n","6/6 [==============================] - 1s 252ms/step - loss: 1.1700 - accuracy: 0.7221 - val_loss: 1.1397 - val_accuracy: 0.4500\n","Epoch 11/20\n","6/6 [==============================] - 1s 252ms/step - loss: 0.9689 - accuracy: 0.7667 - val_loss: 1.2339 - val_accuracy: 0.4000\n","Epoch 12/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.7748 - accuracy: 0.8558 - val_loss: 1.1996 - val_accuracy: 0.4500\n","Epoch 13/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.6985 - accuracy: 0.8448 - val_loss: 1.3276 - val_accuracy: 0.4333\n","Epoch 14/20\n","6/6 [==============================] - 1s 252ms/step - loss: 0.5252 - accuracy: 0.8985 - val_loss: 1.3730 - val_accuracy: 0.4333\n","Epoch 15/20\n","6/6 [==============================] - 1s 261ms/step - loss: 0.4464 - accuracy: 0.8998 - val_loss: 1.4908 - val_accuracy: 0.4000\n","Epoch 16/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.3119 - accuracy: 0.9719 - val_loss: 1.4778 - val_accuracy: 0.4333\n","Epoch 17/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.2920 - accuracy: 0.9339 - val_loss: 1.4914 - val_accuracy: 0.4667\n","Epoch 18/20\n","6/6 [==============================] - 1s 246ms/step - loss: 0.1851 - accuracy: 0.9770 - val_loss: 1.6761 - val_accuracy: 0.4833\n","Epoch 19/20\n","6/6 [==============================] - 1s 252ms/step - loss: 0.1823 - accuracy: 0.9875 - val_loss: 1.5221 - val_accuracy: 0.4833\n","Epoch 20/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.1542 - accuracy: 0.9779 - val_loss: 1.7226 - val_accuracy: 0.4667\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9c7dc560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fad9c7dc560> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 9s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_76/bert/pooler/dense/kernel:0', 'tf_bert_model_76/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_76/bert/pooler/dense/kernel:0', 'tf_bert_model_76/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_76/bert/pooler/dense/kernel:0', 'tf_bert_model_76/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_76/bert/pooler/dense/kernel:0', 'tf_bert_model_76/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - ETA: 0s - loss: 2.6287 - accuracy: 0.3901WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["6/6 [==============================] - 89s 2s/step - loss: 2.6086 - accuracy: 0.3868 - val_loss: 1.1375 - val_accuracy: 0.4167\n","Epoch 2/20\n","6/6 [==============================] - 1s 248ms/step - loss: 2.1477 - accuracy: 0.3035 - val_loss: 1.0773 - val_accuracy: 0.3500\n","Epoch 3/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.9383 - accuracy: 0.5163 - val_loss: 1.0934 - val_accuracy: 0.4167\n","Epoch 4/20\n","6/6 [==============================] - 1s 245ms/step - loss: 1.8965 - accuracy: 0.3162 - val_loss: 1.0845 - val_accuracy: 0.3667\n","Epoch 5/20\n","6/6 [==============================] - 1s 252ms/step - loss: 1.8689 - accuracy: 0.4319 - val_loss: 1.1214 - val_accuracy: 0.4167\n","Epoch 6/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.8086 - accuracy: 0.4360 - val_loss: 1.0769 - val_accuracy: 0.3500\n","Epoch 7/20\n","6/6 [==============================] - 1s 253ms/step - loss: 1.7063 - accuracy: 0.5953 - val_loss: 1.0679 - val_accuracy: 0.4500\n","Epoch 8/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.6645 - accuracy: 0.5616 - val_loss: 1.0940 - val_accuracy: 0.4333\n","Epoch 9/20\n","6/6 [==============================] - 1s 252ms/step - loss: 1.5362 - accuracy: 0.6348 - val_loss: 1.1184 - val_accuracy: 0.4167\n","Epoch 10/20\n","6/6 [==============================] - 1s 251ms/step - loss: 1.2773 - accuracy: 0.7140 - val_loss: 1.1528 - val_accuracy: 0.4500\n","Epoch 11/20\n","6/6 [==============================] - 1s 248ms/step - loss: 1.3256 - accuracy: 0.7294 - val_loss: 1.1350 - val_accuracy: 0.4667\n","Epoch 12/20\n","6/6 [==============================] - 1s 250ms/step - loss: 1.0524 - accuracy: 0.7212 - val_loss: 1.1965 - val_accuracy: 0.4000\n","Epoch 13/20\n","6/6 [==============================] - 1s 248ms/step - loss: 0.9167 - accuracy: 0.8089 - val_loss: 1.1893 - val_accuracy: 0.4500\n","Epoch 14/20\n","6/6 [==============================] - 1s 252ms/step - loss: 0.7481 - accuracy: 0.8835 - val_loss: 1.3496 - val_accuracy: 0.4500\n","Epoch 15/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.5896 - accuracy: 0.9009 - val_loss: 1.2484 - val_accuracy: 0.5167\n","Epoch 16/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.4523 - accuracy: 0.9216 - val_loss: 1.3414 - val_accuracy: 0.4833\n","Epoch 17/20\n","6/6 [==============================] - 1s 244ms/step - loss: 0.3888 - accuracy: 0.9501 - val_loss: 1.3785 - val_accuracy: 0.5000\n","Epoch 18/20\n","6/6 [==============================] - 1s 247ms/step - loss: 0.2852 - accuracy: 0.9496 - val_loss: 1.5094 - val_accuracy: 0.4333\n","Epoch 19/20\n","6/6 [==============================] - 1s 249ms/step - loss: 0.2393 - accuracy: 0.9520 - val_loss: 1.4595 - val_accuracy: 0.5000\n","Epoch 20/20\n","6/6 [==============================] - 1s 250ms/step - loss: 0.1667 - accuracy: 0.9929 - val_loss: 1.4889 - val_accuracy: 0.4667\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faeee2323b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7faeee2323b0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"],"name":"stderr"},{"output_type":"stream","text":["1/1 - 12s\n"],"name":"stdout"},{"output_type":"stream","text":["Some layers from the model checkpoint at bert-base-german-cased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n","- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","All the layers of TFBertModel were initialized from the model checkpoint at bert-base-german-cased.\n","If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["Epoch 1/20\n","WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_77/bert/pooler/dense/kernel:0', 'tf_bert_model_77/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_77/bert/pooler/dense/kernel:0', 'tf_bert_model_77/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"],"name":"stderr"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_77/bert/pooler/dense/kernel:0', 'tf_bert_model_77/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stdout"},{"output_type":"stream","text":["WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model_77/bert/pooler/dense/kernel:0', 'tf_bert_model_77/bert/pooler/dense/bias:0'] when minimizing the loss.\n"],"name":"stderr"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-22-60f5a5298a82>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclass_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m   )\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m-> 2941\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3361\u001b[0;31m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3362\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3204\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3205\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3206\u001b[0;31m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[1;32m   3207\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3208\u001b[0m         \u001b[0mfunction_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    971\u001b[0m                     \u001b[0mrecursive\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m                     \u001b[0moptional_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mautograph_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m                     \u001b[0muser_requested\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    974\u001b[0m                 ))\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    457\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconverted_f\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0meffective_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     14\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    348\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    477\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    478\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 479\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mstep_function\u001b[0;34m(model, iterator)\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m       \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 795\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m       outputs = reduce_per_replica(\n\u001b[1;32m    797\u001b[0m           outputs, self.distribute_strategy, reduction='first')\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/tpu_strategy.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fn, args, kwargs, options)\u001b[0m\n\u001b[1;32m    538\u001b[0m     \u001b[0mfn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mautograph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_convert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mautograph_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m     \u001b[0moptions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mdistribute_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRunOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtpu_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/tpu_strategy.py\u001b[0m in \u001b[0;36mtpu_run\u001b[0;34m(self, fn, args, kwargs, options)\u001b[0m\n\u001b[1;32m   1294\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtpu_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1295\u001b[0m     \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tpu_function_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1296\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1298\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_tpu_function_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/tpu_strategy.py\u001b[0m in \u001b[0;36mtpu_function\u001b[0;34m(args, kwargs)\u001b[0m\n\u001b[1;32m   1362\u001b[0m             \u001b[0mmaximum_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximum_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1363\u001b[0m             \u001b[0mpadding_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1364\u001b[0;31m             xla_options=tpu.XLAOptions(use_spmd_for_xla_partitioning=False))\n\u001b[0m\u001b[1;32m   1365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m       \u001b[0;31m# Remove all no ops that may have been added during 'tpu.replicate()'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/tpu/tpu.py\u001b[0m in \u001b[0;36mreplicate\u001b[0;34m(computation, inputs, infeed_queue, device_assignment, name, maximum_shapes, padding_spec, xla_options)\u001b[0m\n\u001b[1;32m    966\u001b[0m       \u001b[0mmaximum_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaximum_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    967\u001b[0m       \u001b[0mpadding_spec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding_spec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 968\u001b[0;31m       xla_options=xla_options)[1]\n\u001b[0m\u001b[1;32m    969\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    970\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/tpu/tpu.py\u001b[0m in \u001b[0;36msplit_compile_and_replicate\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1437\u001b[0m       \u001b[0mvscope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_custom_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomputation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcomputation_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m       \u001b[0mvscope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_use_resource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_use_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/tpu_strategy.py\u001b[0m in \u001b[0;36mreplicated_fn\u001b[0;34m(replica_id, replica_args, replica_kwargs)\u001b[0m\n\u001b[1;32m   1323\u001b[0m         \u001b[0;34m\"\"\"Wraps user function to provide replica ID and `Tensor` inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0m_TPUReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreplica_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1325\u001b[0;31m           \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mreplica_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mreplica_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_requested\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_allowlisted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m   \u001b[0;31m# internal_convert_user_code is for example turned off when issuing a dynamic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mrun_step\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    786\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m       \u001b[0;32mdef\u001b[0m \u001b[0mrun_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m         \u001b[0;31m# Ensure counter is updated only if `train_step` succeeds.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_minimum_control_deps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    755\u001b[0m       loss = self.compiled_loss(\n\u001b[1;32m    756\u001b[0m           y, y_pred, sample_weight, regularization_losses=self.losses)\n\u001b[0;32m--> 757\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompiled_metrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, var_list, grad_loss, name, tape)\u001b[0m\n\u001b[1;32m    496\u001b[0m     grads_and_vars = self._compute_gradients(\n\u001b[1;32m    497\u001b[0m         loss, var_list=var_list, grad_loss=grad_loss, tape=tape)\n\u001b[0;32m--> 498\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_compute_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_loss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars, name, experimental_aggregate_gradients)\u001b[0m\n\u001b[1;32m    633\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    634\u001b[0m           kwargs={\n\u001b[0;32m--> 635\u001b[0;31m               \u001b[0;34m\"name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    636\u001b[0m           })\n\u001b[1;32m    637\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mmerge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     merge_fn = autograph.tf_convert(\n\u001b[1;32m   2940\u001b[0m         merge_fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 2941\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2942\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2943\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_merge_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_merge_call\u001b[0;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[1;32m   2946\u001b[0m         distribution_strategy_context._CrossReplicaThreadMode(self._strategy))  # pylint: disable=protected-access\n\u001b[1;32m   2947\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2948\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2949\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2950\u001b[0m       \u001b[0m_pop_per_thread_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0mnew_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m         \u001b[0mcaller_fn_scope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaller_fn_scope\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m         options=options)\n\u001b[0m\u001b[1;32m    377\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misbuiltin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    348\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_distributed_apply\u001b[0;34m(self, distribution, grads_and_vars, name, apply_state)\u001b[0m\n\u001b[1;32m    681\u001b[0m                               \"update_\" + var.op.name, skip_on_eager=True):\n\u001b[1;32m    682\u001b[0m             update_ops.extend(distribution.extended.update(\n\u001b[0;32m--> 683\u001b[0;31m                 var, apply_grad_to_update_var, args=(grad,), group=False))\n\u001b[0m\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m       any_symbolic = any(isinstance(i, ops.Operation) or\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   2492\u001b[0m         fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[1;32m   2493\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2494\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2496\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_update\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/tpu_strategy.py\u001b[0m in \u001b[0;36m_update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   1137\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m     \u001b[0;31m# Otherwise, we revert to MirroredStrategy behavior and update the variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    665\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconversion_ctx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 667\u001b[0;31m           \u001b[0;32mreturn\u001b[0m \u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    668\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ag_error_metadata'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    348\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mconversion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_in_allowlist_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Allowlisted %s: from cache'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 350\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    352\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_status_ctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 478\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    479\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36mapply_grad_to_update_var\u001b[0;34m(var, grad)\u001b[0m\n\u001b[1;32m    656\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m\"apply_state\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dense_apply_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0mapply_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"apply_state\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m       \u001b[0mupdate_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_resource_apply_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mapply_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraint\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/adam.py\u001b[0m in \u001b[0;36m_resource_apply_dense\u001b[0;34m(self, grad, var, apply_state)\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0mvar_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m     coefficients = ((apply_state or {}).get((var_device, var_dtype))\n\u001b[0;32m--> 169\u001b[0;31m                     or self._fallback_apply_state(var_device, var_dtype))\n\u001b[0m\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_slot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'm'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py\u001b[0m in \u001b[0;36m_fallback_apply_state\u001b[0;34m(self, var_device, var_dtype)\u001b[0m\n\u001b[1;32m    890\u001b[0m     \u001b[0;34m\"\"\"Compatibility for subclasses that don't pass apply_state through.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m     \u001b[0mapply_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_local\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/adam.py\u001b[0m in \u001b[0;36m_prepare_local\u001b[0;34m(self, var_device, var_dtype, apply_state)\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0mbeta_2_power\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta_2_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m     lr = (apply_state[(var_device, var_dtype)]['lr_t'] *\n\u001b[0;32m--> 143\u001b[0;31m           (math_ops.sqrt(1 - beta_2_power) / (1 - beta_1_power)))\n\u001b[0m\u001b[1;32m    144\u001b[0m     apply_state[(var_device, var_dtype)].update(\n\u001b[1;32m    145\u001b[0m         dict(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1162\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1164\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1165\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m         \u001b[0;31m# Even if dispatching the op failed, the RHS may be a tensor aware\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36mtruediv\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1334\u001b[0m     \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mx\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mhave\u001b[0m \u001b[0mdifferent\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m   \"\"\"\n\u001b[0;32m-> 1336\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_truediv_python3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1337\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/math_ops.py\u001b[0m in \u001b[0;36m_truediv_python3\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   1273\u001b[0m       \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1275\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal_div\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mreal_div\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   7345\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7346\u001b[0m     _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0;32m-> 7347\u001b[0;31m         \"RealDiv\", x=x, y=y, name=name)\n\u001b[0m\u001b[1;32m   7348\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7349\u001b[0m     result = _dispatch.dispatch(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0;31m# Convert attr values to AttrValue protos.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0mattr_protos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mattr_def\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m       \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattr_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m       \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","metadata":{"id":"9s4Dbih_NYkg"},"source":["# New Section"]},{"cell_type":"code","metadata":{"id":"180-D4kGO5K7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1619008370537,"user_tz":-120,"elapsed":591,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}},"outputId":"4fc140d7-2e64-40c7-b4d9-705b2ab39bcb"},"source":["accuracies = []\n","with open(PATH_GDRIVE_TMP + 'bert_4_accuracies.txt', mode='r') as f:\n","  for line in f:\n","    accuracies.append(float(line))\n","accuracies = accuracies[0:250]\n","print(len(accuracies))\n","print(np.array(accuracies).mean())"],"execution_count":27,"outputs":[{"output_type":"stream","text":["311\n","0.4939442658092176\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZN71IZ5rTOOZ","colab":{"base_uri":"https://localhost:8080/","height":281},"executionInfo":{"status":"ok","timestamp":1619008194943,"user_tz":-120,"elapsed":1357,"user":{"displayName":"Stefan Zaruba","photoUrl":"","userId":"04180368157783392691"}},"outputId":"4aa15283-712b-4422-e07a-2c375300e4b5"},"source":["import matplotlib.pyplot as plt\n","import matplotlib.colors\n","import numpy as np\n","\n","total = len(accuracies)\n","mean = sum(accuracies)/total\n","\n","fig = plt.figure()\n","ax = fig.add_subplot(111)\n","ax.plot(sorted(accuracies), label='Model accuracies')\n","plt.axhline(y=0.33, color='r', linestyle='-', label='Random guess')\n","plt.axhline(y=mean, color='orange', linestyle='-', label='Mean accuracy')\n","ax.text(-0.02, mean, \"{:.2f}\".format(mean), color='orange', ha=\"right\", va=\"center\", \n","        transform=ax.get_yaxis_transform())\n","plt.ylabel('Model Accuracies')\n","plt.title(f\"Accuracies of {total} individual train-evaluation runs\")\n","plt.legend(loc=\"lower right\", borderaxespad=0)\n","plt.savefig(PATH_GDRIVE_TMP + 'plots/accuracies_bert_4.png')\n","plt.show()"],"execution_count":24,"outputs":[{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"5KPTuQ_oaIO4"},"source":[""],"execution_count":null,"outputs":[]}]}